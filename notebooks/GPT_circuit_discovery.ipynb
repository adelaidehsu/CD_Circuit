{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61a0720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a120102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for if we're trying to execute on a remote JupyterHub, where the pwd is set to the server root, or else I think pwd is set correctly already.\n",
    "# %cd CD_Circuit/\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# CD-T Imports\n",
    "import math\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson, combine_token_attn, compute_word_intervals, compare_same\n",
    "from pyfunctions.pathology import extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from pyfunctions.wrappers import Node, AblationSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651660-7f59-4b59-a574-afecc52dc306",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model\n",
    "\n",
    "Note: Unlike with the BERT model + medical dataset objective, it is not necessary to pretrain GPT-2 to perform the IOI dataset.\n",
    "GPT-2-small is already capable of performing IOI; that's part of the point of the Mech Interp in the Wild paper.\n",
    "We only need to examine how it does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a520f760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "# Model code adapted from Callum McDougall's notebook for ARENA on reproducing the IOI paper using TransformerLens.\n",
    "# This makes some sense, since EasyTransformer, the repo/lib released by the IOI guys, was forked from TransformerLens.\n",
    "# In fact, this makes the reproduction a little bit more faithful, since they most likely do certain things such as \n",
    "# \"folding\" LayerNorms to improve their interpretability results, and we are able to do the same by using TransformerLens.\n",
    "# HuggingFace, by contrast, has the most impenetrable docs and tons of outdated APIs and etc.; even their source \n",
    "# code is impossible to traverse, and I gave up on it, thankfully quickly.\n",
    "\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",\n",
    "                                          center_unembed=True,\n",
    "                                          center_writing_weights=True,\n",
    "                                          fold_ln=False,\n",
    "                                          refactor_factored_attn_matrices=True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffd4d3-5e8f-4587-bb2a-f06b61918c09",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Generate mean activations\n",
    "\n",
    "This is not as simple as it sounds; for the IOI paper, for each individual input following a template, they ablate using the mean activations of the \"ABC\" dataset, generated over sentences following the same template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab88048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "\n",
    "# Generate a dataset all consisting of one template, randomly chosen.\n",
    "# nb_templates = 2 due to some logic internal to IOIDataset:\n",
    "# essentially, the nouns can be an ABBA or ABAB order and that counts as separate templates.\n",
    "ioi_dataset = IOIDataset(prompt_type=\"mixed\", N=3, tokenizer=model.tokenizer, prepend_bos=False, nb_templates=2)\n",
    "\n",
    "# This is the P_ABC that is mentioned in the IOI paper, which we use for mean ablation.\n",
    "# Importantly, passing in prompt_type=\"ABC\" or similar is NOT the same thing as this.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "\n",
    "logits, cache = model.run_with_cache(abc_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "attention_outputs = [cache['blocks.' + str(i) + '.hook_attn_out'] for i in range(12)]\n",
    "attention_outputs = torch.stack(attention_outputs, dim=1) # now batch, head, seq, d_model\n",
    "mean_acts = torch.mean(attention_outputs, dim=0)\n",
    "mean_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c32de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# source_list = [Node(0, 0, 0), Node(1, 1, 1)]\n",
    "# target_nodes = [(7, 0, 1)]\n",
    "\n",
    "text = ioi_dataset.sentences[0]\n",
    "encoding = model.tokenizer.encode_plus(text, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "# out_decomps, target_decomps, _ = prop_GPT(encoding_idxs, extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851670c7-28fd-447a-a9d8-16b8c87b1ac4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Algorithm A (the one found in the current paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb4c809f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 2304)\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "Running inputs 192 to 256 (of 2304)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m out_decomp, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[0;32m---> 20\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:355\u001b[0m, in \u001b[0;36mbatch_run\u001b[0;34m(prop_model_fn, ablation_list, num_at_time, n_layers)\u001b[0m\n\u001b[1;32m    353\u001b[0m b_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(b_st \u001b[38;5;241m+\u001b[39m num_at_time, n_ablations)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning inputs \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (b_st, b_end, n_ablations))\n\u001b[0;32m--> 355\u001b[0m batch_out_decomps, batch_target_decomps, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprop_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_st\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m out_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_out_decomps\n\u001b[1;32m    358\u001b[0m target_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_target_decomps\n",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ablation_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# cache activations for faster batch run\u001b[39;00m\n\u001b[1;32m     17\u001b[0m out_decomp, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: \u001b[43mprop_GPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_acts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_pre_layer_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_layer_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m batch_run(prop_fn, ablation_sets)\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:332\u001b[0m, in \u001b[0;36mprop_GPT\u001b[0;34m(encoding_idxs, extended_attention_mask, model, ablation_list, target_nodes, device, mean_acts, att_list, output_att_prob, set_irrel_to_mean, cached_pre_layer_acts)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ablation, batch_indices \u001b[38;5;129;01min\u001b[39;00m ablation_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    331\u001b[0m     rel_vec \u001b[38;5;241m=\u001b[39m rel_out[batch_indices, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 332\u001b[0m     irrel_vec \u001b[38;5;241m=\u001b[39m \u001b[43mirrel_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()       \n\u001b[1;32m    333\u001b[0m     out_decomps\u001b[38;5;241m.\u001b[39mappend(OutputDecomposition(ablation, rel_vec, irrel_vec))\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_decomps, target_decomps, att_probs_lst, pre_layer_acts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad70e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = io_logit - s_logit\n",
    "assert(full_score > 0)\n",
    "\n",
    "results = []\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    results.append(Result(decomp.ablation_set, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25972ca-181f-43bc-9750-acfb689a7687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4401803-697d-4dc3-8212-fd99658257a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.26448378),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=3),), score=0.25145364),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=9),), score=0.23916136),\n",
       " Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=6),), score=0.23849736),\n",
       " Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=6),), score=0.23597252),\n",
       " Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=1),), score=0.23574805),\n",
       " Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=1),), score=0.23302731),\n",
       " Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=1),), score=0.23266618),\n",
       " Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=6),), score=0.23030597),\n",
       " Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=2),), score=0.22867103),\n",
       " Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=2),), score=0.22722122),\n",
       " Result(ablation_set=(Node(layer_idx=4, sequence_idx=2, attn_head_idx=6),), score=0.22664025),\n",
       " Result(ablation_set=(Node(layer_idx=6, sequence_idx=2, attn_head_idx=6),), score=0.22631785),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=3),), score=0.2260085),\n",
       " Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=6),), score=0.22309878)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce463474-bb7b-42c5-84bc-8fac38699c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc3f6b47-439f-4fe0-b987-a8b2a1264258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ff1e97-c772-4063-8b4c-e9705185498e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "def interquartile_range(results, iqr_multiplier=1):\n",
    "    # assume sorted in increasing order\n",
    "    third_quartile = results[int(len(results) * 0.75)].score\n",
    "    first_quartile = results[int(len(results) * 0.25)].score\n",
    "    IQR = third_quartile - first_quartile\n",
    "    outlier_score = third_quartile + iqr_multiplier * IQR\n",
    "    print(third_quartile, first_quartile, outlier_score)\n",
    "\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):]\n",
    "    return outliers\n",
    "\n",
    "def n_sigma_rule(results, n=3):\n",
    "    scores = [r.score for r in results]\n",
    "    std_dev = np.std(scores)\n",
    "    mean = np.mean(scores)\n",
    "    outlier_score = mean + std_dev * n\n",
    "    print(std_dev, mean, outlier_score)\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):] #bisect does a binary search, returns idx of outlier_score\n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "effd20fb-68cd-41df-99a8-a2c44bff8038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0048643267 0.0020574331 0.007671220228075981\n",
      "1\n",
      "0.0033118916 0.0037320566 0.005388002377003431\n",
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92ef27aa-343c-42ce-8a25-0af8f4418e22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11498.65576171875\n",
      "12060.0\n",
      "882.81982421875\n",
      "1212.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "600b77bd-5aa7-4a6c-b0d9-35194fb8dffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_per_iter = []\n",
    "# outliers_per_iter = [[Node(11, 14, 3), Node(10, 14, 3), Node(0, 2, 9), Node(1, 2, 6), Node(3, 2, 6), Node(3, 2, 1)]]\n",
    "# Node(layer_idx=11, sequence_idx=14, attn_head_idx=3), Node(layer_idx=10, sequence_idx=14, attn_head_idx=3), Node(layer_idx=0, sequence_idx=2, attn_head_idx=9),\n",
    "# Node(layer_idx=1, sequence_idx=2, attn_head_idx=6), Node(layer_idx=3, sequence_idx=2, attn_head_idx=6), Node(layer_idx=3, sequence_idx=2, attn_head_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32b2b05c-eee7-4a95-aef5-126b082ec550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=0, sequence_idx=2, attn_head_idx=9), Node(layer_idx=2, sequence_idx=2, attn_head_idx=5), Node(layer_idx=0, sequence_idx=2, attn_head_idx=1), Node(layer_idx=1, sequence_idx=2, attn_head_idx=5), Node(layer_idx=0, sequence_idx=2, attn_head_idx=6), Node(layer_idx=0, sequence_idx=2, attn_head_idx=5)]\n",
      "Running inputs 0 to 64 (of 2304)\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "Running inputs 192 to 256 (of 2304)\n",
      "Running inputs 256 to 320 (of 2304)\n",
      "Running inputs 320 to 384 (of 2304)\n",
      "Running inputs 384 to 448 (of 2304)\n",
      "Running inputs 448 to 512 (of 2304)\n",
      "Running inputs 512 to 576 (of 2304)\n",
      "Running inputs 576 to 640 (of 2304)\n",
      "Running inputs 640 to 704 (of 2304)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[0;32m---> 26\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_decomp \u001b[38;5;129;01min\u001b[39;00m target_decomps:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\u001b[39;00m\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:355\u001b[0m, in \u001b[0;36mbatch_run\u001b[0;34m(prop_model_fn, ablation_list, num_at_time, n_layers)\u001b[0m\n\u001b[1;32m    353\u001b[0m b_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(b_st \u001b[38;5;241m+\u001b[39m num_at_time, n_ablations)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning inputs \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (b_st, b_end, n_ablations))\n\u001b[0;32m--> 355\u001b[0m batch_out_decomps, batch_target_decomps, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprop_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_st\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m out_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_out_decomps\n\u001b[1;32m    358\u001b[0m target_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_target_decomps\n",
      "Cell \u001b[0;32mIn[42], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ablation_list)\u001b[0m\n\u001b[1;32m     21\u001b[0m ablation_sets \u001b[38;5;241m=\u001b[39m [(n,) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m source_nodes]\n\u001b[1;32m     23\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 25\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: \u001b[43mprop_GPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_acts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_pre_layer_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_layer_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m batch_run(prop_fn, ablation_sets)\n\u001b[1;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:331\u001b[0m, in \u001b[0;36mprop_GPT\u001b[0;34m(encoding_idxs, extended_attention_mask, model, ablation_list, target_nodes, device, mean_acts, att_list, output_att_prob, set_irrel_to_mean, cached_pre_layer_acts)\u001b[0m\n\u001b[1;32m    329\u001b[0m out_decomps \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ablation, batch_indices \u001b[38;5;129;01min\u001b[39;00m ablation_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 331\u001b[0m     rel_vec \u001b[38;5;241m=\u001b[39m \u001b[43mrel_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    332\u001b[0m     irrel_vec \u001b[38;5;241m=\u001b[39m irrel_out[batch_indices, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()       \n\u001b[1;32m    333\u001b[0m     out_decomps\u001b[38;5;241m.\u001b[39mappend(OutputDecomposition(ablation, rel_vec, irrel_vec))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now, find maximally relevant source nodes to target nodes\n",
    "\n",
    "\n",
    "# results.sort(key=operator.attrgetter('score'), reverse=False)\n",
    "# iqr = interquartile_range(results)\n",
    "# print(len(iqr))\n",
    "# outliers = n_sigma_rule(results, n=0.5)\n",
    "# print(len(outliers))\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = results[:6] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) # why does this run so slowly? is it because moving target decomps is slow or something?\n",
    "\n",
    "results = []\n",
    "for target_decomp in target_decomps:\n",
    "    # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "    score = 0\n",
    "    for i in range(len(target_decomp.target_nodes)):\n",
    "        rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "        irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "        target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "        score += target_node_score\n",
    "    results.append(Result(target_decomp.ablation_set, score))\n",
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "print(results[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5baef4b-3ea1-4131-85a2-396d544d5ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=0, sequence_idx=2, attn_head_idx=9), Node(layer_idx=2, sequence_idx=2, attn_head_idx=5), Node(layer_idx=0, sequence_idx=2, attn_head_idx=1), Node(layer_idx=1, sequence_idx=2, attn_head_idx=5), Node(layer_idx=0, sequence_idx=2, attn_head_idx=6), Node(layer_idx=0, sequence_idx=2, attn_head_idx=5)]\n",
      "running layer 0\n",
      "running layer 1\n",
      "running layer 2\n",
      "running layer 3\n",
      "running layer 4\n",
      "running layer 5\n",
      "running layer 6\n",
      "running layer 7\n",
      "running layer 8\n",
      "running layer 9\n",
      "running layer 10\n",
      "running layer 11\n",
      "Running inputs 0 to 64 (of 2304)\n",
      "running layer 0\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "running layer 0\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "running layer 0\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 192 to 256 (of 2304)\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 256 to 320 (of 2304)\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 320 to 384 (of 2304)\n",
      "running layer 1\n",
      "running layer 2\n",
      "Running inputs 384 to 448 (of 2304)\n",
      "running layer 2\n",
      "Running inputs 448 to 512 (of 2304)\n",
      "running layer 2\n",
      "Running inputs 512 to 576 (of 2304)\n",
      "running layer 2\n",
      "Running inputs 576 to 640 (of 2304)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[0;32m---> 18\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:356\u001b[0m, in \u001b[0;36mbatch_run\u001b[0;34m(prop_model_fn, ablation_list, num_at_time, n_layers)\u001b[0m\n\u001b[1;32m    354\u001b[0m b_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(b_st \u001b[38;5;241m+\u001b[39m num_at_time, n_ablations)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning inputs \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (b_st, b_end, n_ablations))\n\u001b[0;32m--> 356\u001b[0m batch_out_decomps, batch_target_decomps, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprop_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_st\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m out_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_out_decomps\n\u001b[1;32m    359\u001b[0m target_decomps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_target_decomps\n",
      "Cell \u001b[0;32mIn[43], line 17\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ablation_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m ablation_sets \u001b[38;5;241m=\u001b[39m [(n,) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m source_nodes]\n\u001b[1;32m     15\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: \u001b[43mprop_GPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_acts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_pre_layer_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_layer_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m batch_run(prop_fn, ablation_sets)\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:333\u001b[0m, in \u001b[0;36mprop_GPT\u001b[0;34m(encoding_idxs, extended_attention_mask, model, ablation_list, target_nodes, device, mean_acts, att_list, output_att_prob, set_irrel_to_mean, cached_pre_layer_acts)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ablation, batch_indices \u001b[38;5;129;01min\u001b[39;00m ablation_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    332\u001b[0m     rel_vec \u001b[38;5;241m=\u001b[39m rel_out[batch_indices, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 333\u001b[0m     irrel_vec \u001b[38;5;241m=\u001b[39m \u001b[43mirrel_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()       \n\u001b[1;32m    334\u001b[0m     out_decomps\u001b[38;5;241m.\u001b[39mappend(OutputDecomposition(ablation, rel_vec, irrel_vec))\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_decomps, target_decomps, att_probs_lst, pre_layer_acts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = results[:6] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2bf915a-9f08-46b7-b5ef-1cb1e3a7857b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(target_decomps))\n",
    "print((abs(target_decomps[0].rels[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18167b58-cf91-4d50-bbb8-42983d510a43",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## New algorithm (fixed number of nodes per layer, weight relevance to the nodes according to the nodes' relevance in the previous iter, take nodes with highest absolute scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131aae5-b946-4acc-aebf-1e769116f9e9",
   "metadata": {},
   "source": [
    "There are two problems with this algorithm generally:\n",
    "\n",
    "1. The \"relevance to logits\" score isn't on the same scale as \"relevance to target nodes\" score, so there's no principled way to decide whether nodes in the last layer are more or less relevant than others.\n",
    "\n",
    "2. More fatally, the most important nodes converge to position 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2ff3c0a-5464-4075-a40f-a110bef9da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [11],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)\n",
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = io_logit - s_logit\n",
    "assert(full_score > 0)\n",
    "\n",
    "last_layer_results = []\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    last_layer_results.append(Result(decomp.ablation_set, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc619414-6852-435a-b884-2c0a5692e3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.26448268), Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.21131109), Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=1),), score=0.19242775), Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=6),), score=0.15672545), Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=5),), score=0.12439702), Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=10),), score=0.11557169)]\n"
     ]
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "print(last_layer_results[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8c7d26c-c213-4968-9784-f2c4ead35791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 10: \n",
      "new target nodes:\n",
      "[Node(layer_idx=11, sequence_idx=14, attn_head_idx=3), Node(layer_idx=11, sequence_idx=14, attn_head_idx=0), Node(layer_idx=11, sequence_idx=14, attn_head_idx=1), Node(layer_idx=11, sequence_idx=14, attn_head_idx=6), Node(layer_idx=11, sequence_idx=14, attn_head_idx=5), Node(layer_idx=11, sequence_idx=14, attn_head_idx=10)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 9: \n",
      "new target nodes:\n",
      "[Node(layer_idx=10, sequence_idx=2, attn_head_idx=5), Node(layer_idx=10, sequence_idx=2, attn_head_idx=3), Node(layer_idx=10, sequence_idx=9, attn_head_idx=6), Node(layer_idx=10, sequence_idx=2, attn_head_idx=6), Node(layer_idx=10, sequence_idx=2, attn_head_idx=4), Node(layer_idx=10, sequence_idx=2, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 8: \n",
      "new target nodes:\n",
      "[Node(layer_idx=9, sequence_idx=0, attn_head_idx=6), Node(layer_idx=9, sequence_idx=0, attn_head_idx=2), Node(layer_idx=9, sequence_idx=0, attn_head_idx=4), Node(layer_idx=9, sequence_idx=0, attn_head_idx=11), Node(layer_idx=9, sequence_idx=0, attn_head_idx=5), Node(layer_idx=9, sequence_idx=0, attn_head_idx=8)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 7: \n",
      "new target nodes:\n",
      "[Node(layer_idx=8, sequence_idx=0, attn_head_idx=2), Node(layer_idx=8, sequence_idx=0, attn_head_idx=6), Node(layer_idx=8, sequence_idx=0, attn_head_idx=10), Node(layer_idx=8, sequence_idx=0, attn_head_idx=5), Node(layer_idx=8, sequence_idx=0, attn_head_idx=4), Node(layer_idx=8, sequence_idx=0, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 6: \n",
      "new target nodes:\n",
      "[Node(layer_idx=7, sequence_idx=0, attn_head_idx=2), Node(layer_idx=7, sequence_idx=0, attn_head_idx=6), Node(layer_idx=7, sequence_idx=0, attn_head_idx=5), Node(layer_idx=7, sequence_idx=0, attn_head_idx=4), Node(layer_idx=7, sequence_idx=0, attn_head_idx=10), Node(layer_idx=7, sequence_idx=0, attn_head_idx=8)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 5: \n",
      "new target nodes:\n",
      "[Node(layer_idx=6, sequence_idx=0, attn_head_idx=2), Node(layer_idx=6, sequence_idx=0, attn_head_idx=6), Node(layer_idx=6, sequence_idx=0, attn_head_idx=5), Node(layer_idx=6, sequence_idx=0, attn_head_idx=10), Node(layer_idx=6, sequence_idx=0, attn_head_idx=11), Node(layer_idx=6, sequence_idx=0, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 4: \n",
      "new target nodes:\n",
      "[Node(layer_idx=5, sequence_idx=0, attn_head_idx=6), Node(layer_idx=5, sequence_idx=0, attn_head_idx=2), Node(layer_idx=5, sequence_idx=0, attn_head_idx=5), Node(layer_idx=5, sequence_idx=0, attn_head_idx=4), Node(layer_idx=5, sequence_idx=0, attn_head_idx=10), Node(layer_idx=5, sequence_idx=0, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 3: \n",
      "new target nodes:\n",
      "[Node(layer_idx=4, sequence_idx=0, attn_head_idx=6), Node(layer_idx=4, sequence_idx=0, attn_head_idx=2), Node(layer_idx=4, sequence_idx=0, attn_head_idx=5), Node(layer_idx=4, sequence_idx=0, attn_head_idx=1), Node(layer_idx=4, sequence_idx=0, attn_head_idx=11), Node(layer_idx=4, sequence_idx=0, attn_head_idx=10)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 2: \n",
      "new target nodes:\n",
      "[Node(layer_idx=3, sequence_idx=0, attn_head_idx=6), Node(layer_idx=3, sequence_idx=0, attn_head_idx=5), Node(layer_idx=3, sequence_idx=0, attn_head_idx=2), Node(layer_idx=3, sequence_idx=0, attn_head_idx=10), Node(layer_idx=3, sequence_idx=0, attn_head_idx=4), Node(layer_idx=3, sequence_idx=0, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 1: \n",
      "new target nodes:\n",
      "[Node(layer_idx=2, sequence_idx=0, attn_head_idx=2), Node(layer_idx=2, sequence_idx=0, attn_head_idx=5), Node(layer_idx=2, sequence_idx=0, attn_head_idx=4), Node(layer_idx=2, sequence_idx=0, attn_head_idx=6), Node(layer_idx=2, sequence_idx=0, attn_head_idx=10), Node(layer_idx=2, sequence_idx=0, attn_head_idx=11)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 0: \n",
      "new target nodes:\n",
      "[Node(layer_idx=1, sequence_idx=0, attn_head_idx=11), Node(layer_idx=1, sequence_idx=0, attn_head_idx=6), Node(layer_idx=1, sequence_idx=0, attn_head_idx=2), Node(layer_idx=1, sequence_idx=0, attn_head_idx=1), Node(layer_idx=1, sequence_idx=0, attn_head_idx=5), Node(layer_idx=1, sequence_idx=0, attn_head_idx=8)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = last_layer_results[:6] # hardcoded first few N\n",
    "outliers_per_iter = [outliers]\n",
    "node_weights = [r.score for r in outliers]\n",
    "\n",
    "for layer in range(10, -1, -1):\n",
    "    target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "    sum_scores = sum([r.score for r in outliers])\n",
    "    node_weights = [r.score / sum_scores for r in outliers]\n",
    "    print(\"layer %d: \" % layer)\n",
    "    print(\"new target nodes:\")\n",
    "    print(target_nodes)\n",
    "    ranges = [\n",
    "            [layer],\n",
    "            [sequence_position for sequence_position in range(input_shape[1])],\n",
    "            [attention_head_idx for attention_head_idx in range(12)]\n",
    "        ]\n",
    "\n",
    "    source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "    ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "    prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "    _, target_decomps = batch_run(prop_fn, ablation_sets) # why does this run so slowly? is it because moving target decomps is slow or something?\n",
    "\n",
    "    results = []\n",
    "    for target_decomp in target_decomps:\n",
    "        # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "        score = 0\n",
    "        for i in range(len(target_decomp.target_nodes)):\n",
    "            weight = node_weights[i]\n",
    "            rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "            irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "            target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "            score += (target_node_score * weight)\n",
    "        results.append(Result(target_decomp.ablation_set, score))\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    outliers = results[:6] # hardcoded first few N\n",
    "    outliers_per_iter.append(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2e64cd0-7877-420b-9eed-35f9e722eb98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.26448268)\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# for outs in outliers_per_iter:\n",
    "#     print([r.score for r in outs])\n",
    "\n",
    "all_outliers = sum(outliers_per_iter, [])\n",
    "print(all_outliers[0])\n",
    "print(len(all_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80475254-fedc-445a-b251-7ee50dd82df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=0, attn_head_idx=2),), score=tensor(0.6139, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=0, attn_head_idx=2),), score=tensor(0.5838, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5750, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5708, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=0, attn_head_idx=2),), score=tensor(0.5671, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=2),), score=tensor(0.5665, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5463, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5349, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5339, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=6),), score=tensor(0.5266, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=0, attn_head_idx=2),), score=tensor(0.5174, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=0, attn_head_idx=11),), score=tensor(0.4297, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=10),), score=tensor(0.4252, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=5),), score=tensor(0.4241, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=0, attn_head_idx=2),), score=tensor(0.4185, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=5),), score=tensor(0.4120, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=4),), score=tensor(0.4116, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=9, sequence_idx=0, attn_head_idx=6),), score=tensor(0.4054, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=0, attn_head_idx=5),), score=tensor(0.3885, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=0, attn_head_idx=5),), score=tensor(0.3836, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=0, attn_head_idx=1),), score=tensor(0.3727, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=0, attn_head_idx=4),), score=tensor(0.3671, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=9, sequence_idx=0, attn_head_idx=2),), score=tensor(0.3647, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=0, attn_head_idx=5),), score=tensor(0.3617, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=0, attn_head_idx=4),), score=tensor(0.3601, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "all_outliers.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "for x in range(25):\n",
    "    print(all_outliers[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
