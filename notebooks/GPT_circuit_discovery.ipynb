{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61a0720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a120102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for if we're trying to execute on a remote JupyterHub, where the pwd is set to the server root, or else I think pwd is set correctly already.\n",
    "# %cd CD_Circuit/\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# CD-T Imports\n",
    "import math\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson, combine_token_attn, compute_word_intervals, compare_same\n",
    "from pyfunctions.pathology import extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from pyfunctions.wrappers import Node, AblationSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651660-7f59-4b59-a574-afecc52dc306",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model\n",
    "\n",
    "Note: Unlike with the BERT model + medical dataset objective, it is not necessary to pretrain GPT-2 to perform the IOI dataset.\n",
    "GPT-2-small is already capable of performing IOI; that's part of the point of the Mech Interp in the Wild paper.\n",
    "We only need to examine how it does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a520f760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "# Model code adapted from Callum McDougall's notebook for ARENA on reproducing the IOI paper using TransformerLens.\n",
    "# This makes some sense, since EasyTransformer, the repo/lib released by the IOI guys, was forked from TransformerLens.\n",
    "# In fact, this makes the reproduction a little bit more faithful, since they most likely do certain things such as \n",
    "# \"folding\" LayerNorms to improve their interpretability results, and we are able to do the same by using TransformerLens.\n",
    "# HuggingFace, by contrast, has the most impenetrable docs and tons of outdated APIs and etc.; even their source \n",
    "# code is impossible to traverse, and I gave up on it, thankfully quickly.\n",
    "\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",\n",
    "                                          center_unembed=True,\n",
    "                                          center_writing_weights=True,\n",
    "                                          fold_ln=False,\n",
    "                                          refactor_factored_attn_matrices=True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffd4d3-5e8f-4587-bb2a-f06b61918c09",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Generate mean activations\n",
    "\n",
    "This is not as simple as it sounds; for the IOI paper, for each individual input following a template, they ablate using the mean activations of the \"ABC\" dataset, generated over sentences following the same template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab88048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 22:18:59.754606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 22:19:02.585829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "\n",
    "# Generate a dataset all consisting of one template, randomly chosen.\n",
    "# nb_templates = 2 due to some logic internal to IOIDataset:\n",
    "# essentially, the nouns can be an ABBA or ABAB order and that counts as separate templates.\n",
    "ioi_dataset = IOIDataset(prompt_type=\"mixed\", N=3, tokenizer=model.tokenizer, prepend_bos=False, nb_templates=2)\n",
    "\n",
    "# This is the P_ABC that is mentioned in the IOI paper, which we use for mean ablation.\n",
    "# Importantly, passing in prompt_type=\"ABC\" or similar is NOT the same thing as this.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "\n",
    "logits, cache = model.run_with_cache(abc_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "attention_outputs = [cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(12)]\n",
    "attention_outputs = torch.stack(attention_outputs, dim=1) # now batch, layer, seq, n_heads, dim_attn\n",
    "mean_acts = torch.mean(attention_outputs, dim=0)\n",
    "old_shape = mean_acts.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "mean_acts = mean_acts.view(new_shape)\n",
    "mean_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c32de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# source_list = [Node(0, 0, 0), Node(1, 1, 1)]\n",
    "# target_nodes = [(7, 0, 1)]\n",
    "\n",
    "text = ioi_dataset.sentences[0]\n",
    "encoding = model.tokenizer.encode_plus(text, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "# out_decomps, target_decomps, _ = prop_GPT(encoding_idxs, extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851670c7-28fd-447a-a9d8-16b8c87b1ac4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Algorithm A (the one found in the current paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758995f-1b99-4ed8-aeaa-0612767fa13e",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Run on last sequence position specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4c809f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m target_nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# cache activations for faster batch run\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m out_decomp, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m \u001b[43mprop_GPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_acts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[1;32m     21\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m batch_run(prop_fn, ablation_sets)\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:353\u001b[0m, in \u001b[0;36mprop_GPT\u001b[0;34m(encoding_idxs, extended_attention_mask, model, ablation_list, target_nodes, device, mean_acts, att_list, set_irrel_to_mean, cached_pre_layer_acts)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     layer_mean_acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m rel, irrel, layer_target_decomps, returned_att_probs \u001b[38;5;241m=\u001b[39m \u001b[43mprop_GPT_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mirrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_mean_acts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43matt_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_irrel_to_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target_decomps)):\n\u001b[1;32m    362\u001b[0m     target_decomps[idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m layer_target_decomps[idx]\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:155\u001b[0m, in \u001b[0;36mprop_GPT_layer\u001b[0;34m(rel, irrel, attention_mask, head_mask, ablation_dict, target_nodes, level, layer_mean_acts, layer_module, device, att_probs, set_irrel_to_mean)\u001b[0m\n\u001b[1;32m    150\u001b[0m rel_summed_values, irrel_summed_values \u001b[38;5;241m=\u001b[39m set_rel_at_source_nodes(rel_summed_values, irrel_summed_values, ablation_dict, layer_mean_acts, level, attn_wrapper, set_irrel_to_mean, device)\n\u001b[1;32m    151\u001b[0m layer_target_decomps \u001b[38;5;241m=\u001b[39m calculate_contributions(rel_summed_values, irrel_summed_values, ablation_dict,\n\u001b[1;32m    152\u001b[0m                                                                        target_nodes, level,\n\u001b[1;32m    153\u001b[0m                                                                        attn_wrapper, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 155\u001b[0m rel_attn_residual, irrel_attn_residual \u001b[38;5;241m=\u001b[39m prop_linear(rel_summed_values, irrel_summed_values, \u001b[43mattn_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# now that we've calculated the output of the attention mechanism, set desired inputs to \"relevant\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# print('irrel norm after set_rel_at_source_nodes: ', np.linalg.norm(irrel_attn_residual.cpu().numpy()))\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m#rel_attn_residual, irrel_attn_residual = set_rel_at_source_nodes(rel_attn_residual, irrel_attn_residual, ablation_dict, layer_mean_acts, level, attn_wrapper, set_irrel_to_mean, device)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m#                                                                        target_nodes, level,\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m#                                                                       attn_wrapper, device=device)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m rel_mid, irrel_mid \u001b[38;5;241m=\u001b[39m rel \u001b[38;5;241m+\u001b[39m rel_attn_residual, irrel \u001b[38;5;241m+\u001b[39m irrel_attn_residual\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/wrappers.py:79\u001b[0m, in \u001b[0;36mGPTAttentionWrapper.output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGPTOutputMatrixWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_O\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_O\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/wrappers.py:46\u001b[0m, in \u001b[0;36mGPTOutputMatrixWrapper.__init__\u001b[0;34m(self, weight, bias)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight, bias):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# analogous to the value matrix wrappeExpected size for first two dimensions of batch2 tensor to be: [768, 768] but got: [768, 12].\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     new_shape \u001b[38;5;241m=\u001b[39m (\u001b[43mold_shape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m old_shape[\u001b[38;5;241m1\u001b[39m],) \u001b[38;5;241m+\u001b[39m (old_shape[\u001b[38;5;241m2\u001b[39m],)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m (weight\u001b[38;5;241m.\u001b[39mview(new_shape))\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_shape' is not defined"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [input_shape[1] - 2],\n",
    "        # [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376f5a9-9ae5-487d-9a33-7191e95a14e7",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Ablate all heads at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "024c7432-ea39-4f90-b0cf-52663a515f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 180)\n",
      "Running inputs 64 to 128 (of 180)\n",
      "Running inputs 128 to 180 (of 180)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "'''\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        # [input_shape[1] - 2],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "'''\n",
    "ablation_sets = []\n",
    "for layer in range(12):\n",
    "    for seq_idx in range(15):\n",
    "        ablation_sets.append(tuple(Node(layer, seq_idx, x) for x in range(12)))\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea7c8f-a673-4b44-b9a9-d8e7615b3ec5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Do the normal thing and ablate at all individual spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d2e4613-362f-480e-95fb-4f353ac3a845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 2304)\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "Running inputs 192 to 256 (of 2304)\n",
      "Running inputs 256 to 320 (of 2304)\n",
      "Running inputs 320 to 384 (of 2304)\n",
      "Running inputs 384 to 448 (of 2304)\n",
      "Running inputs 448 to 512 (of 2304)\n",
      "Running inputs 512 to 576 (of 2304)\n",
      "Running inputs 576 to 640 (of 2304)\n",
      "Running inputs 640 to 704 (of 2304)\n",
      "Running inputs 704 to 768 (of 2304)\n",
      "Running inputs 768 to 832 (of 2304)\n",
      "Running inputs 832 to 896 (of 2304)\n",
      "Running inputs 896 to 960 (of 2304)\n",
      "Running inputs 960 to 1024 (of 2304)\n",
      "Running inputs 1024 to 1088 (of 2304)\n",
      "Running inputs 1088 to 1152 (of 2304)\n",
      "Running inputs 1152 to 1216 (of 2304)\n",
      "Running inputs 1216 to 1280 (of 2304)\n",
      "Running inputs 1280 to 1344 (of 2304)\n",
      "Running inputs 1344 to 1408 (of 2304)\n",
      "Running inputs 1408 to 1472 (of 2304)\n",
      "Running inputs 1472 to 1536 (of 2304)\n",
      "Running inputs 1536 to 1600 (of 2304)\n",
      "Running inputs 1600 to 1664 (of 2304)\n",
      "Running inputs 1664 to 1728 (of 2304)\n",
      "Running inputs 1728 to 1792 (of 2304)\n",
      "Running inputs 1792 to 1856 (of 2304)\n",
      "Running inputs 1856 to 1920 (of 2304)\n",
      "Running inputs 1920 to 1984 (of 2304)\n",
      "Running inputs 1984 to 2048 (of 2304)\n",
      "Running inputs 2048 to 2112 (of 2304)\n",
      "Running inputs 2112 to 2176 (of 2304)\n",
      "Running inputs 2176 to 2240 (of 2304)\n",
      "Running inputs 2240 to 2304 (of 2304)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad70e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = np.abs(io_logit - s_logit)\n",
    "assert(full_score > 0)\n",
    "\n",
    "results = []\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    results.append(Result(decomp.ablation_set, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "25c0f73b-759e-409a-b677-90aafd725624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_decomps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35821b-8f3c-436a-8489-951f0d817797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to add a normalization for layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215b6f6b-8f26-4966-917d-5ef5ee1fb397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=0, sequence_idx=0, attn_head_idx=0)\n"
     ]
    }
   ],
   "source": [
    "print(out_decomps[].ablation_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bbe1f41-3b08-45e0-a254-ca346d964911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlogits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\\nio_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\\ns_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\\nfull_score = np.abs(io_logit - s_logit)\\nassert(full_score > 0)\\n\\nresults = []\\n\\nfor decomp in out_decomps:\\n    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\\n    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\\n    score = rel_io_logit - rel_s_logit\\n    #print(score, rel_io_logit, rel_s_logit)\\n    norm_score = score / full_score\\n    results.append(Result(decomp.ablation_set, norm_score))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each source node determine the contribution of rel to the actual score\n",
    "# norms_per_layer = np.zeros()\n",
    "norms = []\n",
    "for decomp in out_decomps:\n",
    "    norms.append(np.linalg.norm(decomp.rel))\n",
    "    \n",
    "norms_by_layer = np.array(norms).reshape(-1, 16 * 12)\n",
    "avg_norm_by_layer = np.mean(norms_by_layer, axis=1)\n",
    "\n",
    "'''\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = np.abs(io_logit - s_logit)\n",
    "assert(full_score > 0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    results.append(Result(decomp.ablation_set, norm_score))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180991c2-2e36-457e-b1c6-b2c9d13b916a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms_by_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a9b8864-2d49-451c-b171-28a7c2b93380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219.33165 , 158.0396  , 124.05173 , 100.218346,  79.22871 ,\n",
       "        63.552044,  52.917133,  38.92066 ,  30.557709,  24.813934,\n",
       "        18.621202,  11.463805], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_norm_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a25972ca-181f-43bc-9750-acfb689a7687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e7a3c6-a644-4d56-8b96-f394e364ed5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=6),), score=0.34177423),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=0),), score=0.28064322),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=9),), score=0.24171533),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=10),), score=0.16338332),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.1422774),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=2),), score=0.13067995),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=2),), score=0.094204046),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=6),), score=0.0845308),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=0.07160555),\n",
       " Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=1),), score=0.06859626),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=0),), score=0.06710677),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=4),), score=0.06252931),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=0.062440902),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=0.055581514),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=0.053372897),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=9),), score=0.052896947),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=0.049103156),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=11),), score=0.048401404),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=6),), score=0.04356133),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=8),), score=0.04053725),\n",
       " Result(ablation_set=(Node(layer_idx=8, sequence_idx=14, attn_head_idx=3),), score=0.03910721),\n",
       " Result(ablation_set=(Node(layer_idx=7, sequence_idx=14, attn_head_idx=9),), score=0.038105365),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=8),), score=0.036404587),\n",
       " Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=7),), score=0.03622276),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=11),), score=0.034884028),\n",
       " Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=1),), score=0.033446305),\n",
       " Result(ablation_set=(Node(layer_idx=8, sequence_idx=14, attn_head_idx=6),), score=0.032880496),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=7),), score=0.028256211),\n",
       " Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=2),), score=0.027049903),\n",
       " Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=11),), score=0.026677739)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e448868-480b-4bb3-92c1-ad25186da61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 50257)\n",
      "0.05% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00048127624012575364"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, cache = model.run_with_cache(encoding_idxs[0:1, :])\n",
    "\n",
    "model_out = out_decomps[0].rel + out_decomps[0].irrel\n",
    "print(model_out.shape)\n",
    "compare_same(logits[0], model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d38babb4-94f6-4d2a-bf25-cd84fadeaddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, Samantha and Laura went to the school. Samantha gave a computer to Laura\n"
     ]
    }
   ],
   "source": [
    "print(ioi_dataset.sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4401803-697d-4dc3-8212-fd99658257a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6) 0.12152111\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=10) 0.0822009\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=9) 0.07783296\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=10) 0.07362208\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=3) 0.071159504\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3) 0.07108998\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=9) 0.06943682\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9) 0.06770895\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=9) 0.06574008\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=6) 0.06536073\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=3) 0.06427851\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=9) 0.0599772\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=3) 0.057893638\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=10) 0.057380237\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=10) 0.0559245\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=6) 0.055904876\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=6) 0.05554507\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10) 0.055238955\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=9) 0.05293593\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=3) 0.051339425\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=6) 0.04840822\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=3) 0.046866648\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=3) 0.04618334\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9) 0.045930613\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10) 0.045326427\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=3) 0.04518606\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=3) 0.044725828\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6) 0.043644518\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=3) 0.042973924\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=9) 0.04256318\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=3) 0.042094387\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=3) 0.038879924\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=9) 0.037446495\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=6) 0.03675412\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=10) 0.034736432\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=10) 0.03429487\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=10) 0.03385796\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=6) 0.03225233\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10) 0.031825617\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=6) 0.031171506\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=6) 0.029102717\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=10) 0.028458526\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=10) 0.028269619\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=9) 0.023748085\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=9) 0.021111524\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=10) 0.017978825\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=3) 0.017961964\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=6) 0.017358523\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=9) 0.01682583\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=6) 0.0133941285\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=3) 0.0130641535\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=9) 0.013008005\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=9) 0.012716658\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=3) 0.011983796\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=6) 0.011983144\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=9) 0.010926103\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=10) 0.009415353\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=6) 0.0072015882\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=10) 0.0069930064\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=6) 0.0061120763\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=3) 0.0\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=9) 0.0\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=6) 0.0\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=10) 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for result in results[:20]:\n",
    "    print(result.ablation_set[0], result.score)\n",
    "'''\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 9 and result.ablation_set[0].attn_head_idx == 9:\n",
    "        print(result.ablation_set[0], result.score)\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "            print(result.ablation_set[0], result.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08ce1ab7-79e2-4c79-9ef9-09b75249e5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03560574 0.05491805\n"
     ]
    }
   ],
   "source": [
    "scores = [r.score for r in results if r.score > 0]\n",
    "std_dev = np.std(scores)\n",
    "mean = np.mean(scores)\n",
    "print(std_dev, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce463474-bb7b-42c5-84bc-8fac38699c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c7f07b99-40b1-4563-bbce-478cc6307baa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ff1e97-c772-4063-8b4c-e9705185498e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "def interquartile_range(results, iqr_multiplier=1):\n",
    "    # assume sorted in increasing order\n",
    "    third_quartile = results[int(len(results) * 0.75)].score\n",
    "    first_quartile = results[int(len(results) * 0.25)].score\n",
    "    IQR = third_quartile - first_quartile\n",
    "    outlier_score = third_quartile + iqr_multiplier * IQR\n",
    "    print(third_quartile, first_quartile, outlier_score)\n",
    "\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):]\n",
    "    return outliers\n",
    "\n",
    "def n_sigma_rule(results, n=3):\n",
    "    scores = [r.score for r in results]\n",
    "    std_dev = np.std(scores)\n",
    "    mean = np.mean(scores)\n",
    "    outlier_score = mean + std_dev * n\n",
    "    print(std_dev, mean, outlier_score)\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):] #bisect does a binary search, returns idx of outlier_score\n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92ef27aa-343c-42ce-8a25-0af8f4418e22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11498.65576171875\n",
      "12060.0\n",
      "882.81982421875\n",
      "1212.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "600b77bd-5aa7-4a6c-b0d9-35194fb8dffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ioi_dataset.word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb15008-7d61-4bfd-b0e4-7126bd08951a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_per_iter = []\n",
    "copy_results = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa79dc-7214-4d32-99d0-601f732975db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 16, 12, 64])\n",
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "mean_acts_per_head = mean_acts.view(old_shape)\n",
    "print(mean_acts_per_head.shape)\n",
    "print(target_decomps[0].rels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef834df-fb0e-445a-bb34-01727ae9624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ioi_logits, ioi_cache = model.run_with_cache(ioi_dataset.toks) # run on entire dataset along batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fb521-d084-45e3-9f09-04cfc01eaec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_cache['blocks.' + '0' + '.attn.hook_z'][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ed01ca5-635f-4198-8898-4b7eeab6a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for target_decomp in target_decomps:\n",
    "    # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "    score = 0\n",
    "    for i, target_node in enumerate(target_decomp.target_nodes):\n",
    "        target_mean_act = mean_acts[target_node.layer_idx, target_node.sequence_idx, target_node.attn_head_idx]\n",
    "        target_rel = ioi_cache['blocks.' + str(target_node.layer_idx) + '.attn.hook_z'][0][target_node.sequence_idx][target_node.attn_head_idx] - target_mean_act \n",
    "        rel = target_decomp.rels[i][0]\n",
    "        #print(target_rel.shape, rel.shape)\n",
    "        score += torch.dot(rel, target_rel)\n",
    "    results.append(Result(target_decomp.ablation_set, score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a726588c-4b64-4824-9780-43a0a713b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=3) tensor(2.8631, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=9) tensor(2.5057, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=10) tensor(2.3456, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3) tensor(2.1374, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6) tensor(2.0232, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=9) tensor(1.5772, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=10) tensor(1.5526, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=10) tensor(1.4639, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9) tensor(1.2003, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=6) tensor(1.1704, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=6) tensor(1.1144, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9) tensor(0.9955, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=9) tensor(0.9087, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=3) tensor(0.9014, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=3) tensor(0.8035, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=9) tensor(0.8001, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=10) tensor(0.7452, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=3) tensor(0.6968, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=10) tensor(0.6146, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=3) tensor(0.6018, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=9) tensor(0.6002, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=3) tensor(0.5847, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=10) tensor(0.5632, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=3) tensor(0.5181, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=3) tensor(0.5171, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=9) tensor(0.5040, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=9) tensor(0.4911, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=3) tensor(0.4827, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=6) tensor(0.4606, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=9) tensor(0.4386, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=9) tensor(0.3821, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6) tensor(0.3639, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=6) tensor(0.3592, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=9) tensor(0.2922, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=3) tensor(0.2882, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=9) tensor(0.2731, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=10) tensor(0.2642, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=3) tensor(0.2243, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=3) tensor(0.2014, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10) tensor(0.1696, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=6) tensor(0.1240, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=10) tensor(0.1199, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=6) tensor(0.1156, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=6) tensor(0.1136, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=9) tensor(0.0754, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10) tensor(0.0434, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=6) tensor(0.0395, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=6) tensor(0.0146, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=9) tensor(0.0125, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10) tensor(0.0039, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=3) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=9) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=6) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=10) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=3) tensor(-0.0045, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=3) tensor(-0.0047, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=6) tensor(-0.0170, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=10) tensor(-0.0289, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=10) tensor(-0.0747, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=6) tensor(-0.0801, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=10) tensor(-0.0818, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=10) tensor(-0.1042, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=6) tensor(-0.1684, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=6) tensor(-0.9836, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "results[:50]\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "        print(result.ablation_set[0], result.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32b2b05c-eee7-4a95-aef5-126b082ec550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=9, sequence_idx=14, attn_head_idx=6), Node(layer_idx=10, sequence_idx=14, attn_head_idx=0), Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)]\n",
      "Running inputs 0 to 64 (of 2304)\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "Running inputs 192 to 256 (of 2304)\n",
      "Running inputs 256 to 320 (of 2304)\n",
      "Running inputs 320 to 384 (of 2304)\n",
      "Running inputs 384 to 448 (of 2304)\n",
      "Running inputs 448 to 512 (of 2304)\n",
      "Running inputs 512 to 576 (of 2304)\n",
      "Running inputs 576 to 640 (of 2304)\n",
      "Running inputs 640 to 704 (of 2304)\n",
      "Running inputs 704 to 768 (of 2304)\n",
      "Running inputs 768 to 832 (of 2304)\n",
      "Running inputs 832 to 896 (of 2304)\n",
      "Running inputs 896 to 960 (of 2304)\n",
      "Running inputs 960 to 1024 (of 2304)\n",
      "Running inputs 1024 to 1088 (of 2304)\n",
      "Running inputs 1088 to 1152 (of 2304)\n",
      "Running inputs 1152 to 1216 (of 2304)\n",
      "Running inputs 1216 to 1280 (of 2304)\n",
      "Running inputs 1280 to 1344 (of 2304)\n",
      "Running inputs 1344 to 1408 (of 2304)\n",
      "Running inputs 1408 to 1472 (of 2304)\n",
      "Running inputs 1472 to 1536 (of 2304)\n",
      "Running inputs 1536 to 1600 (of 2304)\n",
      "Running inputs 1600 to 1664 (of 2304)\n",
      "Running inputs 1664 to 1728 (of 2304)\n",
      "Running inputs 1728 to 1792 (of 2304)\n",
      "Running inputs 1792 to 1856 (of 2304)\n",
      "Running inputs 1856 to 1920 (of 2304)\n",
      "Running inputs 1920 to 1984 (of 2304)\n",
      "Running inputs 1984 to 2048 (of 2304)\n",
      "Running inputs 2048 to 2112 (of 2304)\n",
      "Running inputs 2112 to 2176 (of 2304)\n",
      "Running inputs 2176 to 2240 (of 2304)\n",
      "Running inputs 2240 to 2304 (of 2304)\n",
      "[Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=6),), score=tensor(0.6763, device='cuda:0')), Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=9),), score=tensor(0.6328, device='cuda:0')), Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=0),), score=tensor(0.6303, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=tensor(0.2121, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=tensor(0.2109, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=tensor(0.2001, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=tensor(0.1986, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=tensor(0.1894, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=8),), score=tensor(0.1869, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=6),), score=tensor(0.1862, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=11),), score=tensor(0.1819, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=5),), score=tensor(0.1757, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=2),), score=tensor(0.1750, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=8),), score=tensor(0.1750, device='cuda:0')), Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=3),), score=tensor(0.1749, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "# Now, find maximally relevant source nodes to target nodes\n",
    "\n",
    "# TODO: this needs to be put in a loop to implement the \"actual\" algorithm, currently it's just for analysis\n",
    "# results.sort(key=operator.attrgetter('score'), reverse=False)|\n",
    "# iqr = interquartile_range(results)\n",
    "# print(len(iqr))\n",
    "# outliers = n_sigma_rule(results, n=0.5)\n",
    "# print(len(outliers))\n",
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = copy_results[:3] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(16)],\n",
    "        # [ioi_dataset.word_idx['IO'][0]],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)\n",
    "\n",
    "results = []\n",
    "for target_decomp in target_decomps:\n",
    "    # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "    score = 0\n",
    "    for i in range(len(target_decomp.target_nodes)):\n",
    "        rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "        irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "        target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "        score += target_node_score\n",
    "    results.append(Result(target_decomp.ablation_set, score))\n",
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "print(results[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12f080c6-73e5-4833-9290-2919faa090be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9) tensor(0.0242, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=9) tensor(0.0228, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=10) tensor(0.0218, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3) tensor(0.0216, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6) tensor(0.0204, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9) tensor(0.0197, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=6) tensor(0.0185, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10) tensor(0.0180, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10) tensor(0.0179, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6) tensor(0.0177, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=3) tensor(0.0171, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=9) tensor(0.0163, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=9) tensor(0.0146, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=3) tensor(0.0145, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=3) tensor(0.0134, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=3) tensor(0.0126, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=3) tensor(0.0121, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=10) tensor(0.0118, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=9) tensor(0.0109, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=9) tensor(0.0108, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=3) tensor(0.0108, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=6) tensor(0.0108, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=3) tensor(0.0101, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=3) tensor(0.0100, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=10) tensor(0.0099, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=10) tensor(0.0097, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=10) tensor(0.0095, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=10) tensor(0.0090, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=9) tensor(0.0086, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=6) tensor(0.0082, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=9) tensor(0.0078, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=10) tensor(0.0076, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=6) tensor(0.0075, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=6) tensor(0.0075, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=10) tensor(0.0068, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=9) tensor(0.0068, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=6) tensor(0.0066, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=9) tensor(0.0064, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=3) tensor(0.0064, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=10) tensor(0.0061, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=3) tensor(0.0060, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=6) tensor(0.0060, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=3) tensor(0.0059, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=9) tensor(0.0057, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=10) tensor(0.0054, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=6) tensor(0.0049, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=10) tensor(0.0048, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=9) tensor(0.0039, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=6) tensor(0.0039, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=3) tensor(0.0038, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=3) tensor(0.0037, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=9) tensor(0.0036, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=6) tensor(0.0027, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=6) tensor(0.0025, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=3) tensor(0.0018, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=9) tensor(0.0018, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10) tensor(0.0011, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=6) tensor(0.0008, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=10) tensor(0.0002, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=6) tensor(0.0002, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=3) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=9) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=6) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=10) tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for result in results[:20]:\n",
    "    print(result)\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "        print(result.ablation_set[0], result.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6be8110d-0ca1-4de2-bffc-3c2a71550ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Then', ',', ' Samantha', ' and', ' Laura', ' went', ' to', ' the', ' school', '.', ' Samantha', ' gave', ' a', ' computer', ' to']\n"
     ]
    }
   ],
   "source": [
    "tokens = ioi_dataset.tokenized_prompts[0].split('|')[:-1]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f99ab90-2247-440a-acfc-3bcc76829de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score.item() if hasattr(result.score, 'item') else result.score for result in results]\n",
    "#print(scores)\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5844ed6-042c-4dcb-a535-d177f25f417f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    }
   ],
   "source": [
    "b_scores = [s for s in scores if s > 0.01]\n",
    "print(len(b_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5baef4b-3ea1-4131-85a2-396d544d5ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=0, sequence_idx=0, attn_head_idx=10), Node(layer_idx=0, sequence_idx=0, attn_head_idx=1), Node(layer_idx=0, sequence_idx=0, attn_head_idx=0), Node(layer_idx=0, sequence_idx=0, attn_head_idx=7), Node(layer_idx=0, sequence_idx=0, attn_head_idx=3), Node(layer_idx=0, sequence_idx=0, attn_head_idx=9)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"TargetNodeDecompositionList\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[0;32m---> 18\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:427\u001b[0m, in \u001b[0;36mbatch_run\u001b[0;34m(prop_model_fn, ablation_list, num_at_time, n_layers)\u001b[0m\n\u001b[1;32m    424\u001b[0m     batch_out_decomps, batch_target_decomps, _, _ \u001b[38;5;241m=\u001b[39m prop_model_fn(ablation_list[b_st: b_end])\n\u001b[1;32m    426\u001b[0m     out_decomps \u001b[38;5;241m=\u001b[39m out_decomps \u001b[38;5;241m+\u001b[39m batch_out_decomps\n\u001b[0;32m--> 427\u001b[0m     target_decomps \u001b[38;5;241m=\u001b[39m [\u001b[43mtarget_decomps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_target_decomps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)]\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_decomps, target_decomps\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"TargetNodeDecompositionList\") to list"
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = results[:6] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2bf915a-9f08-46b7-b5ef-1cb1e3a7857b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(target_decomps))\n",
    "print((abs(target_decomps[0].rels[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18167b58-cf91-4d50-bbb8-42983d510a43",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## New algorithm (fixed number of nodes per layer, weight relevance to the nodes according to the nodes' relevance in the previous iter, take nodes with highest absolute scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131aae5-b946-4acc-aebf-1e769116f9e9",
   "metadata": {},
   "source": [
    "There are two problems with this algorithm generally:\n",
    "\n",
    "1. The \"relevance to logits\" score isn't on the same scale as \"relevance to target nodes\" score, so there's no principled way to decide whether nodes in the last layer are more or less relevant than others.\n",
    "\n",
    "2. More fatally, the most important nodes converge to position 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2ff3c0a-5464-4075-a40f-a110bef9da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [11],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)\n",
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = io_logit - s_logit\n",
    "assert(full_score > 0)\n",
    "\n",
    "last_layer_results = []\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    last_layer_results.append(Result(decomp.ablation_set, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc619414-6852-435a-b884-2c0a5692e3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=6),), score=0.0623091),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=2),), score=0.049144655),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.04818679),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=7),), score=0.04440797),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=11),), score=0.0425904)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "last_layer_results[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8c7d26c-c213-4968-9784-f2c4ead35791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 10: \n",
      "new target nodes:\n",
      "[Node(layer_idx=11, sequence_idx=14, attn_head_idx=0), Node(layer_idx=11, sequence_idx=14, attn_head_idx=6), Node(layer_idx=11, sequence_idx=14, attn_head_idx=2), Node(layer_idx=11, sequence_idx=14, attn_head_idx=3), Node(layer_idx=11, sequence_idx=14, attn_head_idx=7), Node(layer_idx=11, sequence_idx=14, attn_head_idx=11)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 9: \n",
      "new target nodes:\n",
      "[Node(layer_idx=10, sequence_idx=9, attn_head_idx=0), Node(layer_idx=10, sequence_idx=9, attn_head_idx=6), Node(layer_idx=10, sequence_idx=9, attn_head_idx=10), Node(layer_idx=10, sequence_idx=9, attn_head_idx=7), Node(layer_idx=10, sequence_idx=9, attn_head_idx=1), Node(layer_idx=10, sequence_idx=9, attn_head_idx=2)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 8: \n",
      "new target nodes:\n",
      "[Node(layer_idx=9, sequence_idx=2, attn_head_idx=0), Node(layer_idx=9, sequence_idx=2, attn_head_idx=8), Node(layer_idx=9, sequence_idx=2, attn_head_idx=2), Node(layer_idx=9, sequence_idx=2, attn_head_idx=5), Node(layer_idx=9, sequence_idx=4, attn_head_idx=8), Node(layer_idx=9, sequence_idx=4, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 7: \n",
      "new target nodes:\n",
      "[Node(layer_idx=8, sequence_idx=2, attn_head_idx=2), Node(layer_idx=8, sequence_idx=2, attn_head_idx=11), Node(layer_idx=8, sequence_idx=2, attn_head_idx=4), Node(layer_idx=8, sequence_idx=2, attn_head_idx=9), Node(layer_idx=8, sequence_idx=2, attn_head_idx=8), Node(layer_idx=8, sequence_idx=2, attn_head_idx=10)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 6: \n",
      "new target nodes:\n",
      "[Node(layer_idx=7, sequence_idx=2, attn_head_idx=5), Node(layer_idx=7, sequence_idx=2, attn_head_idx=6), Node(layer_idx=7, sequence_idx=2, attn_head_idx=1), Node(layer_idx=7, sequence_idx=2, attn_head_idx=4), Node(layer_idx=7, sequence_idx=2, attn_head_idx=3), Node(layer_idx=7, sequence_idx=2, attn_head_idx=9)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 5: \n",
      "new target nodes:\n",
      "[Node(layer_idx=6, sequence_idx=2, attn_head_idx=4), Node(layer_idx=6, sequence_idx=2, attn_head_idx=6), Node(layer_idx=6, sequence_idx=2, attn_head_idx=7), Node(layer_idx=6, sequence_idx=2, attn_head_idx=0), Node(layer_idx=6, sequence_idx=2, attn_head_idx=5), Node(layer_idx=6, sequence_idx=2, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 4: \n",
      "new target nodes:\n",
      "[Node(layer_idx=5, sequence_idx=2, attn_head_idx=10), Node(layer_idx=5, sequence_idx=2, attn_head_idx=2), Node(layer_idx=5, sequence_idx=2, attn_head_idx=11), Node(layer_idx=5, sequence_idx=2, attn_head_idx=9), Node(layer_idx=5, sequence_idx=2, attn_head_idx=7), Node(layer_idx=5, sequence_idx=2, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 3: \n",
      "new target nodes:\n",
      "[Node(layer_idx=4, sequence_idx=2, attn_head_idx=4), Node(layer_idx=4, sequence_idx=2, attn_head_idx=3), Node(layer_idx=4, sequence_idx=2, attn_head_idx=7), Node(layer_idx=4, sequence_idx=2, attn_head_idx=5), Node(layer_idx=4, sequence_idx=2, attn_head_idx=8), Node(layer_idx=4, sequence_idx=2, attn_head_idx=6)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 2: \n",
      "new target nodes:\n",
      "[Node(layer_idx=3, sequence_idx=2, attn_head_idx=6), Node(layer_idx=3, sequence_idx=2, attn_head_idx=10), Node(layer_idx=3, sequence_idx=2, attn_head_idx=5), Node(layer_idx=3, sequence_idx=2, attn_head_idx=7), Node(layer_idx=3, sequence_idx=2, attn_head_idx=2), Node(layer_idx=3, sequence_idx=2, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 1: \n",
      "new target nodes:\n",
      "[Node(layer_idx=2, sequence_idx=2, attn_head_idx=1), Node(layer_idx=2, sequence_idx=2, attn_head_idx=9), Node(layer_idx=2, sequence_idx=2, attn_head_idx=7), Node(layer_idx=2, sequence_idx=2, attn_head_idx=0), Node(layer_idx=2, sequence_idx=2, attn_head_idx=10), Node(layer_idx=2, sequence_idx=2, attn_head_idx=2)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 0: \n",
      "new target nodes:\n",
      "[Node(layer_idx=1, sequence_idx=2, attn_head_idx=11), Node(layer_idx=1, sequence_idx=2, attn_head_idx=10), Node(layer_idx=1, sequence_idx=2, attn_head_idx=7), Node(layer_idx=1, sequence_idx=2, attn_head_idx=0), Node(layer_idx=1, sequence_idx=2, attn_head_idx=6), Node(layer_idx=1, sequence_idx=2, attn_head_idx=5)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = last_layer_results[:6] # hardcoded first few N\n",
    "outliers_per_iter = [outliers]\n",
    "node_weights = [r.score for r in outliers]\n",
    "\n",
    "for layer in range(10, -1, -1):\n",
    "    target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "    sum_scores = sum([r.score for r in outliers])\n",
    "    node_weights = [r.score / sum_scores for r in outliers]\n",
    "    print(\"layer %d: \" % layer)\n",
    "    print(\"new target nodes:\")\n",
    "    print(target_nodes)\n",
    "    ranges = [\n",
    "            [layer],\n",
    "            [sequence_position for sequence_position in range(input_shape[1])],\n",
    "            [attention_head_idx for attention_head_idx in range(12)]\n",
    "        ]\n",
    "\n",
    "    source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "    ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "    prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "    _, target_decomps = batch_run(prop_fn, ablation_sets) # why does this run so slowly? is it because moving target decomps is slow or something?\n",
    "\n",
    "    results = []\n",
    "    for target_decomp in target_decomps:\n",
    "        # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "        score = 0\n",
    "        for i in range(len(target_decomp.target_nodes)):\n",
    "            weight = node_weights[i]\n",
    "            rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "            irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "            target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "            score += (target_node_score * weight)\n",
    "        results.append(Result(target_decomp.ablation_set, score))\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    outliers = results[:6] # hardcoded first few N\n",
    "    outliers_per_iter.append(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2e64cd0-7877-420b-9eed-35f9e722eb98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064)\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# for outs in outliers_per_iter:\n",
    "#     print([r.score for r in outs])\n",
    "\n",
    "all_outliers = sum(outliers_per_iter, [])\n",
    "print(all_outliers[0])\n",
    "print(len(all_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80475254-fedc-445a-b251-7ee50dd82df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=tensor(0.0721, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=tensor(0.0670, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=6),), score=0.0623091)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=tensor(0.0588, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=tensor(0.0584, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=2),), score=0.049144655)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.04818679)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=7),), score=0.04440797)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=11),), score=0.0425904)\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=0),), score=tensor(0.0415, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0404, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0392, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=1),), score=tensor(0.0357, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=9),), score=tensor(0.0308, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=6),), score=tensor(0.0284, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=2),), score=tensor(0.0275, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=6),), score=tensor(0.0267, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0266, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0266, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=10),), score=tensor(0.0258, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=4),), score=tensor(0.0251, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0249, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=7),), score=tensor(0.0249, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0236, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "all_outliers.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "for x in range(25):\n",
    "    print(all_outliers[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
