{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61a0720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a120102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for if we're trying to execute on a remote JupyterHub, where the pwd is set to the server root, or else I think pwd is set correctly already.\n",
    "# %cd CD_Circuit/\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# CD-T Imports\n",
    "import math\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson, combine_token_attn, compute_word_intervals, compare_same\n",
    "from pyfunctions.pathology import extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from pyfunctions.wrappers import Node, AblationSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651660-7f59-4b59-a574-afecc52dc306",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model\n",
    "\n",
    "Note: Unlike with the BERT model + medical dataset objective, it is not necessary to pretrain GPT-2 to perform the IOI dataset.\n",
    "GPT-2-small is already capable of performing IOI; that's part of the point of the Mech Interp in the Wild paper.\n",
    "We only need to examine how it does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a520f760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "# Model code adapted from Callum McDougall's notebook for ARENA on reproducing the IOI paper using TransformerLens.\n",
    "# This makes some sense, since EasyTransformer, the repo/lib released by the IOI guys, was forked from TransformerLens.\n",
    "# In fact, this makes the reproduction a little bit more faithful, since they most likely do certain things such as \n",
    "# \"folding\" LayerNorms to improve their interpretability results, and we are able to do the same by using TransformerLens.\n",
    "# HuggingFace, by contrast, has the most impenetrable docs and tons of outdated APIs and etc.; even their source \n",
    "# code is impossible to traverse, and I gave up on it, thankfully quickly.\n",
    "\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",\n",
    "                                          center_unembed=True,\n",
    "                                          center_writing_weights=True,\n",
    "                                          fold_ln=False,\n",
    "                                          refactor_factored_attn_matrices=True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffd4d3-5e8f-4587-bb2a-f06b61918c09",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Generate mean activations\n",
    "\n",
    "This is not as simple as it sounds; for the IOI paper, for each individual input following a template, they ablate using the mean activations of the \"ABC\" dataset, generated over sentences following the same template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab88048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 22:28:04.347444: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 22:28:05.885720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "\n",
    "# Generate a dataset all consisting of one template, randomly chosen.\n",
    "# nb_templates = 2 due to some logic internal to IOIDataset:\n",
    "# essentially, the nouns can be an ABBA or ABAB order and that counts as separate templates.\n",
    "ioi_dataset = IOIDataset(prompt_type=\"mixed\", N=3, tokenizer=model.tokenizer, prepend_bos=False, nb_templates=2)\n",
    "\n",
    "# This is the P_ABC that is mentioned in the IOI paper, which we use for mean ablation.\n",
    "# Importantly, passing in prompt_type=\"ABC\" or similar is NOT the same thing as this.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "\n",
    "logits, cache = model.run_with_cache(abc_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "attention_outputs = [cache['blocks.' + str(i) + '.hook_attn_out'] for i in range(12)]\n",
    "attention_outputs = torch.stack(attention_outputs, dim=1) # now batch, head, seq, d_model\n",
    "mean_acts = torch.mean(attention_outputs, dim=0)\n",
    "mean_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c32de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# source_list = [Node(0, 0, 0), Node(1, 1, 1)]\n",
    "# target_nodes = [(7, 0, 1)]\n",
    "\n",
    "text = ioi_dataset.sentences[0]\n",
    "encoding = model.tokenizer.encode_plus(text, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "# out_decomps, target_decomps, _ = prop_GPT(encoding_idxs, extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964cc25",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Note it is possible to do the analysis \"batchwise\" by just taking the mean of the relevance scores (at time of writing, this detail isn't in the paper, I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4c809f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[-1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = [Node(7, 0, 1)]\n",
    "# target_nodes = []\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run_new(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3cbdd4d-c39e-49d0-8a25-1aadb7609e09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out_decomps)\n",
    "len(out_decomps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de1255a-a9b3-4e65-9a0c-e525d952d4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "TargetNodeDecompositionList(ablation_set=(Node(layer_idx=0, sequence_idx=0, attn_head_idx=1),), target_nodes=[Node(layer_idx=7, sequence_idx=0, attn_head_idx=1)], rels=[tensor([[-4.3728e-03, -1.6879e-02,  1.1377e-02, -3.7736e-02, -2.7680e-03,\n",
      "          1.1830e-02,  2.0415e-02,  4.0660e-02, -6.1969e-02,  1.8279e-02,\n",
      "          5.5179e-04,  1.1143e-02,  1.8905e-03, -2.2309e-02,  2.4620e-03,\n",
      "          2.1823e-04, -4.6860e-03,  6.2320e-03, -6.7943e-02,  3.4332e-02,\n",
      "         -3.0563e-04, -2.8815e-02, -8.9610e-02,  2.0992e-03, -3.9716e-04,\n",
      "         -5.4938e-02, -9.6853e-03, -5.2798e-02,  4.2523e-03,  1.8252e-02,\n",
      "         -8.6224e-02, -3.7990e-02, -2.7555e-01, -1.0652e-03, -1.6171e-02,\n",
      "          1.4562e-03, -5.9614e-02, -1.2768e-02, -2.3432e-03, -5.1467e-02,\n",
      "         -3.3579e-02, -1.5798e-02,  7.3193e-03,  9.6150e-03,  3.4743e-02,\n",
      "          2.2641e-02, -3.3099e-02, -8.5741e-02, -1.2671e-02, -9.1949e-02,\n",
      "          3.2753e-03, -1.5646e-02, -1.3717e-04,  1.7307e-02, -4.5927e-02,\n",
      "         -5.8500e-02, -1.6003e-02,  2.9326e-02,  1.8672e-02, -4.9746e-03,\n",
      "          1.3486e-02, -1.2064e-02, -6.1047e-03, -6.2086e-03]], device='cuda:0')], irrels=[tensor([[-0.0982, -0.0358,  0.2599, -0.0104, -0.0072, -0.0943, -0.1382, -0.0040,\n",
      "         -0.1290,  0.2117,  0.0557,  0.1027, -0.1556, -0.1201,  0.2040, -0.0929,\n",
      "         -0.0325, -0.2357, -0.0739,  0.0234, -0.0034,  0.0668, -0.2100,  0.0089,\n",
      "         -0.0027,  0.0543,  0.0985, -0.2371, -0.2041, -0.0648, -0.1314,  0.0737,\n",
      "         -0.0878, -0.1461, -0.2423,  0.2330, -0.0498,  0.2169, -0.0899, -0.1518,\n",
      "         -0.0602, -0.0552, -0.2213, -0.0193,  0.3822, -0.1647, -0.2757, -0.2788,\n",
      "         -0.1436, -0.0677,  0.0254, -0.1432, -0.1976,  0.0258, -0.1337,  0.0821,\n",
      "          0.0194, -0.0519,  0.0243, -0.0139,  0.0540, -0.1932,  0.0336, -0.1060]],\n",
      "       device='cuda:0')])\n"
     ]
    }
   ],
   "source": [
    "type(target_decomps)\n",
    "print(len(target_decomps))\n",
    "print(target_decomps[1])\n",
    "# target_decomps_0  = sum((x[0] for x in target_decomps), start=TargetNodeDecompositionList((target_nodes[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef61d-6285-4adc-af26-78c4828d8c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cad70e3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22385299 0.7221562 0.49830323\n",
      "0.2392534 0.76870185 0.52944845\n",
      "0.23667926 0.7733195 0.5366402\n",
      "0.23685014 0.7638366 0.5269865\n",
      "0.23639035 0.7733022 0.53691185\n",
      "0.22272491 0.7186734 0.4959485\n",
      "0.22582316 0.7341071 0.5082839\n",
      "0.2316314 0.7488418 0.5172104\n",
      "0.22642213 0.7246672 0.49824506\n",
      "0.23495615 0.7564904 0.52153426\n",
      "0.23141754 0.75336504 0.5219475\n",
      "0.22926027 0.75442255 0.5251623\n",
      "0.24723536 0.7557521 0.5085167\n",
      "0.25159848 0.7492246 0.49762613\n",
      "0.24483094 0.71617734 0.4713464\n",
      "0.24234149 0.70445 0.46210852\n",
      "0.24467531 0.7139339 0.46925858\n",
      "0.25080615 0.7614866 0.51068044\n",
      "0.25057125 0.73540264 0.4848314\n",
      "0.2454082 0.6988676 0.4534594\n",
      "0.24986425 0.73636264 0.4864984\n",
      "0.24615115 0.71148944 0.4653383\n",
      "0.24714243 0.72087544 0.473733\n",
      "0.25133368 0.7378857 0.48655203\n",
      "0.31205982 0.8644854 0.55242556\n",
      "0.2823128 0.8421648 0.559852\n",
      "0.31745702 0.8692186 0.55176157\n",
      "0.33402258 0.9390005 0.6049779\n",
      "0.36480993 0.9478487 0.58303875\n",
      "0.31658602 0.89182043 0.5752344\n",
      "0.306787 0.854296 0.547509\n",
      "0.30229092 0.85053474 0.5482438\n",
      "0.32479596 0.8874176 0.56262165\n",
      "0.30583423 0.85312074 0.5472865\n",
      "0.31911945 0.8983013 0.57918185\n",
      "0.30917937 0.871604 0.56242466\n",
      "0.19223976 0.6572538 0.46501404\n",
      "0.19207954 0.66224176 0.4701622\n",
      "0.19507053 0.66480356 0.46973303\n",
      "0.19520697 0.6730247 0.47781774\n",
      "0.191488 0.6850979 0.49360988\n",
      "0.19740775 0.6793784 0.48197064\n",
      "0.1913042 0.65656286 0.46525866\n",
      "0.19529119 0.6711668 0.4758756\n",
      "0.19275665 0.6709714 0.47821474\n",
      "0.19594714 0.6647539 0.46880677\n",
      "0.19465047 0.65162885 0.45697838\n",
      "0.19552073 0.68503577 0.48951504\n",
      "0.15730724 0.6572021 0.4998949\n",
      "0.15634376 0.6524096 0.49606586\n",
      "0.14716142 0.6586301 0.51146865\n",
      "0.15440911 0.67283916 0.51843005\n",
      "0.1622875 0.65937304 0.49708554\n",
      "0.13978595 0.6828908 0.5431048\n",
      "0.14661103 0.65434915 0.5077381\n",
      "0.16272327 0.6342991 0.47157583\n",
      "0.14735734 0.62904316 0.48168582\n",
      "0.16471496 0.64268976 0.4779748\n",
      "0.16445988 0.6297006 0.46524072\n",
      "0.15812033 0.62903965 0.4709193\n",
      "0.2188791 0.5781878 0.35930872\n",
      "0.21649817 0.5660931 0.34959492\n",
      "0.22188821 0.5758005 0.35391226\n",
      "0.2131714 0.57593983 0.36276844\n",
      "0.2220341 0.5761242 0.3540901\n",
      "0.20326418 0.5515093 0.34824514\n",
      "0.21363005 0.5731001 0.35947004\n",
      "0.2115671 0.5675609 0.3559938\n",
      "0.21249542 0.5721725 0.3596771\n",
      "0.21471816 0.5717171 0.35699892\n",
      "0.2232104 0.58557963 0.36236924\n",
      "0.21314701 0.5717561 0.3586091\n",
      "0.20647576 0.56121564 0.35473987\n",
      "0.20873442 0.56027925 0.35154483\n",
      "0.21069196 0.5671263 0.35643432\n",
      "0.20709258 0.556355 0.34926242\n",
      "0.22278261 0.59512556 0.37234294\n",
      "0.20943269 0.56527996 0.35584727\n",
      "0.20376557 0.54919803 0.34543246\n",
      "0.209247 0.5584499 0.34920293\n",
      "0.21182135 0.5727948 0.36097345\n",
      "0.20843092 0.5626003 0.3541694\n",
      "0.20695502 0.5584817 0.35152668\n",
      "0.20576376 0.5587088 0.35294503\n",
      "0.2090472 0.5475485 0.33850127\n",
      "0.21280959 0.55752677 0.34471717\n",
      "0.21243873 0.54784364 0.3354049\n",
      "0.20525032 0.5442627 0.33901238\n",
      "0.21085128 0.5485129 0.3376616\n",
      "0.20637801 0.54096586 0.33458784\n",
      "0.2096616 0.5459059 0.3362443\n",
      "0.20923251 0.5449664 0.3357339\n",
      "0.21380138 0.55530643 0.34150505\n",
      "0.20998946 0.5486097 0.33862022\n",
      "0.20994961 0.5513605 0.34141088\n",
      "0.21028918 0.54753727 0.3372481\n",
      "0.21598428 0.572468 0.3564837\n",
      "0.21264741 0.56481844 0.35217103\n",
      "0.24094573 0.6148464 0.37390068\n",
      "0.22276199 0.5697886 0.3470266\n",
      "0.22388911 0.5822665 0.3583774\n",
      "0.2335366 0.6047273 0.37119073\n",
      "0.23177928 0.6160804 0.38430113\n",
      "0.22078934 0.5820988 0.36130944\n",
      "0.23131037 0.59593827 0.3646279\n",
      "0.22589514 0.5868284 0.36093327\n",
      "0.22777602 0.592003 0.36422697\n",
      "0.23466086 0.61932236 0.3846615\n",
      "0.20547503 0.5621501 0.3566751\n",
      "0.21164593 0.5801307 0.36848477\n",
      "0.19906962 0.5447164 0.3456468\n",
      "0.19005659 0.5334565 0.3433999\n",
      "0.21420383 0.5734749 0.35927105\n",
      "0.1924937 0.538514 0.3460203\n",
      "0.19334012 0.5372423 0.34390217\n",
      "0.20737413 0.56276244 0.3553883\n",
      "0.22058111 0.59018123 0.36960012\n",
      "0.21143338 0.5666148 0.35518143\n",
      "0.19945717 0.56118387 0.3617267\n",
      "0.19789132 0.5499259 0.3520346\n",
      "0.19711351 0.5372832 0.34016967\n",
      "0.19685432 0.5349842 0.33812985\n",
      "0.20178255 0.5547531 0.35297057\n",
      "0.20787108 0.5520849 0.34421384\n",
      "0.20995325 0.5606377 0.35068446\n",
      "0.19683325 0.5539077 0.35707444\n",
      "0.21250257 0.5572104 0.34470782\n",
      "0.19995189 0.5375462 0.33759433\n",
      "0.19666153 0.54059774 0.3439362\n",
      "0.19877315 0.5366718 0.33789867\n",
      "0.19088095 0.52092004 0.33003908\n",
      "0.19464758 0.5270457 0.33239815\n",
      "0.21688297 0.55773145 0.34084848\n",
      "0.20653212 0.53266054 0.32612842\n",
      "0.22448945 0.5677557 0.34326625\n",
      "0.2084736 0.53648084 0.32800725\n",
      "0.19821173 0.51301384 0.3148021\n",
      "0.21287021 0.54783344 0.33496323\n",
      "0.21406019 0.54949534 0.33543515\n",
      "0.18948686 0.4994488 0.30996194\n",
      "0.19666937 0.5130321 0.3163627\n",
      "0.21552074 0.55256724 0.3370465\n",
      "0.2156829 0.5486792 0.33299628\n",
      "0.20448133 0.5330739 0.32859257\n",
      "0.18158683 0.45940027 0.27781343\n",
      "0.19025001 0.46877122 0.2785212\n",
      "0.1866844 0.47030777 0.28362337\n",
      "0.18343076 0.45448288 0.27105212\n",
      "0.18575737 0.46501604 0.27925867\n",
      "0.17898753 0.45609242 0.27710488\n",
      "0.1787622 0.44270796 0.26394576\n",
      "0.18600357 0.46272856 0.276725\n",
      "0.18331549 0.4596589 0.2763434\n",
      "0.18083665 0.45229056 0.27145392\n",
      "0.18302691 0.46434247 0.28131557\n",
      "0.18413031 0.46233964 0.27820933\n",
      "0.18564835 0.53994894 0.3543006\n",
      "0.1898264 0.51006484 0.32023844\n",
      "0.187437 0.53253317 0.34509617\n",
      "0.1760548 0.49888685 0.32283205\n",
      "0.21074608 0.5308736 0.32012752\n",
      "0.18009612 0.50319695 0.32310084\n",
      "0.19455779 0.51374304 0.31918526\n",
      "0.19110006 0.49962586 0.3085258\n",
      "0.20105872 0.55509835 0.35403964\n",
      "0.18512961 0.50320095 0.31807134\n",
      "0.19599137 0.5336513 0.33765993\n",
      "0.1778928 0.48317856 0.30528575\n",
      "0.18877387 0.47120243 0.28242856\n",
      "0.18709564 0.46702874 0.2799331\n",
      "0.2000229 0.49673116 0.29670826\n",
      "0.1958622 0.4834058 0.2875436\n",
      "0.19087583 0.47170657 0.28083074\n",
      "0.19274431 0.48329958 0.29055527\n",
      "0.19347501 0.48196062 0.28848562\n",
      "0.19136256 0.4841209 0.29275835\n",
      "0.1968315 0.48433158 0.28750008\n",
      "0.19138077 0.4677278 0.27634704\n",
      "0.19446638 0.48548853 0.29102215\n",
      "0.19461757 0.47707623 0.28245866\n",
      "0.2098199 0.44659525 0.23677535\n",
      "0.24582924 0.4853826 0.23955335\n",
      "0.24231327 0.50246525 0.26015198\n",
      "0.26724836 0.5855621 0.31831375\n",
      "0.29201683 0.6025619 0.31054506\n",
      "0.24534294 0.5328317 0.2874888\n",
      "0.20622388 0.4639381 0.2577142\n",
      "0.2234008 0.47926244 0.25586164\n",
      "0.19914225 0.5186502 0.31950793\n",
      "0.2404458 0.52274495 0.28229916\n",
      "0.23991758 0.51835525 0.27843767\n",
      "0.19899091 0.47526568 0.27627477\n",
      "0.17574939 0.5017484 0.325999\n",
      "0.18227091 0.4756906 0.2934197\n",
      "0.18078989 0.46860123 0.28781134\n",
      "0.17589888 0.5064946 0.3305957\n",
      "0.1790761 0.48668638 0.30761027\n",
      "0.17804709 0.46783406 0.28978696\n",
      "0.19022399 0.5107971 0.3205731\n",
      "0.17225128 0.49421218 0.3219609\n",
      "0.18516985 0.49632 0.31115016\n",
      "0.18532676 0.48734266 0.3020159\n",
      "0.18454361 0.48681217 0.30226856\n",
      "0.17792088 0.49149087 0.31357\n",
      "0.20051998 0.5035705 0.30305052\n",
      "0.18987426 0.47202852 0.28215426\n",
      "0.20802099 0.49926025 0.29123926\n",
      "0.19831309 0.49220636 0.29389328\n",
      "0.16798934 0.4396795 0.27169016\n",
      "0.19668448 0.5154028 0.3187183\n",
      "0.18316123 0.47376272 0.2906015\n",
      "0.17080903 0.45525783 0.2844488\n",
      "0.18232298 0.464127 0.28180403\n",
      "0.19923583 0.5237107 0.3244749\n",
      "0.19176567 0.46940604 0.27764037\n",
      "0.19774443 0.49701458 0.29927015\n",
      "0.23437265 0.6392685 0.40489587\n",
      "0.23327535 0.6401477 0.40687233\n",
      "0.22746643 0.56663686 0.33917043\n",
      "0.2350249 0.6413401 0.40631518\n",
      "0.23231393 0.63952065 0.4072067\n",
      "0.22605112 0.5753411 0.34928998\n",
      "0.22568938 0.5722778 0.3465884\n",
      "0.22474489 0.56755775 0.34281287\n",
      "0.22951084 0.63200915 0.4024983\n",
      "0.2290779 0.6336802 0.40460232\n",
      "0.2432884 0.6643131 0.42102468\n",
      "0.23473188 0.6347159 0.39998403\n",
      "0.16987437 0.51129574 0.34142137\n",
      "0.17776781 0.5075588 0.329791\n",
      "0.17581761 0.5181377 0.34232008\n",
      "0.17303869 0.50294954 0.32991084\n",
      "0.16785777 0.50340235 0.3355446\n",
      "0.17498296 0.5174288 0.34244585\n",
      "0.17393565 0.51582724 0.3418916\n",
      "0.16501689 0.5043179 0.339301\n",
      "0.16928452 0.49092674 0.32164222\n",
      "0.17088065 0.50309426 0.3322136\n",
      "0.171621 0.51035106 0.33873007\n",
      "0.17168769 0.49641302 0.32472533\n",
      "0.15135846 0.46778202 0.31642357\n",
      "0.15015611 0.46502885 0.31487274\n",
      "0.15268862 0.47331527 0.32062665\n",
      "0.15593007 0.4738121 0.31788203\n",
      "0.15591013 0.4730353 0.31712517\n",
      "0.1513243 0.45714942 0.3058251\n",
      "0.14887929 0.46477857 0.31589928\n",
      "0.15363017 0.46552762 0.31189746\n",
      "0.15138248 0.4742488 0.32286632\n",
      "0.15269059 0.4709681 0.3182775\n",
      "0.15064421 0.4642097 0.3135655\n",
      "0.1562624 0.47057658 0.3143142\n",
      "0.18391111 0.4569127 0.27300158\n",
      "0.18386546 0.46071145 0.276846\n",
      "0.18816486 0.4427757 0.25461084\n",
      "0.18353799 0.45592132 0.27238333\n",
      "0.18547323 0.44928303 0.2638098\n",
      "0.18288854 0.45479447 0.27190593\n",
      "0.18472457 0.45931214 0.27458757\n",
      "0.18534288 0.45842084 0.27307796\n",
      "0.18175092 0.45361742 0.2718665\n",
      "0.18822742 0.4491394 0.26091197\n",
      "0.18256158 0.44219202 0.25963044\n",
      "0.18219161 0.45185202 0.2696604\n",
      "0.17188296 0.44846272 0.27657977\n",
      "0.17639068 0.4403187 0.26392803\n",
      "0.176287 0.456568 0.280281\n",
      "0.17902422 0.4456003 0.26657608\n",
      "0.17444322 0.43087387 0.25643066\n",
      "0.17023823 0.43142924 0.261191\n",
      "0.18041751 0.4272851 0.2468676\n",
      "0.17980656 0.4508987 0.27109215\n",
      "0.17506462 0.44310325 0.26803863\n",
      "0.17555147 0.44212964 0.26657817\n",
      "0.173184 0.42406648 0.25088248\n",
      "0.17826352 0.44562468 0.26736116\n",
      "0.18881127 0.4398702 0.25105894\n",
      "0.18059146 0.4366188 0.25602734\n",
      "0.18282437 0.43894616 0.25612178\n",
      "0.1819031 0.43760163 0.25569853\n",
      "0.18326691 0.42577168 0.24250478\n",
      "0.1831145 0.43777582 0.25466132\n",
      "0.18674806 0.4398124 0.25306433\n",
      "0.18431707 0.43334615 0.24902909\n",
      "0.18212539 0.43908525 0.25695986\n",
      "0.17929208 0.43018383 0.25089175\n",
      "0.18100268 0.43390235 0.25289968\n",
      "0.18276712 0.43333524 0.25056812\n",
      "0.18556911 0.44255942 0.2569903\n",
      "0.17740461 0.44436744 0.26696283\n",
      "0.18323824 0.4496025 0.26636428\n",
      "0.19251353 0.45199123 0.2594777\n",
      "0.19031769 0.44993606 0.25961837\n",
      "0.17470676 0.4445847 0.26987794\n",
      "0.18461525 0.44401047 0.2593952\n",
      "0.187693 0.44422144 0.25652844\n",
      "0.18365318 0.4374659 0.25381273\n",
      "0.19156177 0.43682498 0.2452632\n",
      "0.18425095 0.4429735 0.25872254\n",
      "0.18670014 0.45211637 0.26541623\n",
      "0.16797873 0.44800052 0.2800218\n",
      "0.16631702 0.4249994 0.25868237\n",
      "0.16565585 0.4293751 0.26371926\n",
      "0.16966978 0.4277446 0.25807482\n",
      "0.16940144 0.43525088 0.26584944\n",
      "0.16908017 0.44319916 0.274119\n",
      "0.16371164 0.43522736 0.27151573\n",
      "0.17370802 0.44253543 0.2688274\n",
      "0.15826651 0.42305073 0.26478422\n",
      "0.16984913 0.43980125 0.26995212\n",
      "0.1641109 0.43129483 0.26718393\n",
      "0.16873482 0.4289947 0.26025987\n",
      "0.15169896 0.3947098 0.24301083\n",
      "0.15312839 0.37888268 0.22575429\n",
      "0.15379135 0.39557683 0.24178548\n",
      "0.1512904 0.38807222 0.23678182\n",
      "0.14915131 0.3839091 0.2347578\n",
      "0.1535167 0.38545293 0.23193623\n",
      "0.15034746 0.39447373 0.24412628\n",
      "0.1458349 0.38108337 0.23524848\n",
      "0.14719385 0.38213363 0.23493978\n",
      "0.14903997 0.39240578 0.24336581\n",
      "0.15070021 0.38037446 0.22967425\n",
      "0.15186231 0.38510984 0.23324753\n",
      "0.15603644 0.40959457 0.25355813\n",
      "0.15879068 0.41426256 0.2554719\n",
      "0.1571078 0.42466506 0.26755726\n",
      "0.1560224 0.39627084 0.24024844\n",
      "0.15877932 0.41916385 0.26038453\n",
      "0.1547977 0.4085449 0.2537472\n",
      "0.15810469 0.41921017 0.26110548\n",
      "0.15524012 0.40856957 0.25332946\n",
      "0.15869069 0.42038992 0.26169923\n",
      "0.1559001 0.40563238 0.24973227\n",
      "0.1572597 0.41132015 0.25406045\n",
      "0.15798932 0.41383725 0.25584793\n",
      "0.16585794 0.38188627 0.21602833\n",
      "0.16327603 0.3762366 0.21296056\n",
      "0.1627079 0.37275296 0.21004507\n",
      "0.16984119 0.37764478 0.20780359\n",
      "0.16294242 0.3772234 0.21428098\n",
      "0.16253904 0.3720304 0.20949137\n",
      "0.16871798 0.37075526 0.20203727\n",
      "0.17195436 0.37655073 0.20459637\n",
      "0.16791303 0.37604997 0.20813693\n",
      "0.16537613 0.37243003 0.2070539\n",
      "0.17056955 0.38592544 0.21535589\n",
      "0.16352506 0.38418844 0.22066338\n",
      "0.15646496 0.37850434 0.22203937\n",
      "0.1614627 0.38397512 0.22251242\n",
      "0.15838183 0.37654287 0.21816103\n",
      "0.15306076 0.37214947 0.2190887\n",
      "0.15942012 0.37681106 0.21739094\n",
      "0.15803595 0.3892678 0.23123185\n",
      "0.15622199 0.38991743 0.23369545\n",
      "0.17080542 0.39215025 0.22134483\n",
      "0.16812009 0.3924904 0.2243703\n",
      "0.1724573 0.3963937 0.2239364\n",
      "0.17245975 0.3965442 0.22408444\n",
      "0.16758397 0.3988966 0.23131263\n",
      "0.1789117 0.41290066 0.23398896\n",
      "0.16647966 0.39157355 0.22509389\n",
      "0.16174912 0.3869683 0.22521919\n",
      "0.16288497 0.3903235 0.22743852\n",
      "0.16478935 0.39292353 0.22813419\n",
      "0.15950707 0.38705552 0.22754845\n",
      "0.16314438 0.38600186 0.22285748\n",
      "0.1652891 0.3924522 0.2271631\n",
      "0.16912514 0.39590323 0.22677809\n",
      "0.16260248 0.38799772 0.22539523\n",
      "0.16165125 0.388565 0.22691375\n",
      "0.16242173 0.39151102 0.22908929\n",
      "0.15291755 0.37435415 0.2214366\n",
      "0.14342868 0.3700282 0.22659951\n",
      "0.16367692 0.36920843 0.20553151\n",
      "0.15600973 0.36834505 0.21233532\n",
      "0.15237093 0.3642902 0.21191928\n",
      "0.16740455 0.36937124 0.20196669\n",
      "0.16438241 0.36024112 0.1958587\n",
      "0.16161063 0.36690432 0.20529369\n",
      "0.15469089 0.35822588 0.20353499\n",
      "0.15744731 0.37016955 0.21272224\n",
      "0.17450705 0.3854439 0.21093684\n",
      "0.14178431 0.36235282 0.22056851\n",
      "0.10792413 0.27662885 0.16870472\n",
      "0.13699313 0.32129666 0.18430354\n",
      "0.11463173 0.3043283 0.18969657\n",
      "0.11915618 0.30519783 0.18604165\n",
      "0.11953451 0.30464536 0.18511085\n",
      "0.12811697 0.31630072 0.18818375\n",
      "0.12910311 0.32513365 0.19603054\n",
      "0.13184033 0.3381455 0.20630516\n",
      "0.1098558 0.29220194 0.18234614\n",
      "0.11482453 0.30837312 0.19354859\n",
      "0.1312084 0.33552393 0.20431553\n",
      "0.12306492 0.3074685 0.18440358\n",
      "0.14657174 0.34463066 0.19805892\n",
      "0.14638084 0.3128087 0.16642785\n",
      "0.15112618 0.3240934 0.17296723\n",
      "0.1481989 0.31670344 0.16850454\n",
      "0.14545071 0.34190416 0.19645345\n",
      "0.15004571 0.32450378 0.17445807\n",
      "0.15342915 0.33217666 0.1787475\n",
      "0.14820258 0.31760016 0.16939758\n",
      "0.15136929 0.33069277 0.17932348\n",
      "0.14847697 0.3364236 0.18794663\n",
      "0.14484265 0.3148677 0.17002505\n",
      "0.14445354 0.31373265 0.16927911\n",
      "0.20281798 0.49556527 0.2927473\n",
      "0.2100009 0.49715117 0.28715026\n",
      "0.22815952 0.54053605 0.31237653\n",
      "0.22290376 0.5028753 0.27997157\n",
      "0.21385941 0.5110872 0.29722777\n",
      "0.2109614 0.49434456 0.28338316\n",
      "0.19963917 0.48833546 0.2886963\n",
      "0.21746534 0.5064024 0.28893703\n",
      "0.19558099 0.46928036 0.27369937\n",
      "0.21178299 0.5038362 0.29205322\n",
      "0.20528013 0.50054 0.2952599\n",
      "0.20841748 0.48575923 0.27734175\n",
      "0.16463241 0.4467206 0.2820882\n",
      "0.16653201 0.44395643 0.27742442\n",
      "0.16539374 0.42969513 0.2643014\n",
      "0.17916629 0.45834827 0.279182\n",
      "0.17599458 0.45703495 0.28104037\n",
      "0.1708301 0.44424817 0.27341807\n",
      "0.16923371 0.4533978 0.2841641\n",
      "0.17055511 0.4646179 0.2940628\n",
      "0.16590664 0.42915103 0.2632444\n",
      "0.17220867 0.4471628 0.27495414\n",
      "0.16902885 0.4392542 0.27022535\n",
      "0.17425635 0.44668022 0.27242386\n",
      "0.13738981 0.35775378 0.22036397\n",
      "0.16367811 0.4109542 0.2472761\n",
      "0.14180532 0.37451315 0.23270783\n",
      "0.16583031 0.3997185 0.23388818\n",
      "0.16234004 0.40211967 0.23977962\n",
      "0.16006653 0.3906978 0.23063128\n",
      "0.14807902 0.38741007 0.23933105\n",
      "0.16554473 0.40822333 0.2426786\n",
      "0.17097841 0.40935975 0.23838134\n",
      "0.1640788 0.4084767 0.24439791\n",
      "0.15610059 0.40243527 0.24633469\n",
      "0.15203495 0.38905883 0.23702388\n",
      "0.18347493 0.39866218 0.21518725\n",
      "0.18171637 0.3934701 0.21175374\n",
      "0.18021284 0.39271158 0.21249874\n",
      "0.18597557 0.4012942 0.21531864\n",
      "0.16989438 0.3641789 0.19428451\n",
      "0.15855956 0.35162008 0.19306052\n",
      "0.18371727 0.40483814 0.22112088\n",
      "0.18139951 0.40017086 0.21877135\n",
      "0.17354168 0.3746351 0.20109342\n",
      "0.17911907 0.3998992 0.22078015\n",
      "0.17843103 0.39476526 0.21633422\n",
      "0.18513335 0.40404558 0.21891223\n",
      "0.16993266 0.37960804 0.20967537\n",
      "0.1773713 0.40226656 0.22489527\n",
      "0.17237008 0.37420356 0.20183349\n",
      "0.18207878 0.40085483 0.21877605\n",
      "0.17162344 0.3811957 0.20957226\n",
      "0.18676984 0.40181693 0.21504709\n",
      "0.16730005 0.37014812 0.20284808\n",
      "0.16953932 0.37244356 0.20290424\n",
      "0.17524426 0.39769357 0.22244932\n",
      "0.17141172 0.36814046 0.19672874\n",
      "0.17597269 0.3950768 0.21910413\n",
      "0.18069373 0.39627478 0.21558104\n",
      "0.16716664 0.36680138 0.19963475\n",
      "0.16372898 0.35740972 0.19368073\n",
      "0.1577671 0.340165 0.18239789\n",
      "0.15680976 0.34251502 0.18570526\n",
      "0.1613007 0.36249742 0.20119672\n",
      "0.16026329 0.34465343 0.18439014\n",
      "0.15747193 0.34042564 0.18295372\n",
      "0.15947145 0.3449103 0.18543884\n",
      "0.14955376 0.31926727 0.16971351\n",
      "0.16348922 0.35873565 0.19524643\n",
      "0.1481805 0.32430184 0.17612134\n",
      "0.16774294 0.3626808 0.19493786\n",
      "0.16084227 0.3471977 0.18635544\n",
      "0.15812968 0.33941576 0.18128608\n",
      "0.1541538 0.34085444 0.18670064\n",
      "0.17869727 0.39287153 0.21417426\n",
      "0.1503261 0.33780754 0.18748143\n",
      "0.14593759 0.31717157 0.17123398\n",
      "0.16136204 0.3502301 0.18886806\n",
      "0.14971107 0.32380807 0.174097\n",
      "0.16305323 0.3561329 0.19307967\n",
      "0.1590887 0.3502726 0.1911839\n",
      "0.16057967 0.34716612 0.18658645\n",
      "0.17104343 0.3730417 0.20199826\n",
      "0.16364604 0.36477876 0.20113271\n",
      "0.16939446 0.37269077 0.2032963\n",
      "0.14898741 0.3279317 0.17894429\n",
      "0.17451377 0.35817757 0.1836638\n",
      "0.16635744 0.37019014 0.2038327\n",
      "0.1711287 0.37213418 0.20100547\n",
      "0.1681905 0.37938192 0.21119143\n",
      "0.16775881 0.37632957 0.20857076\n",
      "0.16257836 0.3576188 0.19504045\n",
      "0.17192356 0.37576985 0.20384629\n",
      "0.17606105 0.37125593 0.19519489\n",
      "0.16216154 0.3653482 0.20318665\n",
      "0.16456176 0.35217392 0.18761216\n",
      "0.14816917 0.3196521 0.17148294\n",
      "0.16244014 0.3477635 0.18532337\n",
      "0.16331546 0.3634161 0.20010065\n",
      "0.15515243 0.3299289 0.17477648\n",
      "0.17109965 0.357475 0.18637536\n",
      "0.15849292 0.34530565 0.18681273\n",
      "0.16018675 0.34594852 0.18576176\n",
      "0.1693751 0.34687242 0.17749731\n",
      "0.16026568 0.34546676 0.18520108\n",
      "0.15955527 0.3452669 0.18571164\n",
      "0.1675179 0.35298306 0.18546516\n",
      "0.15066057 0.34787333 0.19721276\n",
      "0.15002091 0.33978775 0.18976684\n",
      "0.15441406 0.36036074 0.20594668\n",
      "0.16005747 0.3742028 0.21414532\n",
      "0.1549181 0.36119568 0.20627758\n",
      "0.14698735 0.33585736 0.18887001\n",
      "0.16120602 0.37064397 0.20943795\n",
      "0.15280327 0.3456826 0.19287932\n",
      "0.16476654 0.38084632 0.21607979\n",
      "0.14613335 0.33413342 0.18800007\n",
      "0.14649813 0.3518565 0.20535837\n",
      "0.15705332 0.35032046 0.19326714\n",
      "0.16956212 0.3594389 0.18987678\n",
      "0.17020018 0.3467858 0.17658563\n",
      "0.16275324 0.34150615 0.17875291\n",
      "0.1738024 0.3570914 0.18328899\n",
      "0.16437437 0.34168375 0.17730938\n",
      "0.14716196 0.31000015 0.16283819\n",
      "0.16619205 0.338539 0.17234695\n",
      "0.1704281 0.35755733 0.18712923\n",
      "0.1735089 0.35437348 0.18086459\n",
      "0.1728968 0.35412297 0.18122616\n",
      "0.16910842 0.35614476 0.18703634\n",
      "0.16307932 0.3333253 0.17024598\n",
      "0.12720047 0.32396242 0.19676195\n",
      "0.16118972 0.35674137 0.19555165\n",
      "0.15607291 0.34537426 0.18930134\n",
      "0.16182385 0.35872117 0.19689731\n",
      "0.15703554 0.35787788 0.20084234\n",
      "0.15808086 0.3363733 0.17829244\n",
      "0.15027875 0.33890235 0.1886236\n",
      "0.15750107 0.35185614 0.19435507\n",
      "0.15396412 0.33035725 0.17639314\n",
      "0.14773992 0.32089546 0.17315555\n",
      "0.16436331 0.36313638 0.19877307\n",
      "0.15665513 0.3552599 0.19860476\n",
      "0.15963152 0.37623045 0.21659893\n",
      "0.1568944 0.36741576 0.21052136\n",
      "0.16207725 0.38417765 0.2221004\n",
      "0.16190577 0.3842727 0.22236693\n",
      "0.15345249 0.3682903 0.21483782\n",
      "0.15412578 0.37087354 0.21674776\n",
      "0.1590524 0.3785558 0.2195034\n",
      "0.16096699 0.37153846 0.21057147\n",
      "0.16061173 0.37467253 0.2140608\n",
      "0.14645696 0.35801178 0.21155483\n",
      "0.16305429 0.37771088 0.21465659\n",
      "0.14846544 0.3516869 0.20322146\n",
      "0.12818807 0.33404368 0.20585561\n",
      "0.13511325 0.31984732 0.18473406\n",
      "0.15241168 0.31014913 0.15773745\n",
      "0.1506891 0.3357832 0.18509412\n",
      "0.14176999 0.32287464 0.18110465\n",
      "0.13839294 0.32347935 0.18508641\n",
      "0.13769852 0.3281346 0.19043608\n",
      "0.14531091 0.32448187 0.17917097\n",
      "0.13855211 0.3176278 0.17907567\n",
      "0.13711327 0.32976148 0.1926482\n",
      "0.15753724 0.3381702 0.18063296\n",
      "0.1335057 0.3163162 0.18281049\n",
      "0.078638576 0.19789156 0.11925299\n",
      "0.09290746 0.22132711 0.12841965\n",
      "0.07774454 0.19331378 0.115569234\n",
      "0.07908614 0.19477035 0.11568421\n",
      "0.09253328 0.21452944 0.12199616\n",
      "0.07706526 0.1917057 0.114640445\n",
      "0.071974784 0.18197277 0.10999799\n",
      "0.08008293 0.19383356 0.11375063\n",
      "0.07580621 0.18949097 0.113684766\n",
      "0.08172231 0.19807498 0.11635267\n",
      "0.078537814 0.19745354 0.11891573\n",
      "0.079091586 0.19361992 0.114528336\n",
      "0.08940309 0.21434557 0.12494248\n",
      "0.08997528 0.21462846 0.124653175\n",
      "0.09278044 0.21914528 0.12636484\n",
      "0.08277046 0.20313233 0.12036187\n",
      "0.08336451 0.20733616 0.12397165\n",
      "0.08948403 0.21196336 0.12247933\n",
      "0.07852165 0.19584934 0.1173277\n",
      "0.086448446 0.20869726 0.12224881\n",
      "0.09879506 0.23739617 0.13860111\n",
      "0.09472113 0.21926826 0.12454713\n",
      "0.08877551 0.2112674 0.12249189\n",
      "0.08364783 0.20476434 0.121116504\n",
      "0.13554686 0.30334017 0.1677933\n",
      "0.11886099 0.2909748 0.1721138\n",
      "0.13046859 0.32069856 0.19022997\n",
      "0.12630633 0.2986255 0.17231917\n",
      "0.1260145 0.31014162 0.18412712\n",
      "0.12746936 0.31344134 0.18597198\n",
      "0.12606606 0.30853492 0.18246886\n",
      "0.13011706 0.31097072 0.18085366\n",
      "0.12648816 0.30420268 0.17771451\n",
      "0.12343499 0.2992352 0.1758002\n",
      "0.12433118 0.31004292 0.18571174\n",
      "0.13281989 0.3097577 0.17693782\n",
      "0.12476851 0.32039744 0.19562893\n",
      "0.11469577 0.30330265 0.18860687\n",
      "0.12247731 0.31568334 0.19320603\n",
      "0.12465732 0.31691924 0.19226192\n",
      "0.12103872 0.3147939 0.1937552\n",
      "0.12687027 0.32571766 0.19884738\n",
      "0.118825376 0.31184667 0.1930213\n",
      "0.11775373 0.32156748 0.20381375\n",
      "0.11607388 0.302365 0.18629113\n",
      "0.121535406 0.32905868 0.20752327\n",
      "0.13061528 0.32420152 0.19358625\n",
      "0.12282708 0.32141256 0.19858548\n",
      "0.09009497 0.25786257 0.1677676\n",
      "0.0944127 0.24970312 0.15529042\n",
      "0.10505661 0.28539625 0.18033963\n",
      "0.09389663 0.25086117 0.15696454\n",
      "0.09326513 0.25518197 0.16191684\n",
      "0.094359085 0.2663393 0.17198022\n",
      "0.097791865 0.27116206 0.1733702\n",
      "0.10324353 0.2768569 0.17361337\n",
      "0.0981171 0.27199313 0.17387603\n",
      "0.09818497 0.26770064 0.16951567\n",
      "0.10258412 0.2685034 0.16591927\n",
      "0.09814957 0.2600918 0.16194224\n",
      "0.11870521 0.25666824 0.13796303\n",
      "0.115921125 0.25692633 0.1410052\n",
      "0.11621407 0.25969172 0.14347765\n",
      "0.12468052 0.26058492 0.1359044\n",
      "0.11799875 0.25864008 0.14064133\n",
      "0.12368487 0.26050165 0.13681678\n",
      "0.124179944 0.25824916 0.13406922\n",
      "0.11296922 0.25405636 0.14108714\n",
      "0.121975794 0.26305068 0.14107488\n",
      "0.12265222 0.25760126 0.13494904\n",
      "0.11783156 0.25749624 0.13966468\n",
      "0.11346525 0.2577748 0.14430955\n",
      "0.11744687 0.24341226 0.12596539\n",
      "0.113597125 0.24110222 0.1275051\n",
      "0.11577028 0.24066119 0.12489091\n",
      "0.11281161 0.24447294 0.13166133\n",
      "0.120921 0.25235295 0.13143195\n",
      "0.114531785 0.23847951 0.123947725\n",
      "0.10796803 0.23896247 0.13099444\n",
      "0.117596984 0.2466318 0.12903482\n",
      "0.116516516 0.24448754 0.12797102\n",
      "0.118786216 0.24745196 0.12866575\n",
      "0.11635378 0.24505581 0.12870203\n",
      "0.11154166 0.2381436 0.12660193\n",
      "0.11049305 0.22707456 0.116581514\n",
      "0.112859346 0.23151769 0.11865834\n",
      "0.11648424 0.2394299 0.12294567\n",
      "0.11010237 0.22902386 0.11892149\n",
      "0.099326156 0.215958 0.11663184\n",
      "0.10840669 0.22493492 0.11652823\n",
      "0.105198435 0.21874052 0.11354209\n",
      "0.108891614 0.23075491 0.1218633\n",
      "0.11178478 0.22942515 0.11764037\n",
      "0.105922945 0.2273725 0.12144955\n",
      "0.1108731 0.23076169 0.11988859\n",
      "0.10755063 0.22527927 0.11772864\n",
      "0.108196266 0.23170203 0.12350576\n",
      "0.102098145 0.22537266 0.12327451\n",
      "0.113292865 0.23391598 0.12062312\n",
      "0.102525875 0.21972868 0.1172028\n",
      "0.10545238 0.22561277 0.12016039\n",
      "0.109807424 0.22485931 0.11505189\n",
      "0.10816867 0.22723208 0.119063415\n",
      "0.10399748 0.22214718 0.118149705\n",
      "0.103358455 0.22439046 0.12103201\n",
      "0.10933337 0.22734459 0.118011214\n",
      "0.10112503 0.22745341 0.12632838\n",
      "0.10766652 0.22298943 0.1153229\n",
      "0.10476121 0.2208452 0.11608398\n",
      "0.10587162 0.21971972 0.113848105\n",
      "0.0925522 0.21792112 0.12536892\n",
      "0.09689248 0.20817198 0.111279495\n",
      "0.09892028 0.21473585 0.11581557\n",
      "0.10230484 0.2182697 0.11596487\n",
      "0.10456146 0.22144307 0.11688161\n",
      "0.09223345 0.22195378 0.12972033\n",
      "0.09546591 0.20876558 0.11329967\n",
      "0.104977 0.21568707 0.11071007\n",
      "0.0962382 0.21114857 0.11491037\n",
      "0.102396384 0.2137634 0.11136702\n",
      "0.1054067 0.26209667 0.15668997\n",
      "0.10923307 0.25003427 0.1408012\n",
      "0.103672236 0.23736706 0.13369483\n",
      "0.115906164 0.25692564 0.14101948\n",
      "0.12037903 0.25518137 0.13480234\n",
      "0.11510244 0.26493102 0.14982858\n",
      "0.110562816 0.2539558 0.143393\n",
      "0.10327269 0.23754196 0.13426927\n",
      "0.10863146 0.24876742 0.14013596\n",
      "0.11883119 0.25490052 0.13606933\n",
      "0.11566529 0.2666027 0.15093741\n",
      "0.10358246 0.24376102 0.14017856\n",
      "0.105387144 0.21724397 0.111856826\n",
      "0.1105232 0.22904007 0.11851687\n",
      "0.10688071 0.2273397 0.12045899\n",
      "0.107822426 0.22695239 0.11912996\n",
      "0.12154032 0.24589135 0.124351025\n",
      "0.1112181 0.2293239 0.11810579\n",
      "0.10711041 0.2267505 0.11964008\n",
      "0.11336342 0.23581612 0.1224527\n",
      "0.1137351 0.23186877 0.11813367\n",
      "0.11608956 0.24101639 0.12492683\n",
      "0.11393813 0.23854017 0.12460204\n",
      "0.118847124 0.23729143 0.1184443\n",
      "0.08689633 0.1727204 0.08582407\n",
      "0.087952994 0.17113924 0.08318625\n",
      "0.08889659 0.17621306 0.08731647\n",
      "0.089565895 0.18035719 0.09079129\n",
      "0.08567887 0.16763194 0.08195307\n",
      "0.081690386 0.16707306 0.08538267\n",
      "0.087006256 0.17120397 0.084197715\n",
      "0.08726342 0.1694141 0.08215068\n",
      "0.087544404 0.16601035 0.078465946\n",
      "0.09319655 0.18174927 0.08855272\n",
      "0.08340266 0.1690725 0.08566983\n",
      "0.09552671 0.1811733 0.085646585\n",
      "0.098221354 0.21490896 0.1166876\n",
      "0.09987507 0.21864142 0.118766345\n",
      "0.09911364 0.20939124 0.11027759\n",
      "0.09844544 0.22257915 0.12413371\n",
      "0.10105165 0.21689452 0.11584287\n",
      "0.10976301 0.22410002 0.11433701\n",
      "0.1143125 0.24751067 0.13319817\n",
      "0.102018364 0.21628015 0.11426178\n",
      "0.098965526 0.21500742 0.1160419\n",
      "0.10843693 0.23083821 0.12240128\n",
      "0.104281135 0.22470762 0.12042648\n",
      "0.1097979 0.23003903 0.12024113\n",
      "0.11239675 0.28413677 0.17174003\n",
      "0.105207026 0.28844088 0.18323386\n",
      "0.11554934 0.27720848 0.16165914\n",
      "0.11590403 0.28860703 0.172703\n",
      "0.11086087 0.29153037 0.1806695\n",
      "0.11060764 0.28555542 0.17494778\n",
      "0.11497544 0.29208902 0.17711358\n",
      "0.118179664 0.29860407 0.1804244\n",
      "0.11517103 0.29722086 0.18204983\n",
      "0.11367023 0.28811496 0.17444474\n",
      "0.11179753 0.2827062 0.17090867\n",
      "0.11414315 0.29856232 0.18441917\n",
      "0.15139925 0.32794932 0.17655006\n",
      "0.1689619 0.33736035 0.16839845\n",
      "0.16227958 0.33222875 0.16994917\n",
      "0.1437058 0.33689818 0.19319238\n",
      "0.15240082 0.3384989 0.18609807\n",
      "0.14164238 0.33866474 0.19702236\n",
      "0.13731492 0.311168 0.17385307\n",
      "0.15006329 0.31708506 0.16702177\n",
      "0.15198097 0.3451339 0.19315293\n",
      "0.17993632 0.3396632 0.15972689\n",
      "0.14931187 0.3364086 0.18709671\n",
      "0.11190534 0.30065712 0.18875179\n",
      "0.04185462 0.13553862 0.093684\n",
      "0.059136115 0.15552564 0.096389525\n",
      "0.04184807 0.13602062 0.094172545\n",
      "0.040929794 0.1303314 0.0894016\n",
      "0.041635945 0.12841657 0.08678062\n",
      "0.045185044 0.1400069 0.094821855\n",
      "0.044562668 0.13659178 0.09202911\n",
      "0.03711226 0.12938635 0.09227409\n",
      "0.03675721 0.1326751 0.09591789\n",
      "0.045424297 0.13423829 0.08881399\n",
      "0.036271244 0.1298879 0.09361665\n",
      "0.042999633 0.12891763 0.085918\n",
      "0.06532531 0.17298836 0.10766304\n",
      "0.0704348 0.17642188 0.10598708\n",
      "0.069745 0.16924761 0.099502616\n",
      "0.06563031 0.17225693 0.10662662\n",
      "0.061740987 0.17829552 0.116554536\n",
      "0.071401484 0.16786389 0.096462406\n",
      "0.06961827 0.17630936 0.10669109\n",
      "0.063681684 0.17686103 0.11317935\n",
      "0.06295884 0.16688898 0.103930146\n",
      "0.072567806 0.16756983 0.095002025\n",
      "0.06913103 0.17079902 0.101667985\n",
      "0.07078073 0.16563916 0.09485843\n",
      "0.09618858 0.2197044 0.12351582\n",
      "0.091165416 0.21405175 0.12288634\n",
      "0.09487389 0.21908692 0.124213025\n",
      "0.083803535 0.20433654 0.120533004\n",
      "0.08597544 0.2078095 0.121834055\n",
      "0.0920468 0.21557719 0.12353039\n",
      "0.08989146 0.21645948 0.12656802\n",
      "0.072141856 0.20283668 0.13069482\n",
      "0.09284829 0.21354578 0.12069749\n",
      "0.089871496 0.21236251 0.12249102\n",
      "0.09530776 0.21696463 0.12165687\n",
      "0.08937462 0.21393614 0.12456152\n",
      "0.08250356 0.22459832 0.14209476\n",
      "0.078799546 0.22780219 0.14900264\n",
      "0.10600066 0.28099456 0.1749939\n",
      "0.099656 0.24315089 0.14349489\n",
      "0.09248251 0.2306964 0.13821389\n",
      "0.09479874 0.23111765 0.1363189\n",
      "0.09460577 0.25676584 0.16216007\n",
      "0.09827793 0.23944154 0.14116362\n",
      "0.09402256 0.2395889 0.14556634\n",
      "0.08375715 0.23147 0.14771286\n",
      "0.08737919 0.2428415 0.15546231\n",
      "0.08520283 0.23207845 0.14687562\n",
      "0.06553496 0.18629794 0.12076298\n",
      "0.062749416 0.19494869 0.13219927\n",
      "0.06834753 0.22894575 0.16059822\n",
      "0.06027998 0.18182044 0.12154046\n",
      "0.06480718 0.19875701 0.13394983\n",
      "0.06461114 0.1978185 0.13320737\n",
      "0.064043105 0.1907908 0.1267477\n",
      "0.06040588 0.18919326 0.12878738\n",
      "0.05988346 0.18502581 0.12514235\n",
      "0.06031531 0.19032823 0.13001291\n",
      "0.06779237 0.19053562 0.12274325\n",
      "0.060745075 0.1845536 0.12380852\n",
      "0.07473712 0.19882832 0.12409121\n",
      "0.08529049 0.20111807 0.115827575\n",
      "0.07612892 0.1975195 0.12139057\n",
      "0.08102609 0.19598028 0.11495419\n",
      "0.075484194 0.19160138 0.11611719\n",
      "0.08430877 0.1964451 0.11213632\n",
      "0.08182729 0.18697967 0.105152376\n",
      "0.082599044 0.20226887 0.119669825\n",
      "0.0767289 0.19368693 0.11695803\n",
      "0.07711809 0.19033971 0.11322162\n",
      "0.079900295 0.19636992 0.11646962\n",
      "0.08403585 0.18847732 0.10444147\n",
      "0.07010055 0.17478696 0.1046864\n",
      "0.07514449 0.16897123 0.09382673\n",
      "0.07022716 0.17457978 0.10435262\n",
      "0.06789644 0.16961831 0.10172187\n",
      "0.07112158 0.17333576 0.10221418\n",
      "0.07275246 0.17327775 0.10052529\n",
      "0.07393657 0.17235427 0.0984177\n",
      "0.07332851 0.17078745 0.09745894\n",
      "0.07543089 0.17760956 0.10217867\n",
      "0.07251867 0.17650773 0.10398906\n",
      "0.06912288 0.17123891 0.10211603\n",
      "0.07209041 0.171569 0.099478595\n",
      "0.07670702 0.17068505 0.09397803\n",
      "0.076247126 0.16952705 0.09327993\n",
      "0.07805484 0.16485271 0.08679787\n",
      "0.075573616 0.17505634 0.09948272\n",
      "0.08656967 0.17099144 0.08442177\n",
      "0.08152991 0.16989662 0.08836671\n",
      "0.07467066 0.17063399 0.09596333\n",
      "0.083046794 0.17054196 0.08749516\n",
      "0.07277385 0.17002718 0.09725333\n",
      "0.07188704 0.16866978 0.09678274\n",
      "0.074950695 0.17396459 0.099013895\n",
      "0.074442245 0.17348456 0.09904232\n",
      "0.07192959 0.17571145 0.103781864\n",
      "0.07162053 0.17227033 0.1006498\n",
      "0.07295534 0.17698713 0.10403179\n",
      "0.07268336 0.17864566 0.1059623\n",
      "0.07157816 0.17795086 0.1063727\n",
      "0.07014076 0.17813203 0.10799127\n",
      "0.07122312 0.17583941 0.10461629\n",
      "0.068283595 0.17768122 0.10939763\n",
      "0.07237878 0.17042795 0.09804917\n",
      "0.07212313 0.17723688 0.10511375\n",
      "0.06976624 0.17931533 0.10954909\n",
      "0.07208594 0.17910342 0.10701748\n",
      "0.07835773 0.1683269 0.08996917\n",
      "0.07815787 0.17187095 0.093713075\n",
      "0.07011027 0.15893622 0.08882595\n",
      "0.07269218 0.15854667 0.08585449\n",
      "0.07461061 0.16134933 0.08673871\n",
      "0.07382853 0.16418724 0.090358704\n",
      "0.06433028 0.16040306 0.09607278\n",
      "0.073904224 0.15944323 0.085539006\n",
      "0.07003785 0.1638078 0.093769945\n",
      "0.07588518 0.16366819 0.08778301\n",
      "0.066974096 0.15654226 0.08956816\n",
      "0.07368503 0.16418116 0.09049613\n",
      "0.05756431 0.13594785 0.07838354\n",
      "0.0488298 0.1268882 0.0780584\n",
      "0.051060684 0.13124052 0.08017983\n",
      "0.056617334 0.13192466 0.075307325\n",
      "0.059212804 0.14427343 0.085060626\n",
      "0.058523655 0.13643368 0.07791002\n",
      "0.054798365 0.13280827 0.0780099\n",
      "0.061607502 0.13759327 0.07598577\n",
      "0.06041611 0.13706832 0.07665221\n",
      "0.055781886 0.13486217 0.07908028\n",
      "0.061993986 0.14108561 0.07909162\n",
      "0.054246217 0.12593967 0.07169345\n",
      "0.08034594 0.17325437 0.09290843\n",
      "0.081599005 0.17546426 0.09386525\n",
      "0.06927287 0.1641492 0.09487633\n",
      "0.0697449 0.16585621 0.09611131\n",
      "0.0828064 0.1787815 0.09597509\n",
      "0.08749575 0.18322916 0.09573341\n",
      "0.08442716 0.18143599 0.097008824\n",
      "0.08884159 0.18234445 0.093502864\n",
      "0.08328553 0.17086908 0.08758355\n",
      "0.08114176 0.1746594 0.09351764\n",
      "0.07622152 0.1756148 0.099393286\n",
      "0.084618345 0.17668593 0.092067584\n",
      "0.05595289 0.12176919 0.0658163\n",
      "0.057686634 0.11857759 0.060890958\n",
      "0.057709638 0.11935647 0.06164683\n",
      "0.05417885 0.119153455 0.064974606\n",
      "0.056352325 0.11888613 0.0625338\n",
      "0.057432763 0.119615436 0.062182672\n",
      "0.054995835 0.121821344 0.06682551\n",
      "0.05779279 0.12478978 0.06699699\n",
      "0.05896686 0.1260954 0.06712854\n",
      "0.055241704 0.120539226 0.06529752\n",
      "0.054734945 0.124126874 0.06939193\n",
      "0.050540827 0.11776183 0.067221\n",
      "0.0580094 0.13631389 0.078304484\n",
      "0.06318318 0.14800353 0.08482035\n",
      "0.05909864 0.14550887 0.08641023\n",
      "0.063544124 0.14644073 0.082896605\n",
      "0.06762102 0.14708051 0.07945949\n",
      "0.068508886 0.14863405 0.08012516\n",
      "0.0702564 0.16377732 0.093520924\n",
      "0.06729015 0.14027321 0.072983064\n",
      "0.06636841 0.15160002 0.08523161\n",
      "0.06369316 0.14501444 0.08132128\n",
      "0.055723183 0.13983199 0.08410881\n",
      "0.057719223 0.13692191 0.07920269\n",
      "0.067372456 0.16739525 0.10002279\n",
      "0.07575071 0.17856942 0.10281871\n",
      "0.06155008 0.15782654 0.09627646\n",
      "0.066515826 0.16473882 0.09822299\n",
      "0.07229115 0.17219143 0.099900275\n",
      "0.07222332 0.18100995 0.10878663\n",
      "0.07685669 0.19112583 0.11426914\n",
      "0.0718404 0.1779727 0.106132306\n",
      "0.06685518 0.17279598 0.105940804\n",
      "0.072782256 0.18042228 0.10764002\n",
      "0.07440058 0.1834796 0.109079026\n",
      "0.070750035 0.19110483 0.120354794\n",
      "0.117133304 0.25752136 0.14038806\n",
      "0.106042534 0.23670323 0.1306607\n",
      "0.10428193 0.23942135 0.13513942\n",
      "0.1165006 0.24754281 0.13104221\n",
      "0.089800164 0.24981017 0.16001001\n",
      "0.095885694 0.21133639 0.115450695\n",
      "0.10188961 0.2399219 0.13803229\n",
      "0.11440551 0.25238812 0.1379826\n",
      "0.1152281 0.24344012 0.12821202\n",
      "0.108043924 0.25059232 0.1425484\n",
      "0.104258105 0.25962 0.1553619\n",
      "0.104925096 0.244373 0.1394479\n",
      "0.036650725 0.102940656 0.06628993\n",
      "0.03476896 0.10027997 0.06551101\n",
      "0.038047437 0.094452396 0.05640496\n",
      "0.038435545 0.09575687 0.05732133\n",
      "0.03577076 0.0956283 0.05985754\n",
      "0.039583452 0.10913474 0.06955129\n",
      "0.03524962 0.101766184 0.06651656\n",
      "0.036566164 0.09221212 0.055645954\n",
      "0.036740676 0.08754592 0.05080524\n",
      "0.03834703 0.096749604 0.058402576\n",
      "0.03950257 0.095743924 0.056241356\n",
      "0.03989051 0.09623334 0.05634283\n",
      "0.052695416 0.12335758 0.07066216\n",
      "0.057162426 0.12623918 0.069076754\n",
      "0.058675066 0.13554563 0.07687056\n",
      "0.056656234 0.12837495 0.071718715\n",
      "0.050503306 0.12090505 0.07040174\n",
      "0.050618097 0.12763219 0.07701409\n",
      "0.043441653 0.12565069 0.082209036\n",
      "0.05357354 0.12765726 0.07408372\n",
      "0.057260156 0.13575666 0.0784965\n",
      "0.05631776 0.12846051 0.07214275\n",
      "0.049813487 0.122171454 0.07235797\n",
      "0.048293144 0.12309773 0.07480459\n",
      "0.08163144 0.18324494 0.10161351\n",
      "0.0728539 0.17610255 0.10324865\n",
      "0.07140558 0.17758472 0.10617914\n",
      "0.07992707 0.17819364 0.09826657\n",
      "0.06889304 0.17438345 0.10549041\n",
      "0.0730016 0.17795081 0.10494921\n",
      "0.084693424 0.18383312 0.0991397\n",
      "0.0615303 0.17639896 0.11486866\n",
      "0.06539424 0.17844813 0.11305389\n",
      "0.08255634 0.18093583 0.09837949\n",
      "0.0662068 0.1763825 0.1101757\n",
      "0.07035043 0.17878272 0.108432285\n",
      "0.06649285 0.17239134 0.10589849\n",
      "0.059280954 0.1623844 0.10310345\n",
      "0.06358161 0.16710137 0.10351976\n",
      "0.066550046 0.17240232 0.105852276\n",
      "0.06686566 0.16680466 0.099938996\n",
      "0.06421461 0.16447714 0.10026253\n",
      "0.06551648 0.1647087 0.099192224\n",
      "0.06985227 0.16384907 0.0939968\n",
      "0.06771237 0.16952968 0.10181731\n",
      "0.06656874 0.17278099 0.10621225\n",
      "0.0656437 0.16888197 0.10323827\n",
      "0.06133032 0.16549976 0.10416944\n",
      "0.05651848 0.16989572 0.11337724\n",
      "0.05601719 0.16976611 0.11374892\n",
      "0.057227254 0.19034441 0.13311715\n",
      "0.0547648 0.16669007 0.11192527\n",
      "0.06457625 0.16871089 0.104134634\n",
      "0.04865864 0.1600648 0.11140616\n",
      "0.056343302 0.1743494 0.118006095\n",
      "0.059767365 0.16517223 0.10540487\n",
      "0.06268502 0.164511 0.101825975\n",
      "0.06541111 0.18128923 0.11587811\n",
      "0.05890067 0.17173912 0.11283845\n",
      "0.056400053 0.17499948 0.11859942\n",
      "0.061724804 0.15326796 0.09154316\n",
      "0.06555759 0.15852731 0.09296972\n",
      "0.06550573 0.15754105 0.09203532\n",
      "0.060883395 0.15120906 0.09032566\n",
      "0.06141191 0.14943746 0.08802555\n",
      "0.067262605 0.15038213 0.08311953\n",
      "0.055624686 0.14386244 0.088237755\n",
      "0.062303953 0.15436655 0.0920626\n",
      "0.0632879 0.15466924 0.09138134\n",
      "0.05743123 0.14597872 0.08854749\n",
      "0.06151942 0.15170188 0.09018246\n",
      "0.060904257 0.14694144 0.08603718\n",
      "0.058882535 0.14639571 0.08751318\n",
      "0.05745648 0.14662328 0.089166805\n",
      "0.06096641 0.14484748 0.08388107\n",
      "0.05525738 0.14099064 0.085733265\n",
      "0.05816724 0.14354078 0.08537354\n",
      "0.055237517 0.13653526 0.08129774\n",
      "0.060172148 0.14255336 0.08238121\n",
      "0.06349892 0.14979482 0.086295895\n",
      "0.06401571 0.14694747 0.082931764\n",
      "0.06050381 0.1406994 0.08019559\n",
      "0.060652465 0.14407422 0.08342175\n",
      "0.05531264 0.1414102 0.08609756\n",
      "0.057002045 0.14299989 0.08599784\n",
      "0.053214647 0.13474701 0.08153237\n",
      "0.05894906 0.14002 0.08107094\n",
      "0.05877208 0.13744059 0.07866851\n",
      "0.056649476 0.13313207 0.076482594\n",
      "0.061829567 0.14463429 0.082804725\n",
      "0.06347281 0.14225592 0.07878311\n",
      "0.054193556 0.133712 0.07951844\n",
      "0.060311854 0.14570539 0.08539353\n",
      "0.05933766 0.13784187 0.078504205\n",
      "0.054293297 0.13589346 0.08160017\n",
      "0.06410248 0.1476002 0.083497725\n",
      "0.06170006 0.15829556 0.096595496\n",
      "0.05953303 0.14970817 0.09017514\n",
      "0.06652099 0.16570678 0.099185795\n",
      "0.05908654 0.14526245 0.08617591\n",
      "0.070483655 0.15365425 0.08317059\n",
      "0.075174384 0.16170661 0.08653223\n",
      "0.06786855 0.15462062 0.086752065\n",
      "0.06354024 0.16148292 0.09794267\n",
      "0.065646246 0.15077613 0.08512989\n",
      "0.061967075 0.15329108 0.091324\n",
      "0.060521908 0.15038307 0.08986116\n",
      "0.066105545 0.1604507 0.09434515\n",
      "0.06751969 0.14609934 0.07857966\n",
      "0.06751727 0.14409263 0.07657536\n",
      "0.064377345 0.1378505 0.07347315\n",
      "0.064867444 0.14569885 0.0808314\n",
      "0.069691844 0.14017679 0.07048494\n",
      "0.06272607 0.14357013 0.08084405\n",
      "0.062416516 0.13295682 0.0705403\n",
      "0.06709528 0.14402905 0.07693377\n",
      "0.071721725 0.1514984 0.07977668\n",
      "0.06965837 0.14720812 0.077549756\n",
      "0.06507919 0.14639048 0.08131129\n",
      "0.07065284 0.13879906 0.068146214\n",
      "0.0635153 0.15102823 0.08751293\n",
      "0.04939203 0.15572627 0.10633424\n",
      "0.046630196 0.15922284 0.112592645\n",
      "0.06204682 0.1532739 0.09122708\n",
      "0.06202948 0.16493282 0.10290334\n",
      "0.061213605 0.16069442 0.099480815\n",
      "0.06652552 0.17611042 0.1095849\n",
      "0.045534655 0.15004456 0.104509905\n",
      "0.05976265 0.15850568 0.09874303\n",
      "0.06240569 0.16708963 0.104683936\n",
      "0.06505854 0.16083734 0.0957788\n",
      "0.059804127 0.14591913 0.086115\n",
      "0.046989255 0.12390752 0.07691827\n",
      "0.04830215 0.11730975 0.0690076\n",
      "0.04928551 0.12568657 0.07640106\n",
      "0.057651237 0.12147095 0.063819714\n",
      "0.052323885 0.12763432 0.07531043\n",
      "0.051360168 0.1309906 0.07963043\n",
      "0.056773014 0.12634039 0.069567375\n",
      "0.05169443 0.13047573 0.0787813\n",
      "0.055665854 0.11794107 0.062275212\n",
      "0.04599139 0.12705767 0.08106628\n",
      "0.04405073 0.1190522 0.07500147\n",
      "0.057669498 0.12658226 0.06891277\n",
      "0.03291481 0.094935924 0.062021114\n",
      "0.046813935 0.11016071 0.06334677\n",
      "0.05006401 0.10365924 0.053595234\n",
      "0.042036172 0.090107664 0.048071492\n",
      "0.03857769 0.09745896 0.058881268\n",
      "0.040027108 0.0896259 0.049598794\n",
      "0.044288956 0.096876875 0.05258792\n",
      "0.03669557 0.090254895 0.053559326\n",
      "0.03677545 0.096934125 0.060158674\n",
      "0.039187953 0.10074899 0.06156104\n",
      "0.038317952 0.09304635 0.0547284\n",
      "0.032442093 0.09605755 0.063615456\n",
      "0.056903206 0.12508592 0.068182714\n",
      "0.044493347 0.11910481 0.07461146\n",
      "0.05168798 0.12395018 0.072262205\n",
      "0.05524399 0.12797038 0.07272639\n",
      "0.05834593 0.12385061 0.06550468\n",
      "0.052115142 0.12577516 0.073660016\n",
      "0.061749645 0.137119 0.07536935\n",
      "0.048860453 0.12826751 0.07940706\n",
      "0.054272294 0.12264534 0.06837305\n",
      "0.054246694 0.12057675 0.06633005\n",
      "0.05752922 0.13709038 0.07956117\n",
      "0.048854128 0.12258648 0.073732354\n",
      "0.04786008 0.14216822 0.094308145\n",
      "0.054701433 0.1539648 0.09926337\n",
      "0.04619927 0.1521943 0.10599504\n",
      "0.056608222 0.1410903 0.08448208\n",
      "0.049589306 0.14078465 0.091195345\n",
      "0.052616186 0.14565746 0.09304128\n",
      "0.064061984 0.15610856 0.092046574\n",
      "0.055769905 0.14646074 0.09069084\n",
      "0.07040319 0.16697443 0.09657124\n",
      "0.06196422 0.16848 0.10651577\n",
      "0.062720865 0.15241827 0.089697406\n",
      "0.053895883 0.16529523 0.111399345\n",
      "0.06997865 0.18255255 0.1125739\n",
      "0.1132469 0.22318162 0.10993472\n",
      "0.10514473 0.22576241 0.12061768\n",
      "0.093134314 0.21006468 0.116930366\n",
      "0.11660456 0.23305842 0.11645386\n",
      "0.09380101 0.22435337 0.13055237\n",
      "0.0741259 0.2243909 0.150265\n",
      "0.064434886 0.16944316 0.105008274\n",
      "0.08256677 0.23052232 0.14795555\n",
      "0.09026191 0.19722624 0.106964335\n",
      "0.10455879 0.20363995 0.099081166\n",
      "0.09973678 0.20955768 0.1098209\n",
      "0.033042658 0.07238332 0.039340664\n",
      "0.032085516 0.07488062 0.042795107\n",
      "0.04073432 0.07542719 0.03469287\n",
      "0.036246613 0.07278779 0.03654118\n",
      "0.03743901 0.07134081 0.033901796\n",
      "0.03771212 0.07541094 0.03769882\n",
      "0.038866673 0.07598772 0.037121046\n",
      "0.045417532 0.09135942 0.04594189\n",
      "0.028902296 0.077300936 0.04839864\n",
      "0.028045155 0.072799526 0.04475437\n",
      "0.036292143 0.09213638 0.05584424\n",
      "0.03139308 0.07289059 0.041497506\n",
      "0.04278576 0.09653185 0.053746093\n",
      "0.046720404 0.09737304 0.050652634\n",
      "0.041068193 0.093560636 0.052492443\n",
      "0.04659069 0.09878103 0.052190337\n",
      "0.047323924 0.098950066 0.051626142\n",
      "0.045291692 0.09746208 0.05217039\n",
      "0.046282746 0.0987379 0.052455157\n",
      "0.044112097 0.0966133 0.052501205\n",
      "0.039167244 0.0801512 0.040983956\n",
      "0.044008933 0.09767716 0.053668223\n",
      "0.042885106 0.096589796 0.05370469\n",
      "0.045564614 0.09876736 0.05320275\n",
      "0.05673246 0.14226595 0.085533485\n",
      "0.051630825 0.14214888 0.09051806\n",
      "0.053965077 0.13782273 0.083857656\n",
      "0.044639915 0.13256969 0.08792977\n",
      "0.054115497 0.13485226 0.080736764\n",
      "0.067522295 0.14653 0.07900771\n",
      "0.054978766 0.14299057 0.08801181\n",
      "0.05295544 0.14040188 0.087446444\n",
      "0.057812653 0.13631839 0.07850573\n",
      "0.057902448 0.14533423 0.08743178\n",
      "0.05300103 0.13972768 0.08672665\n",
      "0.056593187 0.14389418 0.08730099\n",
      "0.042786427 0.12909247 0.08630604\n",
      "0.04328917 0.13965833 0.09636916\n",
      "0.046055824 0.13771798 0.09166215\n",
      "0.04411468 0.13414127 0.09002659\n",
      "0.050107628 0.1360581 0.08595048\n",
      "0.040811375 0.1396406 0.098829225\n",
      "0.03597594 0.12267238 0.08669644\n",
      "0.048707023 0.13466422 0.0859572\n",
      "0.037917286 0.13287011 0.09495282\n",
      "0.036563262 0.13497241 0.098409146\n",
      "0.0480311 0.13042992 0.082398824\n",
      "0.038788795 0.13099517 0.092206374\n",
      "0.042935655 0.131651 0.088715345\n",
      "0.0360211 0.13332227 0.09730117\n",
      "0.03490509 0.1357934 0.10088831\n",
      "0.03896693 0.13367707 0.094710134\n",
      "0.03610473 0.13433665 0.09823192\n",
      "0.042315617 0.123097815 0.0807822\n",
      "0.035938084 0.12096857 0.08503049\n",
      "0.041121393 0.14184466 0.10072327\n",
      "0.03959597 0.13030499 0.09070902\n",
      "0.042745255 0.13608827 0.09334301\n",
      "0.03640203 0.12831903 0.09191699\n",
      "0.032639578 0.13257456 0.09993498\n",
      "0.03979589 0.116744936 0.076949045\n",
      "0.044253603 0.1177845 0.0735309\n",
      "0.044251285 0.11871645 0.07446516\n",
      "0.045831315 0.122839436 0.07700812\n",
      "0.0431265 0.12171494 0.07858844\n",
      "0.046477936 0.11419605 0.06771811\n",
      "0.04542899 0.12505925 0.079630256\n",
      "0.0399921 0.12107283 0.08108073\n",
      "0.04419186 0.12316398 0.07897212\n",
      "0.04078018 0.11608565 0.07530547\n",
      "0.040839493 0.11996688 0.079127386\n",
      "0.04901623 0.12246318 0.07344695\n",
      "0.045581408 0.12094897 0.07536756\n",
      "0.046621114 0.11893896 0.072317846\n",
      "0.04236909 0.12305657 0.08068748\n",
      "0.03874045 0.113145515 0.07440507\n",
      "0.04073233 0.12603162 0.08529929\n",
      "0.045628212 0.12011823 0.07449002\n",
      "0.04524003 0.12048033 0.0752403\n",
      "0.043453723 0.12104478 0.077591054\n",
      "0.04130497 0.12395506 0.082650095\n",
      "0.045121484 0.11965625 0.07453477\n",
      "0.050904505 0.12736003 0.076455526\n",
      "0.050448082 0.12275379 0.07230571\n",
      "0.043160796 0.10324932 0.060088523\n",
      "0.043077588 0.11310752 0.07002993\n",
      "0.045343325 0.118130445 0.07278712\n",
      "0.041549206 0.11107265 0.069523446\n",
      "0.043253526 0.11606237 0.07280885\n",
      "0.042809784 0.10958798 0.0667782\n",
      "0.043634824 0.10855329 0.064918466\n",
      "0.04716509 0.11591485 0.06874976\n",
      "0.039983235 0.11335802 0.073374785\n",
      "0.043028176 0.11235325 0.069325075\n",
      "0.040979877 0.11459239 0.07361251\n",
      "0.038804814 0.109516755 0.07071194\n",
      "0.04227362 0.11980276 0.07752914\n",
      "0.041035026 0.11909954 0.078064516\n",
      "0.04071057 0.12088338 0.080172814\n",
      "0.048224583 0.1265693 0.07834472\n",
      "0.04257395 0.12031886 0.07774491\n",
      "0.05027064 0.12759757 0.07732693\n",
      "0.049620368 0.12129747 0.0716771\n",
      "0.04730048 0.13057345 0.08327297\n",
      "0.041238256 0.12201643 0.080778174\n",
      "0.044090733 0.12369913 0.079608396\n",
      "0.04879368 0.12775356 0.078959875\n",
      "0.045646332 0.123466626 0.07782029\n",
      "0.049488127 0.10969969 0.06021156\n",
      "0.044411637 0.105497524 0.061085887\n",
      "0.05350116 0.11222905 0.05872789\n",
      "0.04917334 0.113577634 0.064404294\n",
      "0.046446204 0.113296136 0.06684993\n",
      "0.053406507 0.114303716 0.06089721\n",
      "0.0524611 0.1134247 0.060963605\n",
      "0.053494878 0.11294153 0.059446655\n",
      "0.05320671 0.11521741 0.0620107\n",
      "0.049537964 0.12253483 0.07299686\n",
      "0.04826265 0.11570636 0.06744371\n",
      "0.05276063 0.11683131 0.06407068\n",
      "0.03246653 0.091514304 0.059047773\n",
      "0.026775211 0.097790524 0.07101531\n",
      "0.029777147 0.0990559 0.069278754\n",
      "0.029156215 0.08739074 0.058234528\n",
      "0.027529016 0.08523799 0.05770897\n",
      "0.027032584 0.09766134 0.070628755\n",
      "0.024279792 0.08622357 0.06194378\n",
      "0.025904194 0.089988254 0.06408406\n",
      "0.032978337 0.09334753 0.06036919\n",
      "0.02218245 0.08926879 0.06708634\n",
      "0.035185825 0.083583385 0.04839756\n",
      "0.027547076 0.08641878 0.0588717\n",
      "0.03581117 0.105384275 0.069573104\n",
      "0.040630266 0.108311035 0.06768077\n",
      "0.039037757 0.10860297 0.069565214\n",
      "0.044344284 0.11458026 0.070235975\n",
      "0.049763877 0.10973927 0.05997539\n",
      "0.04460852 0.12012457 0.07551605\n",
      "0.04958859 0.11632117 0.06673258\n",
      "0.049335152 0.12177885 0.0724437\n",
      "0.03562387 0.10518341 0.06955954\n",
      "0.04736972 0.11520124 0.06783152\n",
      "0.0481965 0.10974474 0.061548244\n",
      "0.04768776 0.11242384 0.064736076\n",
      "0.03559987 0.090215206 0.054615337\n",
      "0.030414693 0.0877765 0.057361804\n",
      "0.030382618 0.088195145 0.057812527\n",
      "0.031540543 0.08489247 0.053351924\n",
      "0.03401623 0.0922965 0.058280274\n",
      "0.031382717 0.084982336 0.05359962\n",
      "0.037194453 0.09069979 0.05350534\n",
      "0.025614116 0.082612485 0.05699837\n",
      "0.041404538 0.09190722 0.05050268\n",
      "0.026865296 0.08975059 0.06288529\n",
      "0.030379754 0.0760736 0.04569385\n",
      "0.041306403 0.09194876 0.05064236\n",
      "0.025173418 0.08812506 0.06295164\n",
      "0.035504 0.104272485 0.06876849\n",
      "0.034508638 0.10034339 0.06583475\n",
      "0.03706144 0.097333185 0.060271744\n",
      "0.038470823 0.096240856 0.057770032\n",
      "0.034882702 0.110240966 0.075358264\n",
      "0.02869331 0.10189387 0.07320056\n",
      "0.02839924 0.09046079 0.062061552\n",
      "0.032348394 0.10172071 0.06937232\n",
      "0.040649198 0.09308359 0.052434392\n",
      "0.033963673 0.092297226 0.058333553\n",
      "0.03239607 0.103603356 0.071207285\n",
      "0.027248293 0.10528615 0.07803786\n",
      "0.04380724 0.119858235 0.076051\n",
      "0.032430105 0.10193727 0.06950717\n",
      "0.040104203 0.105162024 0.06505782\n",
      "0.034245282 0.10595519 0.07170991\n",
      "0.021066137 0.10285223 0.081786096\n",
      "0.031820387 0.10338305 0.07156266\n",
      "0.040930398 0.12795343 0.08702303\n",
      "0.04197903 0.10915293 0.0671739\n",
      "0.05353184 0.12035374 0.0668219\n",
      "0.034774184 0.12055155 0.085777365\n",
      "0.034954824 0.10571691 0.07076208\n",
      "0.014682315 0.12560736 0.11092504\n",
      "0.044538096 0.14135239 0.09681429\n",
      "0.05752957 0.12916842 0.07163885\n",
      "0.033732913 0.13256915 0.098836236\n",
      "0.082547836 0.18267038 0.10012255\n",
      "0.053653806 0.13871828 0.08506447\n",
      "0.06871537 0.1565656 0.087850235\n",
      "0.031398214 0.1327066 0.10130838\n",
      "0.0595174 0.108828284 0.049310885\n",
      "0.04143838 0.12686625 0.08542787\n",
      "0.06670856 0.122344 0.055635445\n",
      "0.007832587 0.12630995 0.11847736\n",
      "0.026717313 0.056141965 0.029424652\n",
      "0.02640437 0.07053683 0.04413246\n",
      "0.026704311 0.056190096 0.029485784\n",
      "0.020750955 0.058346912 0.037595958\n",
      "0.028549144 0.05641605 0.027866906\n",
      "0.026228176 0.05664789 0.030419713\n",
      "0.027498296 0.055372726 0.02787443\n",
      "0.02807011 0.05625286 0.028182749\n",
      "0.026485845 0.06881711 0.042331263\n",
      "0.022701219 0.05901184 0.03631062\n",
      "0.0094327405 0.04550714 0.0360744\n",
      "0.021497656 0.057547107 0.03604945\n",
      "0.019550469 0.05247172 0.03292125\n",
      "0.037115462 0.078687884 0.04157242\n",
      "0.026905913 0.073322184 0.04641627\n",
      "0.027444202 0.06619714 0.03875294\n",
      "0.040968407 0.095523 0.054554593\n",
      "0.028420154 0.076313496 0.04789334\n",
      "0.021871462 0.064136714 0.04226525\n",
      "0.036654677 0.07629927 0.039644595\n",
      "0.020556085 0.064071886 0.0435158\n",
      "0.036928296 0.07884717 0.041918874\n",
      "0.037041128 0.07917383 0.042132705\n",
      "0.031104274 0.07640118 0.045296907\n",
      "0.0459515 0.10553811 0.059586607\n",
      "0.047468696 0.109777376 0.06230868\n",
      "0.047599435 0.09934704 0.051747605\n",
      "0.05315224 0.1095 0.056347758\n",
      "0.04478783 0.10084034 0.056052506\n",
      "0.05114806 0.098228 0.04707994\n",
      "0.052206744 0.107247226 0.055040482\n",
      "0.052530374 0.1076521 0.055121724\n",
      "0.049072504 0.104776844 0.05570434\n",
      "0.04879765 0.10675378 0.057956133\n",
      "0.055806614 0.110871844 0.05506523\n",
      "0.04666231 0.10217304 0.05551073\n",
      "0.036041528 0.105378106 0.06933658\n",
      "0.033972137 0.094029136 0.060057\n",
      "0.051126048 0.11701567 0.06588962\n",
      "0.039676696 0.11258556 0.07290886\n",
      "0.049877577 0.11950688 0.069629304\n",
      "0.036545776 0.10278565 0.06623987\n",
      "0.03923598 0.1066845 0.06744852\n",
      "0.039997704 0.107863195 0.06786549\n",
      "0.032029554 0.111795075 0.07976552\n",
      "0.044226527 0.11625386 0.07202733\n",
      "0.04299675 0.11177273 0.06877598\n",
      "0.04053291 0.103504546 0.06297164\n",
      "0.040631548 0.105752826 0.06512128\n",
      "0.0344295 0.0910149 0.056585398\n",
      "0.03702547 0.09246195 0.05543648\n",
      "0.03905079 0.09656811 0.057517316\n",
      "0.04539769 0.10893803 0.06354034\n",
      "0.038448498 0.10146153 0.06301303\n",
      "0.041353736 0.09048137 0.049127635\n",
      "0.04276634 0.10346197 0.060695633\n",
      "0.033405244 0.09365689 0.060251646\n",
      "0.042141132 0.09673845 0.05459732\n",
      "0.03543593 0.09526807 0.05983214\n",
      "0.036922835 0.09638513 0.059462294\n",
      "0.03739256 0.08782059 0.05042803\n",
      "0.03910835 0.08849049 0.049382143\n",
      "0.041227847 0.08596969 0.04474184\n",
      "0.030794822 0.0844258 0.053630978\n",
      "0.04218852 0.098250814 0.056062292\n",
      "0.041275304 0.09572005 0.05444475\n",
      "0.039924607 0.09484278 0.05491817\n",
      "0.032741837 0.088524796 0.05578296\n",
      "0.032562997 0.084179394 0.051616397\n",
      "0.038049813 0.089948885 0.05189907\n",
      "0.045232013 0.08687831 0.041646294\n",
      "0.04051461 0.08561926 0.045104653\n",
      "0.0420374 0.09137073 0.04933333\n",
      "0.038726598 0.08416835 0.045441754\n",
      "0.044715818 0.085856736 0.041140918\n",
      "0.03596485 0.08766188 0.051697027\n",
      "0.038336642 0.08808702 0.04975038\n",
      "0.04676122 0.098297544 0.051536325\n",
      "0.037891757 0.081552066 0.04366031\n",
      "0.035616484 0.088490725 0.05287424\n",
      "0.03940823 0.092269205 0.052860975\n",
      "0.040976007 0.08856492 0.04758891\n",
      "0.047350753 0.10089237 0.05354162\n",
      "0.041564237 0.08582133 0.044257093\n",
      "0.036283948 0.088080645 0.051796697\n",
      "0.04584817 0.094597064 0.048748896\n",
      "0.0403516 0.08736298 0.047011383\n",
      "0.03558366 0.08825008 0.05266642\n",
      "0.035830658 0.09104782 0.055217165\n",
      "0.042119525 0.087514535 0.04539501\n",
      "0.03439648 0.0868103 0.052413817\n",
      "0.040422637 0.08501104 0.044588406\n",
      "0.044092607 0.0897045 0.045611892\n",
      "0.036911946 0.08615549 0.049243543\n",
      "0.040442724 0.09102146 0.05057874\n",
      "0.04222797 0.08850691 0.04627894\n",
      "0.036731496 0.09369459 0.056963094\n",
      "0.042355184 0.10460458 0.062249396\n",
      "0.0406203 0.094533235 0.053912934\n",
      "0.042744342 0.09126932 0.04852498\n",
      "0.0384843 0.095524095 0.057039794\n",
      "0.040960807 0.09309709 0.052136283\n",
      "0.04442635 0.099742256 0.055315904\n",
      "0.04080221 0.09909869 0.05829648\n",
      "0.040336404 0.08988845 0.04955205\n",
      "0.04666038 0.1072005 0.060540125\n",
      "0.034703296 0.0916999 0.056996603\n",
      "0.040233273 0.09636158 0.056128304\n",
      "0.037418224 0.088955805 0.05153758\n",
      "0.032670725 0.08713062 0.054459896\n",
      "0.0418003 0.09037727 0.04857697\n",
      "0.03781778 0.08882319 0.051005412\n",
      "0.04130261 0.08875245 0.04744984\n",
      "0.031251602 0.083446465 0.052194864\n",
      "0.029402494 0.08292982 0.053527325\n",
      "0.03160291 0.077918395 0.046315484\n",
      "0.030785527 0.08472424 0.053938713\n",
      "0.040773436 0.08953909 0.048765652\n",
      "0.034968026 0.09707431 0.06210628\n",
      "0.03176676 0.083265945 0.051499184\n",
      "0.023412202 0.07098311 0.04757091\n",
      "0.016891275 0.06514459 0.048253316\n",
      "0.027973417 0.084550336 0.05657692\n",
      "0.019614682 0.071656264 0.052041583\n",
      "0.02736443 0.072164044 0.044799615\n",
      "0.027048469 0.08889104 0.06184257\n",
      "0.02955202 0.08518352 0.055631503\n",
      "0.025469441 0.08385021 0.05838077\n",
      "0.022859357 0.08255949 0.05970013\n",
      "0.024994586 0.079002455 0.05400787\n",
      "0.030553333 0.07581102 0.045257688\n",
      "0.0220577 0.07711443 0.055056732\n",
      "0.022415098 0.069920726 0.04750563\n",
      "0.020615965 0.076886356 0.05627039\n",
      "0.013919845 0.06949718 0.055577338\n",
      "0.019408297 0.07807276 0.05866446\n",
      "0.02128831 0.07924604 0.057957727\n",
      "0.01988925 0.067232184 0.047342934\n",
      "0.027053002 0.0831417 0.056088697\n",
      "0.025452025 0.0683932 0.042941175\n",
      "0.021904908 0.07656304 0.05465813\n",
      "0.025666445 0.078911886 0.05324544\n",
      "0.024708595 0.07355617 0.048847575\n",
      "0.02052658 0.07649867 0.05597209\n",
      "0.01834521 0.064633116 0.046287905\n",
      "0.023945361 0.06722884 0.043283477\n",
      "0.019388147 0.063939705 0.04455156\n",
      "0.021925382 0.06364343 0.04171805\n",
      "0.013401937 0.06474236 0.05134042\n",
      "0.01622228 0.059389103 0.043166824\n",
      "0.017628439 0.060697388 0.04306895\n",
      "0.019946381 0.06429336 0.04434698\n",
      "0.021051094 0.065165445 0.04411435\n",
      "0.02025253 0.056131 0.035878472\n",
      "0.014933594 0.06339664 0.048463047\n",
      "0.024130642 0.07454614 0.0504155\n",
      "0.019074965 0.07807168 0.05899672\n",
      "0.034500744 0.083958544 0.0494578\n",
      "0.023612168 0.08003074 0.05641857\n",
      "0.028498601 0.08136994 0.052871335\n",
      "0.022082012 0.0794251 0.057343084\n",
      "0.02130783 0.07498985 0.053682018\n",
      "0.025671192 0.074997775 0.049326584\n",
      "0.025004685 0.083255835 0.05825115\n",
      "0.017753005 0.07218236 0.054429352\n",
      "0.019344505 0.067845605 0.0485011\n",
      "0.024304967 0.0795859 0.055280935\n",
      "0.016015664 0.07960179 0.06358612\n",
      "0.023525625 0.107113615 0.08358799\n",
      "0.029785916 0.09773263 0.06794672\n",
      "0.028241105 0.100862585 0.07262148\n",
      "0.032348327 0.10879331 0.07644498\n",
      "0.026758544 0.12115903 0.09440049\n",
      "0.020605266 0.124567814 0.10396255\n",
      "0.037477598 0.12391364 0.08643604\n",
      "0.021188103 0.11625145 0.09506334\n",
      "0.04213866 0.105525315 0.06338666\n",
      "0.026776515 0.10690389 0.08012737\n",
      "0.043473333 0.112436794 0.06896346\n",
      "0.03931386 0.12501054 0.085696675\n",
      "-0.018875629 0.07874231 0.09761794\n",
      "0.034382313 0.10982176 0.075439446\n",
      "0.038164698 0.12674202 0.08857732\n",
      "0.030310698 0.10137495 0.07106425\n",
      "0.037282735 0.10056408 0.06328134\n",
      "0.03403405 0.11363558 0.079601526\n",
      "0.0391395 0.10912625 0.069986746\n",
      "0.025430039 0.121355005 0.095924966\n",
      "0.02311644 0.12542987 0.10231343\n",
      "0.02162347 0.12366303 0.10203956\n",
      "0.012759551 0.10714486 0.09438531\n",
      "0.029163357 0.08438571 0.05522235\n",
      "0.00019560009 0.023578603 0.023383003\n",
      "0.008512046 0.023796503 0.015284456\n",
      "0.0052139666 0.024538636 0.01932467\n",
      "0.007986356 0.023536503 0.015550148\n",
      "0.010357727 0.025370244 0.015012517\n",
      "0.025328016 0.049660422 0.024332406\n",
      "0.009229457 0.023614552 0.014385095\n",
      "0.008787555 0.02329717 0.0145096155\n",
      "0.010385822 0.025491435 0.0151056135\n",
      "0.0079446435 0.023057107 0.015112463\n",
      "0.009587541 0.02535188 0.015764339\n",
      "0.008904673 0.02976709 0.020862417\n",
      "0.015165864 0.03968251 0.024516648\n",
      "0.015875285 0.039521404 0.023646118\n",
      "0.019366596 0.04474002 0.025373425\n",
      "0.016837781 0.04035035 0.02351257\n",
      "0.014160166 0.037952337 0.023792172\n",
      "0.019828107 0.044761296 0.02493319\n",
      "0.012087829 0.03827556 0.02618773\n",
      "0.018734625 0.043841507 0.025106883\n",
      "0.01670765 0.039862603 0.023154953\n",
      "0.015377371 0.04360832 0.028230948\n",
      "0.016521446 0.039942358 0.023420911\n",
      "0.017302837 0.046680376 0.029377539\n",
      "0.03205956 0.076272614 0.044213053\n",
      "0.039919715 0.07753316 0.037613448\n",
      "0.034767378 0.07218455 0.03741717\n",
      "0.032756217 0.06970605 0.036949836\n",
      "0.034557357 0.085703716 0.05114636\n",
      "0.03659547 0.081847645 0.045252174\n",
      "0.03912547 0.08907326 0.049947795\n",
      "0.029923685 0.08112158 0.051197894\n",
      "0.029825237 0.07851643 0.048691195\n",
      "0.03593442 0.07267374 0.03673932\n",
      "0.032280434 0.07720594 0.044925507\n",
      "0.032782577 0.08507942 0.05229684\n",
      "0.040068883 0.088193886 0.048125003\n",
      "0.032169424 0.0810026 0.048833176\n",
      "0.036997773 0.07982185 0.042824075\n",
      "0.03283746 0.07737848 0.04454102\n",
      "0.03781552 0.08274954 0.04493402\n",
      "0.018471897 0.07911845 0.060646556\n",
      "0.03874477 0.08263074 0.04388597\n",
      "0.043711122 0.10038852 0.056677397\n",
      "0.029322296 0.074291684 0.044969387\n",
      "0.037416585 0.08261568 0.045199096\n",
      "0.03822193 0.08708561 0.048863683\n",
      "0.028352827 0.07957644 0.051223613\n",
      "0.025713064 0.07652067 0.050807603\n",
      "0.029568136 0.0770824 0.047514267\n",
      "0.027904235 0.07696013 0.049055897\n",
      "0.031008381 0.08448086 0.053472478\n",
      "0.0280407 0.07651903 0.048478328\n",
      "0.028871622 0.08090191 0.05203029\n",
      "0.029587533 0.07741109 0.04782356\n",
      "0.025665235 0.08080404 0.055138808\n",
      "0.027214281 0.08084217 0.053627886\n",
      "0.031849343 0.077375576 0.045526233\n",
      "0.02929921 0.075603664 0.046304453\n",
      "0.03143649 0.07851621 0.047079716\n",
      "0.025924455 0.06710115 0.041176695\n",
      "0.026660848 0.06680773 0.040146884\n",
      "0.024156418 0.062426366 0.03826995\n",
      "0.02379239 0.06681441 0.043022018\n",
      "0.024301227 0.068582445 0.04428122\n",
      "0.026473116 0.06902973 0.042556617\n",
      "0.024348807 0.06789062 0.043541815\n",
      "0.02737533 0.07341123 0.046035904\n",
      "0.027457535 0.06756758 0.040110044\n",
      "0.021119881 0.056291763 0.03517188\n",
      "0.02541069 0.06746074 0.04205005\n",
      "0.030357838 0.068916015 0.038558178\n",
      "0.02658118 0.06780391 0.041222733\n",
      "0.030346937 0.07207199 0.041725054\n",
      "0.026059624 0.06408875 0.038029123\n",
      "0.027860358 0.07255198 0.044691622\n",
      "0.0343814 0.07674412 0.042362716\n",
      "0.029650122 0.07113454 0.041484416\n",
      "0.026224397 0.07068039 0.04445599\n",
      "0.026126888 0.063910484 0.037783597\n",
      "0.025370557 0.06830893 0.04293837\n",
      "0.025946632 0.06766817 0.041721538\n",
      "0.023620505 0.064457566 0.04083706\n",
      "0.027269166 0.069579504 0.04231034\n",
      "0.02748983 0.06123725 0.03374742\n",
      "0.024010409 0.059946567 0.03593616\n",
      "0.025477752 0.067486815 0.042009063\n",
      "0.029485252 0.07354735 0.044062097\n",
      "0.024400096 0.0631687 0.0387686\n",
      "0.024253871 0.061495654 0.037241783\n",
      "0.025599554 0.06757232 0.041972764\n",
      "0.032576103 0.08017514 0.047599036\n",
      "0.02788613 0.06526984 0.037383713\n",
      "0.02819629 0.068218425 0.040022135\n",
      "0.029265769 0.073100284 0.043834515\n",
      "0.02707839 0.07057066 0.043492272\n",
      "0.025533155 0.06837446 0.042841308\n",
      "0.033711646 0.076644585 0.04293294\n",
      "0.031896822 0.076349355 0.044452533\n",
      "0.025211655 0.066884786 0.04167313\n",
      "0.030616798 0.07649192 0.045875125\n",
      "0.03389944 0.064833984 0.030934542\n",
      "0.027393945 0.07535888 0.047964938\n",
      "0.033795442 0.07362922 0.03983378\n",
      "0.029618513 0.06899613 0.03937762\n",
      "0.033987522 0.07489312 0.040905595\n",
      "0.029530283 0.07584482 0.046314534\n",
      "0.02696567 0.07051889 0.04355322\n",
      "0.030619547 0.08699898 0.05637943\n",
      "0.029127494 0.07450794 0.045380443\n",
      "0.034041908 0.081805274 0.047763366\n",
      "0.03602322 0.08250224 0.04647902\n",
      "0.033028718 0.07485805 0.04182933\n",
      "0.0382493 0.08964918 0.05139988\n",
      "0.03405997 0.08857449 0.05451452\n",
      "0.031690832 0.07987117 0.048180338\n",
      "0.04451015 0.089179255 0.044669107\n",
      "0.03245546 0.08212037 0.049664907\n",
      "0.030740667 0.069779746 0.03903908\n",
      "0.04114772 0.08945486 0.04830714\n",
      "0.01357156 0.066315114 0.052743554\n",
      "0.009130102 0.051899835 0.042769734\n",
      "0.011986591 0.05138342 0.03939683\n",
      "0.020071346 0.0553228 0.035251454\n",
      "0.018893417 0.06279965 0.04390623\n",
      "0.010890659 0.06374714 0.05285648\n",
      "0.009798594 0.05048798 0.040689386\n",
      "0.012387484 0.052816994 0.04042951\n",
      "0.011975057 0.05299509 0.041020032\n",
      "0.011412792 0.052085876 0.040673085\n",
      "0.021601293 0.06651346 0.044912163\n",
      "0.016976465 0.06694437 0.049967904\n",
      "0.019352019 0.06528676 0.045934744\n",
      "0.01857321 0.058362897 0.039789688\n",
      "0.014700156 0.057209834 0.04250968\n",
      "0.017722357 0.06610961 0.048387256\n",
      "0.014494743 0.055441834 0.04094709\n",
      "0.015625913 0.056072723 0.04044681\n",
      "0.010491349 0.06196424 0.05147289\n",
      "0.026150823 0.06729909 0.041148268\n",
      "0.009772558 0.06740155 0.057628993\n",
      "0.023720048 0.058801565 0.035081517\n",
      "0.011042699 0.06354594 0.052503243\n",
      "0.017903682 0.05582116 0.03791748\n",
      "0.020770423 0.050229743 0.02945932\n",
      "0.017538134 0.04249021 0.024952076\n",
      "0.017364398 0.050858572 0.033494174\n",
      "0.015275018 0.04138749 0.026112473\n",
      "0.005889021 0.047639236 0.041750215\n",
      "0.0076177455 0.050423626 0.04280588\n",
      "0.015276369 0.05180769 0.03653132\n",
      "0.01152496 0.04864044 0.03711548\n",
      "0.015768418 0.045976568 0.03020815\n",
      "0.00939776 0.04361046 0.0342127\n",
      "0.013354592 0.054419093 0.0410645\n",
      "0.013878409 0.045512147 0.03163374\n",
      "0.025232151 0.06690033 0.041668177\n",
      "0.017184306 0.050498053 0.033313747\n",
      "0.013340961 0.053480778 0.040139817\n",
      "0.01949593 0.05393732 0.03444139\n",
      "0.009986546 0.054499704 0.04451316\n",
      "0.022655867 0.055259462 0.032603595\n",
      "0.012122177 0.06946584 0.05734366\n",
      "0.011909556 0.052414138 0.040504582\n",
      "0.0077154897 0.054561205 0.046845715\n",
      "0.010125097 0.055057082 0.044931985\n",
      "0.014303289 0.06042672 0.04612343\n",
      "0.017518438 0.061908092 0.044389654\n",
      "0.013247997 0.0889252 0.0756772\n",
      "0.033263788 0.092880405 0.059616618\n",
      "0.025828734 0.09972068 0.073891945\n",
      "0.024615176 0.099672206 0.07505703\n",
      "0.018977784 0.101684235 0.08270645\n",
      "0.010757908 0.09461185 0.083853945\n",
      "0.021629006 0.111039415 0.08941041\n",
      "0.009361744 0.08310585 0.0737441\n",
      "0.036477163 0.11188468 0.07540752\n",
      "0.012027003 0.07174148 0.059714474\n",
      "0.020272478 0.10244827 0.08217579\n",
      "0.050026864 0.11867834 0.068651475\n",
      "0.0056851357 0.092814766 0.08712963\n",
      "0.029913403 0.10976913 0.079855725\n",
      "0.028956741 0.14337724 0.1144205\n",
      "0.054998793 0.13771173 0.08271294\n",
      "0.038941547 0.12549141 0.08654986\n",
      "0.031227857 0.13715594 0.10592808\n",
      "0.015689991 0.10703136 0.09134137\n",
      "0.020825319 0.11828233 0.097457014\n",
      "0.09726976 0.15058291 0.053313147\n",
      "0.021276943 0.11611143 0.094834484\n",
      "0.11631663 0.14217135 0.02585472\n",
      "0.030171677 0.09801598 0.0678443\n",
      "0.0031078719 0.014654764 0.011546892\n",
      "0.0048021926 0.014248663 0.00944647\n",
      "0.0040710513 0.013385629 0.009314578\n",
      "0.0046985717 0.013629447 0.008930875\n",
      "0.0040629217 0.013390044 0.009327122\n",
      "0.010638913 0.023894243 0.01325533\n",
      "0.0043225503 0.013170689 0.008848139\n",
      "0.0033776592 0.019294268 0.015916608\n",
      "0.004723669 0.013710477 0.008986808\n",
      "0.002572706 0.016769147 0.014196441\n",
      "0.0027357647 0.015623802 0.012888038\n",
      "0.0031272983 0.014775197 0.011647899\n",
      "0.0005331021 0.009353485 0.008820383\n",
      "-6.346777e-05 0.009120047 0.009183515\n",
      "-0.00082741305 0.012865648 0.013693061\n",
      "0.0009767655 0.020424934 0.019448169\n",
      "0.000584146 0.009947085 0.009362939\n",
      "-0.00032537617 0.009434269 0.009759645\n",
      "0.0018968843 0.019990344 0.01809346\n",
      "0.0006797975 0.009686178 0.00900638\n",
      "-0.0013014721 0.010552533 0.011854005\n",
      "-0.00013191439 0.0105529465 0.010684861\n",
      "-0.00027504563 0.0107970955 0.011072141\n",
      "-0.0009207949 0.011517454 0.012438249\n",
      "0.012684267 0.04879889 0.036114622\n",
      "0.01612467 0.048057813 0.031933144\n",
      "0.023147546 0.051986713 0.028839167\n",
      "0.02223191 0.046491843 0.024259932\n",
      "0.016707752 0.052829415 0.036121663\n",
      "0.016799469 0.04597808 0.029178612\n",
      "0.017477144 0.05057282 0.033095676\n",
      "0.018371735 0.05477996 0.036408227\n",
      "0.025742449 0.057242487 0.031500038\n",
      "0.01311313 0.049627267 0.036514137\n",
      "0.025943609 0.05463574 0.028692132\n",
      "0.017285507 0.054276146 0.03699064\n",
      "0.0107645355 0.046855092 0.036090557\n",
      "0.01333737 0.04744176 0.03410439\n",
      "0.01631224 0.043669246 0.027357006\n",
      "0.011353899 0.042129327 0.030775428\n",
      "0.015632773 0.042715546 0.027082773\n",
      "0.012384905 0.04093765 0.028552746\n",
      "0.015164997 0.041727323 0.026562326\n",
      "0.012544755 0.042086083 0.029541329\n",
      "0.013999036 0.044161763 0.030162727\n",
      "0.022794057 0.048572514 0.025778458\n",
      "0.018865416 0.045561653 0.026696237\n",
      "0.011235591 0.04709565 0.035860058\n",
      "0.0039742514 0.043211028 0.039236777\n",
      "0.019780455 0.04681164 0.027031185\n",
      "0.011725619 0.043564823 0.031839203\n",
      "0.009247195 0.044280015 0.03503282\n",
      "0.014917834 0.04243261 0.027514776\n",
      "0.009562515 0.043598596 0.03403608\n",
      "0.014685925 0.047180053 0.032494128\n",
      "0.011151291 0.04673928 0.03558799\n",
      "0.014886085 0.043005496 0.028119411\n",
      "0.017014844 0.045199692 0.028184848\n",
      "0.014119841 0.043419868 0.029300027\n",
      "0.015394393 0.041779593 0.0263852\n",
      "0.009625446 0.04161388 0.031988434\n",
      "0.012034947 0.039972305 0.027937358\n",
      "0.01177218 0.042113096 0.030340916\n",
      "0.011154078 0.044102583 0.032948505\n",
      "0.016062055 0.04006208 0.024000026\n",
      "0.011169508 0.03940854 0.02823903\n",
      "0.013341546 0.043346442 0.030004896\n",
      "0.009560486 0.040736195 0.031175708\n",
      "0.016158061 0.038848057 0.022689996\n",
      "0.012788124 0.043390445 0.030602321\n",
      "0.010707466 0.039971024 0.029263558\n",
      "0.011791207 0.042147618 0.03035641\n",
      "0.0118591655 0.038927387 0.027068222\n",
      "0.0002652388 0.024553284 0.024288045\n",
      "0.011807971 0.04086915 0.02906118\n",
      "0.011016443 0.041091517 0.030075073\n",
      "0.011688873 0.040621944 0.02893307\n",
      "0.014184354 0.043797255 0.0296129\n",
      "0.009897208 0.039878696 0.029981488\n",
      "0.010548137 0.035457134 0.024908997\n",
      "0.0069719404 0.03530832 0.02833638\n",
      "0.008144775 0.037111074 0.028966298\n",
      "0.010127991 0.039856303 0.029728312\n",
      "0.0115171205 0.039475437 0.027958317\n",
      "0.016040765 0.039671455 0.02363069\n",
      "0.012531202 0.03661669 0.024085488\n",
      "0.01604326 0.03910762 0.02306436\n",
      "0.012640061 0.038506906 0.025866846\n",
      "0.014209803 0.040685125 0.026475322\n",
      "0.011381706 0.041029233 0.029647527\n",
      "0.018233838 0.040523313 0.022289475\n",
      "0.013718974 0.04133509 0.027616117\n",
      "0.006841466 0.03284 0.025998533\n",
      "0.011499139 0.03836645 0.026867313\n",
      "0.006619241 0.032907102 0.026287861\n",
      "0.011717185 0.03715303 0.025435846\n",
      "0.017663512 0.052365623 0.03470211\n",
      "0.014666766 0.050387688 0.035720922\n",
      "0.014712885 0.04779347 0.033080585\n",
      "0.018365692 0.05076525 0.032399558\n",
      "0.014483437 0.05072142 0.036237985\n",
      "0.018453214 0.050433416 0.0319802\n",
      "0.0137604475 0.044795852 0.031035405\n",
      "0.013307814 0.04752428 0.034216467\n",
      "0.016960919 0.050453555 0.033492636\n",
      "0.015138425 0.04757075 0.032432325\n",
      "0.016628288 0.05059071 0.03396242\n",
      "0.017689865 0.047663637 0.029973771\n",
      "0.011646524 0.08146935 0.069822825\n",
      "0.024104096 0.066567145 0.04246305\n",
      "0.029113892 0.0677038 0.038589906\n",
      "0.017977871 0.066045806 0.048067935\n",
      "0.017106906 0.06741924 0.050312333\n",
      "0.035160016 0.075589634 0.04042962\n",
      "0.021789167 0.073151246 0.05136208\n",
      "0.026185699 0.06681932 0.04063362\n",
      "0.037518572 0.07327091 0.035752337\n",
      "0.0316509 0.07479308 0.043142177\n",
      "0.035595607 0.082434244 0.046838637\n",
      "0.027550545 0.071362264 0.04381172\n",
      "-0.0020709708 0.020887356 0.022958327\n",
      "0.0013683774 0.0235814 0.022213023\n",
      "0.0056742635 0.027643114 0.02196885\n",
      "0.0010666922 0.02165979 0.020593097\n",
      "-0.0063513406 0.027947824 0.034299165\n",
      "-0.00079163536 0.02353406 0.024325695\n",
      "0.0012596585 0.026040498 0.02478084\n",
      "-0.00016797148 0.026941411 0.027109383\n",
      "-0.0024461225 0.018735044 0.021181166\n",
      "0.0022906028 0.024664711 0.022374108\n",
      "-0.0044185203 0.02011102 0.02452954\n",
      "-0.0041403435 0.020192634 0.024332978\n",
      "0.01459045 0.05068741 0.03609696\n",
      "0.0021106973 0.043521725 0.041411027\n",
      "0.010753419 0.042127892 0.031374473\n",
      "0.011394724 0.04998091 0.038586184\n",
      "0.011734318 0.04204857 0.030314252\n",
      "0.01635205 0.048010517 0.031658467\n",
      "0.009695757 0.058526147 0.04883039\n",
      "0.017029861 0.047100727 0.030070866\n",
      "0.015489742 0.056960315 0.041470572\n",
      "0.0073908456 0.04058365 0.033192806\n",
      "0.029231459 0.06856308 0.039331622\n",
      "0.01953315 0.052358825 0.032825675\n",
      "0.00097114407 0.02626428 0.025293136\n",
      "0.009669181 0.025221514 0.015552333\n",
      "0.00012884103 0.026052957 0.025924116\n",
      "0.008247266 0.032387525 0.02414026\n",
      "0.001232408 0.0329033 0.03167089\n",
      "0.009449527 0.028941445 0.019491918\n",
      "0.008387649 0.023370637 0.014982987\n",
      "0.012665013 0.029463325 0.016798312\n",
      "0.0045088287 0.03093277 0.02642394\n",
      "0.0053670295 0.025867285 0.020500256\n",
      "0.0024720877 0.02658228 0.024110192\n",
      "0.00900672 0.027985118 0.018978398\n",
      "0.0077037103 0.039130647 0.031426936\n",
      "0.007548224 0.045306187 0.037757963\n",
      "0.010610264 0.04042861 0.029818345\n",
      "0.010109348 0.03432699 0.024217641\n",
      "0.009445619 0.044056185 0.034610566\n",
      "0.006611295 0.033331096 0.026719801\n",
      "0.009851139 0.048791617 0.038940478\n",
      "0.010589544 0.04218739 0.031597845\n",
      "0.00053949654 0.036402397 0.0358629\n",
      "0.0073454976 0.038719993 0.031374495\n",
      "0.008541904 0.038575314 0.03003341\n",
      "0.009886144 0.037992314 0.02810617\n",
      "-0.0022678077 0.05024553 0.05251334\n",
      "0.007201493 0.051914312 0.04471282\n",
      "0.013755668 0.057782527 0.04402686\n",
      "0.031059038 0.065841414 0.034782376\n",
      "0.006806977 0.04788282 0.041075844\n",
      "0.019242894 0.039263323 0.020020429\n",
      "0.013137512 0.050736763 0.03759925\n",
      "0.024843818 0.05258632 0.027742503\n",
      "0.0175334 0.05362434 0.03609094\n",
      "0.027683115 0.058294803 0.030611688\n",
      "0.035668902 0.07103426 0.035365358\n",
      "0.0346538 0.0710308 0.036377\n",
      "-0.04745058 0.0820357 0.12948628\n",
      "-0.013455421 0.13047989 0.14393531\n",
      "0.001472313 0.049129285 0.047656972\n",
      "0.008774042 0.0862919 0.07751786\n",
      "0.037360854 0.10936034 0.07199948\n",
      "0.06625862 0.094435066 0.02817645\n",
      "0.034213074 0.101276875 0.0670638\n",
      "0.040701367 0.11244357 0.0717422\n",
      "0.0725871 0.102957204 0.030370103\n",
      "0.04006035 0.14045696 0.10039661\n",
      "0.006975673 0.0880667 0.081091024\n",
      "0.030273996 0.11513557 0.08486158\n",
      "-0.0010770578 0.00059122575 0.0016682835\n",
      "-0.0020244673 0.001116534 0.0031410013\n",
      "-0.0022423752 0.0012458704 0.0034882454\n",
      "-0.0006412185 0.00034749 0.0009887085\n",
      "-0.0010942495 0.0006079701 0.0017022196\n",
      "-0.0018162029 0.006889982 0.008706185\n",
      "-0.0029970482 0.0020752992 0.0050723474\n",
      "-0.0028089217 0.0015598151 0.004368737\n",
      "-0.0031431643 0.0023093978 0.005452562\n",
      "-0.0007623324 0.000421312 0.0011836444\n",
      "-0.0028589144 0.0016912902 0.0045502046\n",
      "-0.0024481742 0.0013486817 0.003796856\n",
      "-0.00072557747 0.00039530228 0.0011208798\n",
      "-0.0011815808 0.0006481671 0.0018297479\n",
      "-0.00028846588 0.00015626069 0.00044472655\n",
      "-9.7992364e-05 5.3311378e-05 0.00015130374\n",
      "-0.0003340675 0.00018618454 0.00052025204\n",
      "-0.0018907415 0.0010484578 0.0029391993\n",
      "-0.0010387962 0.0005693693 0.0016081654\n",
      "-0.00020433337 0.00011398233 0.0003183157\n",
      "-0.00059571944 0.00032343867 0.0009191581\n",
      "-0.0012145427 0.0006976122 0.0019121548\n",
      "-0.0013563789 0.0007460457 0.0021024246\n",
      "-0.0033974547 0.0025646894 0.005962144\n",
      "0.002215921 0.010946737 0.008730816\n",
      "0.00507834 0.013606519 0.0085281795\n",
      "0.007392127 0.017269947 0.00987782\n",
      "0.006572796 0.015132291 0.008559495\n",
      "0.0055538584 0.014446598 0.008892739\n",
      "0.004755848 0.014505003 0.009749155\n",
      "0.00612503 0.015895784 0.009770754\n",
      "0.008433945 0.017489983 0.009056038\n",
      "0.0036261547 0.014856025 0.01122987\n",
      "0.0049735485 0.0154426 0.010469051\n",
      "0.0046630558 0.01508262 0.010419564\n",
      "0.0031151315 0.0136263855 0.010511254\n",
      "0.004443285 0.012931071 0.008487786\n",
      "0.005418745 0.013457435 0.00803869\n",
      "0.005162998 0.016507717 0.011344719\n",
      "0.0036000311 0.015445581 0.01184555\n",
      "-0.0013368214 0.010793276 0.0121300975\n",
      "0.004722627 0.01513428 0.010411653\n",
      "0.0036063194 0.014383665 0.010777346\n",
      "0.0025167624 0.011244737 0.008727974\n",
      "0.0019459398 0.01215687 0.01021093\n",
      "-0.0010142103 0.012496352 0.0135105625\n",
      "0.005578111 0.014320644 0.008742533\n",
      "-0.0014164466 0.012756825 0.014173272\n",
      "0.0036335327 0.012318251 0.008684718\n",
      "0.0009848932 0.010384086 0.009399192\n",
      "0.0028781258 0.012963492 0.010085367\n",
      "0.00033788662 0.015391174 0.015053287\n",
      "0.0034011556 0.013080846 0.00967969\n",
      "-0.005767882 0.011845967 0.017613849\n",
      "-0.00014582649 0.011311962 0.011457789\n",
      "0.00010117609 0.012393557 0.01229238\n",
      "0.002168242 0.012364905 0.010196663\n",
      "-0.00030912738 0.011463054 0.011772182\n",
      "-0.0018544961 0.020237764 0.02209226\n",
      "0.0031113448 0.013882272 0.010770927\n",
      "0.0036837803 0.015324408 0.011640628\n",
      "0.0009176899 0.013274587 0.012356897\n",
      "0.0008652909 0.0060088495 0.0051435586\n",
      "0.0035498384 0.012265739 0.008715901\n",
      "0.0007089516 0.0124572115 0.01174826\n",
      "0.001803264 0.013231188 0.011427924\n",
      "-0.00068769045 0.005611539 0.0062992293\n",
      "-0.004247398 0.010897829 0.015145227\n",
      "0.0064958627 0.014264409 0.0077685467\n",
      "0.0034414749 0.009033079 0.0055916044\n",
      "-0.0023982283 0.01295246 0.015350688\n",
      "0.0028298115 0.012233139 0.0094033275\n",
      "0.0061110305 0.016905492 0.010794462\n",
      "0.0014285427 0.016225284 0.014796741\n",
      "0.00213271 0.010859608 0.008726898\n",
      "0.0064832615 0.016637316 0.0101540545\n",
      "0.0015839459 0.009719779 0.008135833\n",
      "0.004966628 0.013813575 0.008846947\n",
      "0.0049524326 0.01723942 0.012286987\n",
      "0.0041156737 0.013565615 0.009449941\n",
      "0.0030675605 0.010617447 0.0075498866\n",
      "0.0019521033 0.010749749 0.008797646\n",
      "0.00525505 0.014244944 0.008989894\n",
      "0.0025355238 0.010973472 0.008437948\n",
      "-0.0010216953 0.009179925 0.01020162\n",
      "0.0029428098 0.008006237 0.0050634276\n",
      "0.0025490709 0.007760606 0.005211535\n",
      "0.0002855882 0.009865271 0.009579683\n",
      "0.00092010805 0.006060373 0.005140265\n",
      "-0.0044155065 0.0062448746 0.010660381\n",
      "-0.00027718488 0.011466787 0.011743972\n",
      "0.0028325417 0.01058465 0.007752108\n",
      "-0.004176112 0.007885775 0.0120618865\n",
      "-6.3681975e-05 0.009783271 0.009846953\n",
      "-0.0018998529 0.006697118 0.008596971\n",
      "0.002603243 0.007872163 0.00526892\n",
      "0.0013197847 0.011015738 0.009695954\n",
      "0.0003022626 0.015093484 0.014791221\n",
      "0.0091357175 0.016586598 0.0074508805\n",
      "0.005455654 0.014532447 0.009076793\n",
      "-0.002161895 0.010651093 0.012812988\n",
      "0.00068763644 0.015050734 0.014363098\n",
      "-0.0020356495 0.010112549 0.012148199\n",
      "0.008057905 0.020879377 0.012821471\n",
      "0.0010925699 0.020182308 0.019089738\n",
      "-0.0033294242 0.020075904 0.023405328\n",
      "0.0037547424 0.013994689 0.010239947\n",
      "0.006646971 0.016249908 0.009602937\n",
      "0.010921301 0.041217003 0.030295702\n",
      "0.0072005466 0.03164303 0.024442483\n",
      "0.020828078 0.039700367 0.018872289\n",
      "0.014424086 0.046259504 0.03183542\n",
      "0.009615649 0.048054636 0.038438987\n",
      "0.017138109 0.05083926 0.03370115\n",
      "0.013247654 0.04058774 0.027340084\n",
      "0.017627053 0.047216516 0.029589463\n",
      "0.003881637 0.03205655 0.028174914\n",
      "0.022506824 0.04627567 0.023768848\n",
      "0.033835344 0.04897306 0.015137719\n",
      "0.017657777 0.03990466 0.022246884\n",
      "-0.00072146114 0.012065261 0.012786722\n",
      "0.0008245148 0.010372094 0.009547579\n",
      "-0.0063785044 0.01321094 0.019589445\n",
      "-0.00248993 0.016240181 0.018730111\n",
      "-0.0010184282 0.014730821 0.01574925\n",
      "-0.0010747341 0.013873421 0.014948155\n",
      "0.0049328897 0.0153909465 0.010458057\n",
      "-0.0004022289 0.017224967 0.017627196\n",
      "-0.0001120707 0.0138123855 0.013924456\n",
      "0.0036863917 0.017935337 0.014248946\n",
      "0.0026527587 0.019543933 0.016891174\n",
      "0.001203496 0.013891254 0.012687758\n",
      "0.0025379676 0.019834498 0.01729653\n",
      "-0.0027145632 0.02206261 0.024777174\n",
      "0.0031177234 0.019767415 0.016649691\n",
      "0.0036040284 0.02170787 0.018103842\n",
      "-0.0042869477 0.013431315 0.017718263\n",
      "0.010052485 0.030535838 0.020483352\n",
      "-0.0008686166 0.01566307 0.016531687\n",
      "0.0058854893 0.024890209 0.01900472\n",
      "2.8586015e-05 0.019216388 0.019187802\n",
      "-0.006063644 0.019449167 0.02551281\n",
      "0.00855675 0.029283643 0.020726893\n",
      "0.006833289 0.025891228 0.019057939\n",
      "-0.0011475645 0.010789295 0.011936859\n",
      "-0.003675444 0.012529897 0.01620534\n",
      "0.00041157147 0.007801329 0.0073897573\n",
      "-0.0053287195 0.012042015 0.017370734\n",
      "-0.0036080275 0.013130741 0.016738769\n",
      "-0.0034173084 0.011977793 0.015395101\n",
      "-0.0014147358 0.010967157 0.012381893\n",
      "0.0037742849 0.011053789 0.0072795046\n",
      "0.0025914581 0.010551568 0.00796011\n",
      "0.004441188 0.010951727 0.0065105385\n",
      "0.0018468015 0.013927314 0.012080513\n",
      "0.0014031287 0.011391306 0.009988178\n",
      "0.012085 0.029897805 0.017812805\n",
      "0.00719711 0.03170742 0.024510311\n",
      "0.015922468 0.030981269 0.0150588\n",
      "-0.000647841 0.024758711 0.025406552\n",
      "0.013955969 0.032787558 0.018831588\n",
      "-0.00024827383 0.030454922 0.030703196\n",
      "0.021257102 0.042523876 0.021266773\n",
      "0.011065347 0.027700981 0.016635634\n",
      "0.011405561 0.03579436 0.024388798\n",
      "0.0044743735 0.033581056 0.029106682\n",
      "0.0090181045 0.03253307 0.023514964\n",
      "0.009584516 0.029014517 0.01943\n",
      "-0.0043231025 0.021732207 0.02605531\n",
      "0.0026984587 0.025998631 0.023300173\n",
      "-0.0013100021 0.031437777 0.03274778\n",
      "0.008024903 0.022287305 0.014262402\n",
      "-0.0092623085 0.02346386 0.03272617\n",
      "0.0047768485 0.025316814 0.020539965\n",
      "0.0066391863 0.019725217 0.01308603\n",
      "0.008398952 0.024355624 0.015956672\n",
      "0.0071180817 0.027849825 0.020731743\n",
      "0.0073374594 0.019667 0.01232954\n",
      "0.015737977 0.036578655 0.020840678\n",
      "0.005788436 0.02657297 0.020784535\n",
      "-0.021714829 0.10186128 0.12357611\n",
      "-0.0018425435 0.063508816 0.06535136\n",
      "-0.048539087 0.018754914 0.067294\n",
      "0.019657638 0.060457412 0.040799774\n",
      "0.001035884 0.15361996 0.15258408\n",
      "0.01847566 0.099619284 0.081143625\n",
      "0.086897254 0.105287336 0.018390086\n",
      "-0.031448834 0.09351729 0.12496612\n",
      "0.13158217 0.16516778 0.033585608\n",
      "0.07209131 0.17513485 0.10304354\n",
      "0.091612294 0.16043182 0.06881952\n",
      "0.010896556 0.09254812 0.08165156\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "-0.0565643 0.08190705 0.13847135\n",
      "0.06728202 0.2252675 0.15798548\n",
      "0.029269267 0.0894992 0.06022993\n",
      "0.059596777 0.16816677 0.108569995\n",
      "0.052528918 0.17993443 0.12740551\n",
      "-0.002087213 0.11456408 0.1166513\n",
      "0.028498016 0.1222293 0.093731284\n",
      "0.0088498145 0.13178091 0.12293109\n",
      "0.14939171 0.22799769 0.07860599\n",
      "0.057994656 0.10546644 0.047471784\n",
      "0.06673904 0.24651212 0.17977308\n",
      "-0.013512105 0.21185906 0.22537117\n"
     ]
    }
   ],
   "source": [
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -1, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -1, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = io_logit - s_logit\n",
    "\n",
    "results = []\n",
    "Result = collections.namedtuple('Result', ('source_node', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -1, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -1, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    results.append(Result(decomp.source_node, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb241388-4c18-4ee4-9368-f8b389fb01ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set rel/irrel for source node, batch_idx  (11, 0, 0) [0]\n",
      "mean act was:  tensor([ 4.3381,  4.3175,  4.1953,  4.4962,  4.3581,  4.2597,  4.5472,  4.5256,\n",
      "         4.5398,  4.3996,  4.3893,  4.1143,  4.2761,  4.4938,  4.2828,  4.2813,\n",
      "         4.4125,  4.5117,  4.5224,  4.2365,  4.2461,  4.3754,  4.4378,  4.4196,\n",
      "         4.1841,  4.3478,  4.4578,  4.5042,  4.5110,  4.8423,  4.3440,  4.4366,\n",
      "         4.2189,  4.1272,  4.1817,  4.2968, 22.1240,  4.5640,  4.4600,  4.4444,\n",
      "         4.3637,  4.3948,  4.7283,  4.2437,  4.2377,  4.0271,  4.3663,  4.4075,\n",
      "         4.3571,  4.1481,  4.5351,  4.2055,  4.0362,  4.3295,  4.5534,  3.9828,\n",
      "         4.3085,  4.5576,  4.2134,  4.4471,  3.9249,  4.4140,  4.6684,  4.2879],\n",
      "       device='cuda:0')\n",
      "set rel/irrel for source node, batch_idx  (11, 0, 1) [0]\n",
      "mean act was:  tensor([-50.4150,   4.5419,   4.0771,   4.4587,   4.3852,   4.3702,   4.7570,\n",
      "          4.1151,   4.4245,   4.5867,   4.2426,   4.3015,   4.5942,   4.2429,\n",
      "          3.9775,   4.2670,   4.3114,   4.7077,   4.5156,   4.4641,   4.2917,\n",
      "          4.2196,   4.4200, -47.7652,   4.3789,   4.3428,   4.3551,   4.7054,\n",
      "          4.3918,   4.5775,   4.5554,   4.2323,   4.5869,   4.4249,   4.6586,\n",
      "          4.0289,   4.4529,   4.4937,   4.6877,   4.4632,   4.2892,   4.5740,\n",
      "          4.6484,   4.5116,   4.3098,   4.4774,   4.7135,   4.6235,   4.4586,\n",
      "          4.5783,   4.2940,   4.6634,   4.6463,   4.3447,   4.2935,   4.2616,\n",
      "          4.2106,   4.7998,   4.4519,   4.4664,   4.5991,   4.3695,   4.5176,\n",
      "          4.2863], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "source_list = [(11, 0, 0)]\n",
    "out_decomps, target_decomps, _ = prop_GPT(ioi_dataset.toks[0:1, :], extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)\n",
    "rel1 = out_decomps[0].rel\n",
    "\n",
    "source_list = [(11, 0, 1)]\n",
    "out_decomps, target_decomps, _ = prop_GPT(ioi_dataset.toks[0:1, :], extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)\n",
    "rel2 = out_decomps[0].rel\n",
    "\n",
    "#print(rel1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a25972ca-181f-43bc-9750-acfb689a7687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4401803-697d-4dc3-8212-fd99658257a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(source_node=(11, 15, 2), score=0.026049923),\n",
       " Result(source_node=(11, 15, 1), score=0.022229344),\n",
       " Result(source_node=(11, 15, 10), score=0.010748272),\n",
       " Result(source_node=(11, 15, 11), score=0.009650529),\n",
       " Result(source_node=(11, 15, 5), score=0.009105967),\n",
       " Result(source_node=(11, 15, 8), score=0.008731268),\n",
       " Result(source_node=(11, 15, 9), score=0.0045712376),\n",
       " Result(source_node=(11, 15, 6), score=0.003845009),\n",
       " Result(source_node=(11, 15, 4), score=0.0032666253),\n",
       " Result(source_node=(11, 15, 3), score=0.0023612017),\n",
       " Result(source_node=(11, 0, 0), score=0.0),\n",
       " Result(source_node=(11, 0, 1), score=0.0),\n",
       " Result(source_node=(11, 0, 2), score=0.0),\n",
       " Result(source_node=(11, 0, 3), score=0.0),\n",
       " Result(source_node=(11, 0, 4), score=0.0),\n",
       " Result(source_node=(11, 0, 5), score=0.0),\n",
       " Result(source_node=(11, 0, 6), score=0.0),\n",
       " Result(source_node=(11, 0, 7), score=0.0),\n",
       " Result(source_node=(11, 0, 8), score=0.0),\n",
       " Result(source_node=(11, 0, 9), score=0.0),\n",
       " Result(source_node=(11, 0, 10), score=0.0),\n",
       " Result(source_node=(11, 0, 11), score=0.0),\n",
       " Result(source_node=(11, 1, 0), score=0.0),\n",
       " Result(source_node=(11, 1, 1), score=0.0),\n",
       " Result(source_node=(11, 1, 2), score=0.0),\n",
       " Result(source_node=(11, 1, 3), score=0.0),\n",
       " Result(source_node=(11, 1, 4), score=0.0),\n",
       " Result(source_node=(11, 1, 5), score=0.0),\n",
       " Result(source_node=(11, 1, 6), score=0.0),\n",
       " Result(source_node=(11, 1, 7), score=0.0),\n",
       " Result(source_node=(11, 1, 8), score=0.0),\n",
       " Result(source_node=(11, 1, 9), score=0.0),\n",
       " Result(source_node=(11, 1, 10), score=0.0),\n",
       " Result(source_node=(11, 1, 11), score=0.0),\n",
       " Result(source_node=(11, 2, 0), score=0.0),\n",
       " Result(source_node=(11, 2, 1), score=0.0),\n",
       " Result(source_node=(11, 2, 2), score=0.0),\n",
       " Result(source_node=(11, 2, 3), score=0.0),\n",
       " Result(source_node=(11, 2, 4), score=0.0),\n",
       " Result(source_node=(11, 2, 5), score=0.0),\n",
       " Result(source_node=(11, 2, 6), score=0.0),\n",
       " Result(source_node=(11, 2, 7), score=0.0),\n",
       " Result(source_node=(11, 2, 8), score=0.0),\n",
       " Result(source_node=(11, 2, 9), score=0.0),\n",
       " Result(source_node=(11, 2, 10), score=0.0),\n",
       " Result(source_node=(11, 2, 11), score=0.0),\n",
       " Result(source_node=(11, 3, 0), score=0.0),\n",
       " Result(source_node=(11, 3, 1), score=0.0),\n",
       " Result(source_node=(11, 3, 2), score=0.0),\n",
       " Result(source_node=(11, 3, 3), score=0.0),\n",
       " Result(source_node=(11, 3, 4), score=0.0),\n",
       " Result(source_node=(11, 3, 5), score=0.0),\n",
       " Result(source_node=(11, 3, 6), score=0.0),\n",
       " Result(source_node=(11, 3, 7), score=0.0),\n",
       " Result(source_node=(11, 3, 8), score=0.0),\n",
       " Result(source_node=(11, 3, 9), score=0.0),\n",
       " Result(source_node=(11, 3, 10), score=0.0),\n",
       " Result(source_node=(11, 3, 11), score=0.0),\n",
       " Result(source_node=(11, 4, 0), score=0.0),\n",
       " Result(source_node=(11, 4, 1), score=0.0),\n",
       " Result(source_node=(11, 4, 2), score=0.0),\n",
       " Result(source_node=(11, 4, 3), score=0.0),\n",
       " Result(source_node=(11, 4, 4), score=0.0),\n",
       " Result(source_node=(11, 4, 5), score=0.0),\n",
       " Result(source_node=(11, 4, 6), score=0.0),\n",
       " Result(source_node=(11, 4, 7), score=0.0),\n",
       " Result(source_node=(11, 4, 8), score=0.0),\n",
       " Result(source_node=(11, 4, 9), score=0.0),\n",
       " Result(source_node=(11, 4, 10), score=0.0),\n",
       " Result(source_node=(11, 4, 11), score=0.0),\n",
       " Result(source_node=(11, 5, 0), score=0.0),\n",
       " Result(source_node=(11, 5, 1), score=0.0),\n",
       " Result(source_node=(11, 5, 2), score=0.0),\n",
       " Result(source_node=(11, 5, 3), score=0.0),\n",
       " Result(source_node=(11, 5, 4), score=0.0),\n",
       " Result(source_node=(11, 5, 5), score=0.0),\n",
       " Result(source_node=(11, 5, 6), score=0.0),\n",
       " Result(source_node=(11, 5, 7), score=0.0),\n",
       " Result(source_node=(11, 5, 8), score=0.0),\n",
       " Result(source_node=(11, 5, 9), score=0.0),\n",
       " Result(source_node=(11, 5, 10), score=0.0),\n",
       " Result(source_node=(11, 5, 11), score=0.0),\n",
       " Result(source_node=(11, 6, 0), score=0.0),\n",
       " Result(source_node=(11, 6, 1), score=0.0),\n",
       " Result(source_node=(11, 6, 2), score=0.0),\n",
       " Result(source_node=(11, 6, 3), score=0.0),\n",
       " Result(source_node=(11, 6, 4), score=0.0),\n",
       " Result(source_node=(11, 6, 5), score=0.0),\n",
       " Result(source_node=(11, 6, 6), score=0.0),\n",
       " Result(source_node=(11, 6, 7), score=0.0),\n",
       " Result(source_node=(11, 6, 8), score=0.0),\n",
       " Result(source_node=(11, 6, 9), score=0.0),\n",
       " Result(source_node=(11, 6, 10), score=0.0),\n",
       " Result(source_node=(11, 6, 11), score=0.0),\n",
       " Result(source_node=(11, 7, 0), score=0.0),\n",
       " Result(source_node=(11, 7, 1), score=0.0),\n",
       " Result(source_node=(11, 7, 2), score=0.0),\n",
       " Result(source_node=(11, 7, 3), score=0.0),\n",
       " Result(source_node=(11, 7, 4), score=0.0),\n",
       " Result(source_node=(11, 7, 5), score=0.0),\n",
       " Result(source_node=(11, 7, 6), score=0.0),\n",
       " Result(source_node=(11, 7, 7), score=0.0),\n",
       " Result(source_node=(11, 7, 8), score=0.0),\n",
       " Result(source_node=(11, 7, 9), score=0.0),\n",
       " Result(source_node=(11, 7, 10), score=0.0),\n",
       " Result(source_node=(11, 7, 11), score=0.0),\n",
       " Result(source_node=(11, 8, 0), score=0.0),\n",
       " Result(source_node=(11, 8, 1), score=0.0),\n",
       " Result(source_node=(11, 8, 2), score=0.0),\n",
       " Result(source_node=(11, 8, 3), score=0.0),\n",
       " Result(source_node=(11, 8, 4), score=0.0),\n",
       " Result(source_node=(11, 8, 5), score=0.0),\n",
       " Result(source_node=(11, 8, 6), score=0.0),\n",
       " Result(source_node=(11, 8, 7), score=0.0),\n",
       " Result(source_node=(11, 8, 8), score=0.0),\n",
       " Result(source_node=(11, 8, 9), score=0.0),\n",
       " Result(source_node=(11, 8, 10), score=0.0),\n",
       " Result(source_node=(11, 8, 11), score=0.0),\n",
       " Result(source_node=(11, 9, 0), score=0.0),\n",
       " Result(source_node=(11, 9, 1), score=0.0),\n",
       " Result(source_node=(11, 9, 2), score=0.0),\n",
       " Result(source_node=(11, 9, 3), score=0.0),\n",
       " Result(source_node=(11, 9, 4), score=0.0),\n",
       " Result(source_node=(11, 9, 5), score=0.0),\n",
       " Result(source_node=(11, 9, 6), score=0.0),\n",
       " Result(source_node=(11, 9, 7), score=0.0),\n",
       " Result(source_node=(11, 9, 8), score=0.0),\n",
       " Result(source_node=(11, 9, 9), score=0.0),\n",
       " Result(source_node=(11, 9, 10), score=0.0),\n",
       " Result(source_node=(11, 9, 11), score=0.0),\n",
       " Result(source_node=(11, 10, 0), score=0.0),\n",
       " Result(source_node=(11, 10, 1), score=0.0),\n",
       " Result(source_node=(11, 10, 2), score=0.0),\n",
       " Result(source_node=(11, 10, 3), score=0.0),\n",
       " Result(source_node=(11, 10, 4), score=0.0),\n",
       " Result(source_node=(11, 10, 5), score=0.0),\n",
       " Result(source_node=(11, 10, 6), score=0.0),\n",
       " Result(source_node=(11, 10, 7), score=0.0),\n",
       " Result(source_node=(11, 10, 8), score=0.0),\n",
       " Result(source_node=(11, 10, 9), score=0.0),\n",
       " Result(source_node=(11, 10, 10), score=0.0),\n",
       " Result(source_node=(11, 10, 11), score=0.0),\n",
       " Result(source_node=(11, 11, 0), score=0.0),\n",
       " Result(source_node=(11, 11, 1), score=0.0),\n",
       " Result(source_node=(11, 11, 2), score=0.0),\n",
       " Result(source_node=(11, 11, 3), score=0.0),\n",
       " Result(source_node=(11, 11, 4), score=0.0),\n",
       " Result(source_node=(11, 11, 5), score=0.0),\n",
       " Result(source_node=(11, 11, 6), score=0.0),\n",
       " Result(source_node=(11, 11, 7), score=0.0),\n",
       " Result(source_node=(11, 11, 8), score=0.0),\n",
       " Result(source_node=(11, 11, 9), score=0.0),\n",
       " Result(source_node=(11, 11, 10), score=0.0),\n",
       " Result(source_node=(11, 11, 11), score=0.0),\n",
       " Result(source_node=(11, 12, 0), score=0.0),\n",
       " Result(source_node=(11, 12, 1), score=0.0),\n",
       " Result(source_node=(11, 12, 2), score=0.0),\n",
       " Result(source_node=(11, 12, 3), score=0.0),\n",
       " Result(source_node=(11, 12, 4), score=0.0),\n",
       " Result(source_node=(11, 12, 5), score=0.0),\n",
       " Result(source_node=(11, 12, 6), score=0.0),\n",
       " Result(source_node=(11, 12, 7), score=0.0),\n",
       " Result(source_node=(11, 12, 8), score=0.0),\n",
       " Result(source_node=(11, 12, 9), score=0.0),\n",
       " Result(source_node=(11, 12, 10), score=0.0),\n",
       " Result(source_node=(11, 12, 11), score=0.0),\n",
       " Result(source_node=(11, 13, 0), score=0.0),\n",
       " Result(source_node=(11, 13, 1), score=0.0),\n",
       " Result(source_node=(11, 13, 2), score=0.0),\n",
       " Result(source_node=(11, 13, 3), score=0.0),\n",
       " Result(source_node=(11, 13, 4), score=0.0),\n",
       " Result(source_node=(11, 13, 5), score=0.0),\n",
       " Result(source_node=(11, 13, 6), score=0.0),\n",
       " Result(source_node=(11, 13, 7), score=0.0),\n",
       " Result(source_node=(11, 13, 8), score=0.0),\n",
       " Result(source_node=(11, 13, 9), score=0.0),\n",
       " Result(source_node=(11, 13, 10), score=0.0),\n",
       " Result(source_node=(11, 13, 11), score=0.0),\n",
       " Result(source_node=(11, 14, 0), score=0.0),\n",
       " Result(source_node=(11, 14, 1), score=0.0),\n",
       " Result(source_node=(11, 14, 2), score=0.0),\n",
       " Result(source_node=(11, 14, 3), score=0.0),\n",
       " Result(source_node=(11, 14, 4), score=0.0),\n",
       " Result(source_node=(11, 14, 5), score=0.0),\n",
       " Result(source_node=(11, 14, 6), score=0.0),\n",
       " Result(source_node=(11, 14, 7), score=0.0),\n",
       " Result(source_node=(11, 14, 8), score=0.0),\n",
       " Result(source_node=(11, 14, 9), score=0.0),\n",
       " Result(source_node=(11, 14, 10), score=0.0),\n",
       " Result(source_node=(11, 14, 11), score=0.0),\n",
       " Result(source_node=(11, 15, 7), score=-0.0010629403),\n",
       " Result(source_node=(11, 15, 0), score=-0.0147551745)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce463474-bb7b-42c5-84bc-8fac38699c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=True, bins=192)  # density=False would make counts\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc3f6b47-439f-4fe0-b987-a8b2a1264258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "def interquartile_range(results, iqr_multiplier=1):\n",
    "    # assume sorted in increasing order\n",
    "    third_quartile = results[int(len(results) * 0.75)].score\n",
    "    first_quartile = results[int(len(results) * 0.25)].score\n",
    "    IQR = third_quartile - first_quartile\n",
    "    outlier_score = third_quartile + iqr_multiplier * IQR\n",
    "    print(third_quartile, first_quartile, outlier_score)\n",
    "\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ff1e97-c772-4063-8b4c-e9705185498e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def n_sigma_rule(results, n=3):\n",
    "    scores = [r.score for r in results]\n",
    "    std_dev = np.std(scores)\n",
    "    mean = np.mean(scores)\n",
    "    outlier_score = mean + std_dev * n\n",
    "    print(std_dev, mean, outlier_score)\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):] #bisect does a binary search, returns idx of outlier_score\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "effd20fb-68cd-41df-99a8-a2c44bff8038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056104362 0.0071276473 0.10508107766509056\n",
      "18\n",
      "0.03002767 0.031796653 0.12187966518104076\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=False)\n",
    "iqr = interquartile_range(results)\n",
    "print(len(iqr))\n",
    "outliers = n_sigma_rule(results, n=3)\n",
    "print(len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d00b5-4527-48e9-b84d-1df046336b6f",
   "metadata": {},
   "source": [
    "# One more iteration: Find maximally relevant source nodes to target nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92ef27aa-343c-42ce-8a25-0af8f4418e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cache activations for later\n",
    "\n",
    "# Note: I discovered that the calculation of rels is very sensitive to the cached pre-layer activations\n",
    "# Since the forward pass via TransformerLens is very slightly different for numerical reasons, this is enough to throw off the calculation of rels substantially\n",
    "# logits, cache = model.run_with_cache(ioi_dataset.toks[0])\n",
    "# pre_layer_activations = [cache['blocks.' + str(i) + '.hook_resid_pre'] for i in range(12)]\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_sets, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32b2b05c-eee7-4a95-aef5-126b082ec550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_nodes = [r.source_node for r in outliers]\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[-1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run_new(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03fbfb5d-f7f7-497d-8cf3-91e417ce69ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(target_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d49e40ef-23d0-406a-880f-eef911bb601b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for target_decomp in target_decomps:\n",
    "    # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "    score = 0\n",
    "    for i in range(len(target_decomp.target_nodes)):\n",
    "        rels_magnitude = np.mean(abs(target_decomp.rels[i]))\n",
    "        if rels_magnitude > 0:\n",
    "            print('rels has something')\n",
    "        irrels_magnitude = np.mean(abs(target_decomp.irrels[i]))\n",
    "        target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "        score += target_node_score\n",
    "    results.append(Result(target_decomp.ablation_set[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b01dbf85-0148-4d56-9f14-4274fa3604c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=3, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=4, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=5, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=6, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=7, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=8, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=9, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=10, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=11, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=12, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=13, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=14, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=0, sequence_idx=15, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=3, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=4, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=5, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=6, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=7, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=8, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=9, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=10, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=11, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=12, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=13, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=14, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=1, sequence_idx=15, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=3, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=4, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=5, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=6, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=7, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=8, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=9, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=10, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=11, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=12, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=13, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=14, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=2, sequence_idx=15, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=3, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=4, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=5, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=6, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=7, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=8, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=9, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=10, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=11, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=12, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=13, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=14, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=3, sequence_idx=15, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=3, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=4, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=5, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=6, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=7, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=8, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=9, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=10, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=11, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=12, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=13, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=14, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=4, sequence_idx=15, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=0, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=1, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=3), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=4), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=5), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=6), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=7), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=8), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=9), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=10), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=2, attn_head_idx=11), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=3, attn_head_idx=0), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=3, attn_head_idx=1), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=3, attn_head_idx=2), score=0),\n",
       " Result(source_node=Node(layer_idx=5, sequence_idx=3, attn_head_idx=3), score=0),\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
