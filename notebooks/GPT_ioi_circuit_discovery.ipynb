{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61a0720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a120102",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extractListFromDic, readJson, combine_token_attn, compute_word_intervals, compare_same\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpathology\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcdt_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcdt_source_to_target\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mioi_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IOIDataset\n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_basic.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfancy_einsum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m einsum\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformer_lens\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleUtilsMixin\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# utility\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformer_lens/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hook_points\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evals\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformer_lens/hook_points.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Slice, SliceInput\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLensHandle\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Dataclass that holds information about a PyTorch hook.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformer_lens/utils.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjaxtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Float, Int\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mprint\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m rprint\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFactoredMatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FactoredMatrix\n\u001b[1;32m     31\u001b[0m CACHE_DIR \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTRANSFORMERS_CACHE\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/utils/import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/utils/import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1607\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1608\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/linux/miniforge-3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     albert,\n\u001b[1;32m     17\u001b[0m     align,\n\u001b[1;32m     18\u001b[0m     altclip,\n\u001b[1;32m     19\u001b[0m     audio_spectrogram_transformer,\n\u001b[1;32m     20\u001b[0m     auto,\n\u001b[1;32m     21\u001b[0m     autoformer,\n\u001b[1;32m     22\u001b[0m     bark,\n\u001b[1;32m     23\u001b[0m     bart,\n\u001b[1;32m     24\u001b[0m     barthez,\n\u001b[1;32m     25\u001b[0m     bartpho,\n\u001b[1;32m     26\u001b[0m     beit,\n\u001b[1;32m     27\u001b[0m     bert,\n\u001b[1;32m     28\u001b[0m     bert_generation,\n\u001b[1;32m     29\u001b[0m     bert_japanese,\n\u001b[1;32m     30\u001b[0m     bertweet,\n\u001b[1;32m     31\u001b[0m     big_bird,\n\u001b[1;32m     32\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     33\u001b[0m     biogpt,\n\u001b[1;32m     34\u001b[0m     bit,\n\u001b[1;32m     35\u001b[0m     blenderbot,\n\u001b[1;32m     36\u001b[0m     blenderbot_small,\n\u001b[1;32m     37\u001b[0m     blip,\n\u001b[1;32m     38\u001b[0m     blip_2,\n\u001b[1;32m     39\u001b[0m     bloom,\n\u001b[1;32m     40\u001b[0m     bridgetower,\n\u001b[1;32m     41\u001b[0m     bros,\n\u001b[1;32m     42\u001b[0m     byt5,\n\u001b[1;32m     43\u001b[0m     camembert,\n\u001b[1;32m     44\u001b[0m     canine,\n\u001b[1;32m     45\u001b[0m     chameleon,\n\u001b[1;32m     46\u001b[0m     chinese_clip,\n\u001b[1;32m     47\u001b[0m     clap,\n\u001b[1;32m     48\u001b[0m     clip,\n\u001b[1;32m     49\u001b[0m     clipseg,\n\u001b[1;32m     50\u001b[0m     clvp,\n\u001b[1;32m     51\u001b[0m     code_llama,\n\u001b[1;32m     52\u001b[0m     codegen,\n\u001b[1;32m     53\u001b[0m     cohere,\n\u001b[1;32m     54\u001b[0m     conditional_detr,\n\u001b[1;32m     55\u001b[0m     convbert,\n\u001b[1;32m     56\u001b[0m     convnext,\n\u001b[1;32m     57\u001b[0m     convnextv2,\n\u001b[1;32m     58\u001b[0m     cpm,\n\u001b[1;32m     59\u001b[0m     cpmant,\n\u001b[1;32m     60\u001b[0m     ctrl,\n\u001b[1;32m     61\u001b[0m     cvt,\n\u001b[1;32m     62\u001b[0m     data2vec,\n\u001b[1;32m     63\u001b[0m     dbrx,\n\u001b[1;32m     64\u001b[0m     deberta,\n\u001b[1;32m     65\u001b[0m     deberta_v2,\n\u001b[1;32m     66\u001b[0m     decision_transformer,\n\u001b[1;32m     67\u001b[0m     deformable_detr,\n\u001b[1;32m     68\u001b[0m     deit,\n\u001b[1;32m     69\u001b[0m     deprecated,\n\u001b[1;32m     70\u001b[0m     depth_anything,\n\u001b[1;32m     71\u001b[0m     detr,\n\u001b[1;32m     72\u001b[0m     dialogpt,\n\u001b[1;32m     73\u001b[0m     dinat,\n\u001b[1;32m     74\u001b[0m     dinov2,\n\u001b[1;32m     75\u001b[0m     distilbert,\n\u001b[1;32m     76\u001b[0m     dit,\n\u001b[1;32m     77\u001b[0m     donut,\n\u001b[1;32m     78\u001b[0m     dpr,\n\u001b[1;32m     79\u001b[0m     dpt,\n\u001b[1;32m     80\u001b[0m     efficientnet,\n\u001b[1;32m     81\u001b[0m     electra,\n\u001b[1;32m     82\u001b[0m     encodec,\n\u001b[1;32m     83\u001b[0m     encoder_decoder,\n\u001b[1;32m     84\u001b[0m     ernie,\n\u001b[1;32m     85\u001b[0m     esm,\n\u001b[1;32m     86\u001b[0m     falcon,\n\u001b[1;32m     87\u001b[0m     fastspeech2_conformer,\n\u001b[1;32m     88\u001b[0m     flaubert,\n\u001b[1;32m     89\u001b[0m     flava,\n\u001b[1;32m     90\u001b[0m     fnet,\n\u001b[1;32m     91\u001b[0m     focalnet,\n\u001b[1;32m     92\u001b[0m     fsmt,\n\u001b[1;32m     93\u001b[0m     funnel,\n\u001b[1;32m     94\u001b[0m     fuyu,\n\u001b[1;32m     95\u001b[0m     gemma,\n\u001b[1;32m     96\u001b[0m     gemma2,\n\u001b[1;32m     97\u001b[0m     git,\n\u001b[1;32m     98\u001b[0m     glpn,\n\u001b[1;32m     99\u001b[0m     gpt2,\n\u001b[1;32m    100\u001b[0m     gpt_bigcode,\n\u001b[1;32m    101\u001b[0m     gpt_neo,\n\u001b[1;32m    102\u001b[0m     gpt_neox,\n\u001b[1;32m    103\u001b[0m     gpt_neox_japanese,\n\u001b[1;32m    104\u001b[0m     gpt_sw3,\n\u001b[1;32m    105\u001b[0m     gptj,\n\u001b[1;32m    106\u001b[0m     grounding_dino,\n\u001b[1;32m    107\u001b[0m     groupvit,\n\u001b[1;32m    108\u001b[0m     herbert,\n\u001b[1;32m    109\u001b[0m     hiera,\n\u001b[1;32m    110\u001b[0m     hubert,\n\u001b[1;32m    111\u001b[0m     ibert,\n\u001b[1;32m    112\u001b[0m     idefics,\n\u001b[1;32m    113\u001b[0m     idefics2,\n\u001b[1;32m    114\u001b[0m     imagegpt,\n\u001b[1;32m    115\u001b[0m     informer,\n\u001b[1;32m    116\u001b[0m     instructblip,\n\u001b[1;32m    117\u001b[0m     instructblipvideo,\n\u001b[1;32m    118\u001b[0m     jamba,\n\u001b[1;32m    119\u001b[0m     jetmoe,\n\u001b[1;32m    120\u001b[0m     kosmos2,\n\u001b[1;32m    121\u001b[0m     layoutlm,\n\u001b[1;32m    122\u001b[0m     layoutlmv2,\n\u001b[1;32m    123\u001b[0m     layoutlmv3,\n\u001b[1;32m    124\u001b[0m     layoutxlm,\n\u001b[1;32m    125\u001b[0m     led,\n\u001b[1;32m    126\u001b[0m     levit,\n\u001b[1;32m    127\u001b[0m     lilt,\n\u001b[1;32m    128\u001b[0m     llama,\n\u001b[1;32m    129\u001b[0m     llava,\n\u001b[1;32m    130\u001b[0m     llava_next,\n\u001b[1;32m    131\u001b[0m     llava_next_video,\n\u001b[1;32m    132\u001b[0m     longformer,\n\u001b[1;32m    133\u001b[0m     longt5,\n\u001b[1;32m    134\u001b[0m     luke,\n\u001b[1;32m    135\u001b[0m     lxmert,\n\u001b[1;32m    136\u001b[0m     m2m_100,\n\u001b[1;32m    137\u001b[0m     mamba,\n\u001b[1;32m    138\u001b[0m     mamba2,\n\u001b[1;32m    139\u001b[0m     marian,\n\u001b[1;32m    140\u001b[0m     markuplm,\n\u001b[1;32m    141\u001b[0m     mask2former,\n\u001b[1;32m    142\u001b[0m     maskformer,\n\u001b[1;32m    143\u001b[0m     mbart,\n\u001b[1;32m    144\u001b[0m     mbart50,\n\u001b[1;32m    145\u001b[0m     megatron_bert,\n\u001b[1;32m    146\u001b[0m     megatron_gpt2,\n\u001b[1;32m    147\u001b[0m     mgp_str,\n\u001b[1;32m    148\u001b[0m     mistral,\n\u001b[1;32m    149\u001b[0m     mixtral,\n\u001b[1;32m    150\u001b[0m     mluke,\n\u001b[1;32m    151\u001b[0m     mobilebert,\n\u001b[1;32m    152\u001b[0m     mobilenet_v1,\n\u001b[1;32m    153\u001b[0m     mobilenet_v2,\n\u001b[1;32m    154\u001b[0m     mobilevit,\n\u001b[1;32m    155\u001b[0m     mobilevitv2,\n\u001b[1;32m    156\u001b[0m     mpnet,\n\u001b[1;32m    157\u001b[0m     mpt,\n\u001b[1;32m    158\u001b[0m     mra,\n\u001b[1;32m    159\u001b[0m     mt5,\n\u001b[1;32m    160\u001b[0m     musicgen,\n\u001b[1;32m    161\u001b[0m     musicgen_melody,\n\u001b[1;32m    162\u001b[0m     mvp,\n\u001b[1;32m    163\u001b[0m     nemotron,\n\u001b[1;32m    164\u001b[0m     nllb,\n\u001b[1;32m    165\u001b[0m     nllb_moe,\n\u001b[1;32m    166\u001b[0m     nougat,\n\u001b[1;32m    167\u001b[0m     nystromformer,\n\u001b[1;32m    168\u001b[0m     olmo,\n\u001b[1;32m    169\u001b[0m     oneformer,\n\u001b[1;32m    170\u001b[0m     openai,\n\u001b[1;32m    171\u001b[0m     opt,\n\u001b[1;32m    172\u001b[0m     owlv2,\n\u001b[1;32m    173\u001b[0m     owlvit,\n\u001b[1;32m    174\u001b[0m     paligemma,\n\u001b[1;32m    175\u001b[0m     patchtsmixer,\n\u001b[1;32m    176\u001b[0m     patchtst,\n\u001b[1;32m    177\u001b[0m     pegasus,\n\u001b[1;32m    178\u001b[0m     pegasus_x,\n\u001b[1;32m    179\u001b[0m     perceiver,\n\u001b[1;32m    180\u001b[0m     persimmon,\n\u001b[1;32m    181\u001b[0m     phi,\n\u001b[1;32m    182\u001b[0m     phi3,\n\u001b[1;32m    183\u001b[0m     phobert,\n\u001b[1;32m    184\u001b[0m     pix2struct,\n\u001b[1;32m    185\u001b[0m     plbart,\n\u001b[1;32m    186\u001b[0m     poolformer,\n\u001b[1;32m    187\u001b[0m     pop2piano,\n\u001b[1;32m    188\u001b[0m     prophetnet,\n\u001b[1;32m    189\u001b[0m     pvt,\n\u001b[1;32m    190\u001b[0m     pvt_v2,\n\u001b[1;32m    191\u001b[0m     qwen2,\n\u001b[1;32m    192\u001b[0m     qwen2_moe,\n\u001b[1;32m    193\u001b[0m     rag,\n\u001b[1;32m    194\u001b[0m     recurrent_gemma,\n\u001b[1;32m    195\u001b[0m     reformer,\n\u001b[1;32m    196\u001b[0m     regnet,\n\u001b[1;32m    197\u001b[0m     rembert,\n\u001b[1;32m    198\u001b[0m     resnet,\n\u001b[1;32m    199\u001b[0m     roberta,\n\u001b[1;32m    200\u001b[0m     roberta_prelayernorm,\n\u001b[1;32m    201\u001b[0m     roc_bert,\n\u001b[1;32m    202\u001b[0m     roformer,\n\u001b[1;32m    203\u001b[0m     rt_detr,\n\u001b[1;32m    204\u001b[0m     rwkv,\n\u001b[1;32m    205\u001b[0m     sam,\n\u001b[1;32m    206\u001b[0m     seamless_m4t,\n\u001b[1;32m    207\u001b[0m     seamless_m4t_v2,\n\u001b[1;32m    208\u001b[0m     segformer,\n\u001b[1;32m    209\u001b[0m     seggpt,\n\u001b[1;32m    210\u001b[0m     sew,\n\u001b[1;32m    211\u001b[0m     sew_d,\n\u001b[1;32m    212\u001b[0m     siglip,\n\u001b[1;32m    213\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    214\u001b[0m     speech_to_text,\n\u001b[1;32m    215\u001b[0m     speecht5,\n\u001b[1;32m    216\u001b[0m     splinter,\n\u001b[1;32m    217\u001b[0m     squeezebert,\n\u001b[1;32m    218\u001b[0m     stablelm,\n\u001b[1;32m    219\u001b[0m     starcoder2,\n\u001b[1;32m    220\u001b[0m     superpoint,\n\u001b[1;32m    221\u001b[0m     swiftformer,\n\u001b[1;32m    222\u001b[0m     swin,\n\u001b[1;32m    223\u001b[0m     swin2sr,\n\u001b[1;32m    224\u001b[0m     swinv2,\n\u001b[1;32m    225\u001b[0m     switch_transformers,\n\u001b[1;32m    226\u001b[0m     t5,\n\u001b[1;32m    227\u001b[0m     table_transformer,\n\u001b[1;32m    228\u001b[0m     tapas,\n\u001b[1;32m    229\u001b[0m     time_series_transformer,\n\u001b[1;32m    230\u001b[0m     timesformer,\n\u001b[1;32m    231\u001b[0m     timm_backbone,\n\u001b[1;32m    232\u001b[0m     trocr,\n\u001b[1;32m    233\u001b[0m     tvp,\n\u001b[1;32m    234\u001b[0m     udop,\n\u001b[1;32m    235\u001b[0m     umt5,\n\u001b[1;32m    236\u001b[0m     unispeech,\n\u001b[1;32m    237\u001b[0m     unispeech_sat,\n\u001b[1;32m    238\u001b[0m     univnet,\n\u001b[1;32m    239\u001b[0m     upernet,\n\u001b[1;32m    240\u001b[0m     video_llava,\n\u001b[1;32m    241\u001b[0m     videomae,\n\u001b[1;32m    242\u001b[0m     vilt,\n\u001b[1;32m    243\u001b[0m     vipllava,\n\u001b[1;32m    244\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    245\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    246\u001b[0m     visual_bert,\n\u001b[1;32m    247\u001b[0m     vit,\n\u001b[1;32m    248\u001b[0m     vit_mae,\n\u001b[1;32m    249\u001b[0m     vit_msn,\n\u001b[1;32m    250\u001b[0m     vitdet,\n\u001b[1;32m    251\u001b[0m     vitmatte,\n\u001b[1;32m    252\u001b[0m     vits,\n\u001b[1;32m    253\u001b[0m     vivit,\n\u001b[1;32m    254\u001b[0m     wav2vec2,\n\u001b[1;32m    255\u001b[0m     wav2vec2_bert,\n\u001b[1;32m    256\u001b[0m     wav2vec2_conformer,\n\u001b[1;32m    257\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    258\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    259\u001b[0m     wavlm,\n\u001b[1;32m    260\u001b[0m     whisper,\n\u001b[1;32m    261\u001b[0m     x_clip,\n\u001b[1;32m    262\u001b[0m     xglm,\n\u001b[1;32m    263\u001b[0m     xlm,\n\u001b[1;32m    264\u001b[0m     xlm_roberta,\n\u001b[1;32m    265\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    266\u001b[0m     xlnet,\n\u001b[1;32m    267\u001b[0m     xmod,\n\u001b[1;32m    268\u001b[0m     yolos,\n\u001b[1;32m    269\u001b[0m     yoso,\n\u001b[1;32m    270\u001b[0m     zoedepth,\n\u001b[1;32m    271\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is for if we're trying to execute on a remote JupyterHub, where the pwd is set to the server root, or else I think pwd is set correctly already.\n",
    "# %cd CD_Circuit/\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# CD-T Imports\n",
    "import math\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson, combine_token_attn, compute_word_intervals, compare_same\n",
    "from pyfunctions.pathology import extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from pyfunctions.wrappers import Node, AblationSet\n",
    "\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651660-7f59-4b59-a574-afecc52dc306",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Load Model\n",
    "\n",
    "Note: Unlike with the BERT model + medical dataset objective, it is not necessary to pretrain GPT-2 to perform the IOI dataset.\n",
    "GPT-2-small is already capable of performing IOI; that's part of the point of the Mech Interp in the Wild paper.\n",
    "We only need to examine how it does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520f760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "# Model code adapted from Callum McDougall's notebook for ARENA on reproducing the IOI paper using TransformerLens.\n",
    "# This makes some sense, since EasyTransformer, the repo/lib released by the IOI guys, was forked from TransformerLens.\n",
    "# In fact, this makes the reproduction a little bit more faithful, since they most likely do certain things such as \n",
    "# \"folding\" LayerNorms to improve their interpretability results, and we are able to do the same by using TransformerLens.\n",
    "# HuggingFace, by contrast, has the most impenetrable docs and tons of outdated APIs and etc.; even their source \n",
    "# code is impossible to traverse, and I gave up on it, thankfully quickly.\n",
    "\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",\n",
    "                                          center_unembed=True,\n",
    "                                          center_writing_weights=True,\n",
    "                                          fold_ln=False,\n",
    "                                          refactor_factored_attn_matrices=True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffd4d3-5e8f-4587-bb2a-f06b61918c09",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Generate mean activations\n",
    "\n",
    "This is not as simple as it sounds; for the IOI paper, for each individual input following a template, they ablate using the mean activations of the \"ABC\" dataset, generated over sentences following the same template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab88048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "\n",
    "# Generate a dataset all consisting of one template, randomly chosen.\n",
    "# nb_templates = 2 due to some logic internal to IOIDataset:\n",
    "# essentially, the nouns can be an ABBA or ABAB order and that counts as separate templates.\n",
    "ioi_dataset = IOIDataset(prompt_type=\"mixed\", N=50, tokenizer=model.tokenizer, prepend_bos=False, nb_templates=2)\n",
    "\n",
    "# This is the P_ABC that is mentioned in the IOI paper, which we use for mean ablation.\n",
    "# Importantly, passing in prompt_type=\"ABC\" or similar is NOT the same thing as this.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "\n",
    "logits, cache = model.run_with_cache(abc_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "attention_outputs = [cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(12)]\n",
    "attention_outputs = torch.stack(attention_outputs, dim=1) # now batch, layer, seq, n_heads, dim_attn\n",
    "mean_acts = torch.mean(attention_outputs, dim=0)\n",
    "old_shape = mean_acts.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "mean_acts = mean_acts.view(new_shape)\n",
    "mean_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c32de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# source_list = [Node(0, 0, 0), Node(1, 1, 1)]\n",
    "# target_nodes = [(7, 0, 1)]\n",
    "\n",
    "text = ioi_dataset.sentences[0]\n",
    "encoding = model.tokenizer.encode_plus(text, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "# out_decomps, target_decomps, _ = prop_GPT(encoding_idxs, extended_attention_mask, model, source_list, target_nodes, mean_acts=mean_acts, set_irrel_to_mean=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851670c7-28fd-447a-a9d8-16b8c87b1ac4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Algorithm A (the one found in the current paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758995f-1b99-4ed8-aeaa-0612767fa13e",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Run on last sequence position specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4c809f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 144)\n",
      "Running inputs 64 to 128 (of 144)\n",
      "Running inputs 128 to 144 (of 144)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [input_shape[1] - 2],\n",
    "        # [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376f5a9-9ae5-487d-9a33-7191e95a14e7",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Ablate all heads at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "024c7432-ea39-4f90-b0cf-52663a515f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 180)\n",
      "Running inputs 64 to 128 (of 180)\n",
      "Running inputs 128 to 180 (of 180)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "'''\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        # [input_shape[1] - 2],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "'''\n",
    "ablation_sets = []\n",
    "for layer in range(12):\n",
    "    for seq_idx in range(15):\n",
    "        ablation_sets.append(tuple(Node(layer, seq_idx, x) for x in range(12)))\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea7c8f-a673-4b44-b9a9-d8e7615b3ec5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Do the normal thing and ablate at all individual spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f4466-63c4-41e5-85dc-cec4da4dadac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2e4613-362f-480e-95fb-4f353ac3a845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running input 0\n",
      "running input 1600\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b6f2e3-76e4-4f71-8f57-a87e6cbea335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logits_decomposition_scores(out_decomps):\n",
    "    logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "    io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    full_score = np.abs(io_logit - s_logit)\n",
    "    assert(full_score > 0) # this needs to be replaced with a check higher in the pipeline; GPT2 succeeds at this like 99%+ of the time but not always\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for decomp in out_decomps:\n",
    "        rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "        rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "        score = rel_io_logit - rel_s_logit\n",
    "        norm_score = score / full_score\n",
    "        # predicted_probs = torch.nn.functional.softmax(torch.Tensor(decomp.rel[0][-2])).cpu().numpy()\n",
    "        # score = -np.log(predicted_probs[ioi_dataset.io_tokenIDs[0]]) # KL divergence from one-hot distribution\n",
    "        results.append(Result(decomp.ablation_set, score))\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca897ab1-f348-4a6e-a43a-96f0fc30c0ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_decomps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m compute_logits_decomposition_scores(\u001b[43mout_decomps\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[:\u001b[38;5;241m10\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_decomps' is not defined"
     ]
    }
   ],
   "source": [
    "results = compute_logits_decomposition_scores(out_decomps)\n",
    "\n",
    "for result in results[:10]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4401803-697d-4dc3-8212-fd99658257a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6) 0.12152111\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=10) 0.0822009\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=9) 0.07783296\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=10) 0.07362208\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=3) 0.071159504\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3) 0.07108998\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=9) 0.06943682\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9) 0.06770895\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=9) 0.06574008\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=6) 0.06536073\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=3) 0.06427851\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=9) 0.0599772\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=3) 0.057893638\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=10) 0.057380237\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=10) 0.0559245\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=6) 0.055904876\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=6) 0.05554507\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10) 0.055238955\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=9) 0.05293593\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=3) 0.051339425\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=6) 0.04840822\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=3) 0.046866648\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=3) 0.04618334\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9) 0.045930613\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10) 0.045326427\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=3) 0.04518606\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=3) 0.044725828\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6) 0.043644518\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=3) 0.042973924\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=9) 0.04256318\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=3) 0.042094387\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=3) 0.038879924\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=9) 0.037446495\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=6) 0.03675412\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=10) 0.034736432\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=10) 0.03429487\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=10) 0.03385796\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=6) 0.03225233\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10) 0.031825617\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=6) 0.031171506\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=6) 0.029102717\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=10) 0.028458526\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=10) 0.028269619\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=9) 0.023748085\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=9) 0.021111524\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=10) 0.017978825\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=3) 0.017961964\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=6) 0.017358523\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=9) 0.01682583\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=6) 0.0133941285\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=3) 0.0130641535\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=9) 0.013008005\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=9) 0.012716658\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=3) 0.011983796\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=6) 0.011983144\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=9) 0.010926103\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=10) 0.009415353\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=6) 0.0072015882\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=10) 0.0069930064\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=6) 0.0061120763\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=3) 0.0\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=9) 0.0\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=6) 0.0\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=10) 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for result in results[:20]:\n",
    "    print(result.ablation_set[0], result.score)\n",
    "'''\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 9 and result.ablation_set[0].attn_head_idx == 9:\n",
    "        print(result.ablation_set[0], result.score)\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "            print(result.ablation_set[0], result.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08ce1ab7-79e2-4c79-9ef9-09b75249e5dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03560574 0.05491805\n"
     ]
    }
   ],
   "source": [
    "scores = [r.score for r in results if r.score > 0]\n",
    "std_dev = np.std(scores)\n",
    "mean = np.mean(scores)\n",
    "print(std_dev, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce463474-bb7b-42c5-84bc-8fac38699c14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c7f07b99-40b1-4563-bbce-478cc6307baa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Contribution')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "scores = [result.score for result in results]\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.hist(scores, density=False, bins=192)\n",
    "plt.ylabel('Example Count')\n",
    "plt.xlabel('Contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ff1e97-c772-4063-8b4c-e9705185498e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "def interquartile_range(results, iqr_multiplier=1):\n",
    "    # assume sorted in increasing order\n",
    "    third_quartile = results[int(len(results) * 0.75)].score\n",
    "    first_quartile = results[int(len(results) * 0.25)].score\n",
    "    IQR = third_quartile - first_quartile\n",
    "    outlier_score = third_quartile + iqr_multiplier * IQR\n",
    "    print(third_quartile, first_quartile, outlier_score)\n",
    "\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):]\n",
    "    return outliers\n",
    "\n",
    "def n_sigma_rule(results, n=3):\n",
    "    scores = [r.score for r in results]\n",
    "    std_dev = np.std(scores)\n",
    "    mean = np.mean(scores)\n",
    "    outlier_score = mean + std_dev * n\n",
    "    print(std_dev, mean, outlier_score)\n",
    "    by_score = operator.attrgetter('score')\n",
    "    outliers = results[bisect.bisect(results, outlier_score, key=by_score):] #bisect does a binary search, returns idx of outlier_score\n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92ef27aa-343c-42ce-8a25-0af8f4418e22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11498.65576171875\n",
      "12060.0\n",
      "882.81982421875\n",
      "1212.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(0)/1024/1024)\n",
    "print(torch.cuda.memory_reserved(0)/1024/1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "600b77bd-5aa7-4a6c-b0d9-35194fb8dffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ioi_dataset.word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa79dc-7214-4d32-99d0-601f732975db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 16, 12, 64])\n",
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "mean_acts_per_head = mean_acts.view(old_shape)\n",
    "print(mean_acts_per_head.shape)\n",
    "print(target_decomps[0].rels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef834df-fb0e-445a-bb34-01727ae9624c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fb521-d084-45e3-9f09-04cfc01eaec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_logits, ioi_cache = model.run_with_cache(ioi_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "ioi_cache['blocks.' + '0' + '.attn.hook_z'][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726588c-4b64-4824-9780-43a0a713b1fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=3) tensor(2.8631, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=2, attn_head_idx=9) tensor(2.5057, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=10) tensor(2.3456, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3) tensor(2.1374, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6) tensor(2.0232, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=9) tensor(1.5772, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=10) tensor(1.5526, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=10) tensor(1.4639, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9) tensor(1.2003, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=2, attn_head_idx=6) tensor(1.1704, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=10, attn_head_idx=6) tensor(1.1144, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9) tensor(0.9955, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=9) tensor(0.9087, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=3) tensor(0.9014, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=3) tensor(0.8035, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=1, attn_head_idx=9) tensor(0.8001, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=10) tensor(0.7452, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=14, attn_head_idx=3) tensor(0.6968, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=10) tensor(0.6146, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=3) tensor(0.6018, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=9) tensor(0.6002, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=3) tensor(0.5847, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=10) tensor(0.5632, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=3) tensor(0.5181, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=3) tensor(0.5171, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=6, attn_head_idx=9) tensor(0.5040, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=4, attn_head_idx=9) tensor(0.4911, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=10, attn_head_idx=3) tensor(0.4827, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=4, attn_head_idx=6) tensor(0.4606, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=7, attn_head_idx=9) tensor(0.4386, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=5, attn_head_idx=9) tensor(0.3821, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6) tensor(0.3639, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=6, attn_head_idx=6) tensor(0.3592, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=9) tensor(0.2922, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=9, attn_head_idx=3) tensor(0.2882, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=9) tensor(0.2731, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=10) tensor(0.2642, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=3) tensor(0.2243, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=13, attn_head_idx=3) tensor(0.2014, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10) tensor(0.1696, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=6) tensor(0.1240, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=10) tensor(0.1199, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=5, attn_head_idx=6) tensor(0.1156, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=6) tensor(0.1136, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=8, attn_head_idx=9) tensor(0.0754, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10) tensor(0.0434, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=12, attn_head_idx=6) tensor(0.0395, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=7, attn_head_idx=6) tensor(0.0146, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=9) tensor(0.0125, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10) tensor(0.0039, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=3) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=15, attn_head_idx=9) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=6) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=15, attn_head_idx=10) tensor(0., device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=12, attn_head_idx=3) tensor(-0.0045, device='cuda:0')\n",
      "Node(layer_idx=7, sequence_idx=0, attn_head_idx=3) tensor(-0.0047, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=6) tensor(-0.0170, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=0, attn_head_idx=10) tensor(-0.0289, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=10) tensor(-0.0747, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=1, attn_head_idx=6) tensor(-0.0801, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=13, attn_head_idx=10) tensor(-0.0818, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=9, attn_head_idx=10) tensor(-0.1042, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=8, attn_head_idx=6) tensor(-0.1684, device='cuda:0')\n",
      "Node(layer_idx=8, sequence_idx=3, attn_head_idx=6) tensor(-0.9836, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "results[:50]\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "        print(result.ablation_set[0], result.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb15008-7d61-4bfd-b0e4-7126bd08951a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_per_iter = []\n",
    "results_per_iter = [results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2653251-9d90-4115-a531-476e42f741db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers = results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b66c9215-27fd-42ca-8a1a-584bf5a24cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers = results[:2] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32b2b05c-eee7-4a95-aef5-126b082ec550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=1, sequence_idx=3, attn_head_idx=7), Node(layer_idx=1, sequence_idx=3, attn_head_idx=10)]\n",
      "Running inputs 0 to 64 (of 2304)\n",
      "Running inputs 64 to 128 (of 2304)\n",
      "Running inputs 128 to 192 (of 2304)\n",
      "Running inputs 192 to 256 (of 2304)\n",
      "Running inputs 256 to 320 (of 2304)\n",
      "Running inputs 320 to 384 (of 2304)\n",
      "Running inputs 384 to 448 (of 2304)\n",
      "Running inputs 448 to 512 (of 2304)\n",
      "Running inputs 512 to 576 (of 2304)\n",
      "Running inputs 576 to 640 (of 2304)\n",
      "Running inputs 640 to 704 (of 2304)\n",
      "Running inputs 704 to 768 (of 2304)\n",
      "Running inputs 768 to 832 (of 2304)\n",
      "Running inputs 832 to 896 (of 2304)\n",
      "Running inputs 896 to 960 (of 2304)\n",
      "Running inputs 960 to 1024 (of 2304)\n",
      "Running inputs 1024 to 1088 (of 2304)\n",
      "Running inputs 1088 to 1152 (of 2304)\n",
      "Running inputs 1152 to 1216 (of 2304)\n",
      "Running inputs 1216 to 1280 (of 2304)\n",
      "Running inputs 1280 to 1344 (of 2304)\n",
      "Running inputs 1344 to 1408 (of 2304)\n",
      "Running inputs 1408 to 1472 (of 2304)\n",
      "Running inputs 1472 to 1536 (of 2304)\n",
      "Running inputs 1536 to 1600 (of 2304)\n",
      "Running inputs 1600 to 1664 (of 2304)\n",
      "Running inputs 1664 to 1728 (of 2304)\n",
      "Running inputs 1728 to 1792 (of 2304)\n",
      "Running inputs 1792 to 1856 (of 2304)\n",
      "Running inputs 1856 to 1920 (of 2304)\n",
      "Running inputs 1920 to 1984 (of 2304)\n",
      "Running inputs 1984 to 2048 (of 2304)\n",
      "Running inputs 2048 to 2112 (of 2304)\n",
      "Running inputs 2112 to 2176 (of 2304)\n",
      "Running inputs 2176 to 2240 (of 2304)\n",
      "Running inputs 2240 to 2304 (of 2304)\n"
     ]
    }
   ],
   "source": [
    "# Now, find maximally relevant source nodes to target nodes\n",
    "\n",
    "# TODO: this needs to be put in a loop to implement the \"actual\" algorithm, currently it's just for analysis\n",
    "# results.sort(key=operator.attrgetter('score'), reverse=False)|\n",
    "# iqr = interquartile_range(results)\n",
    "# print(len(iqr))\n",
    "# outliers = n_sigma_rule(results, n=0.5)\n",
    "# print(len(outliers))\n",
    "\n",
    "# results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = results[:2] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(16)],\n",
    "        # [ioi_dataset.word_idx['IO'][0]],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebab7b5-5f80-40b6-98f1-bccf4a16274a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_target_decomposition_scores(target_decomps, method=\"l1\", mean_acts=None, attn_cache=None):\n",
    "    results = []\n",
    "    # for target_decomp in target_decomps:\n",
    "\n",
    "    # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "    # other ideas to try:\n",
    "    # normalize mean relevance by layer # does get rid of the \"early layers thing\", but many nodes are about as relevant as the ones identified by IOI\n",
    "    # try a better target decomposition metric: for example, dot product with the rel of the previous iter (which makes more sense)? # actually made the results worse?\n",
    "    # try some measure of indirect conections rather than just direct connections\n",
    "    relevances = np.zeros((12, 16, 12))\n",
    "    for layer in range(12):\n",
    "        for sequence_position in range(16):\n",
    "            for attention_head_idx in range(12):\n",
    "                idx = layer * 16 * 12 + sequence_position * 12 + attention_head_idx\n",
    "                target_decomp = target_decomps[idx]\n",
    "                if target_decomp.ablation_set[0] in target_nodes:\n",
    "                    continue\n",
    "                score = 0\n",
    "                for i in range(len(target_decomp.target_nodes)):\n",
    "                    if method == 'l1':\n",
    "                        rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "                        irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "                        target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "                        score += target_node_score\n",
    "                    if method == 'dot':\n",
    "                        target_node = target_decomp.target_nodes[i]\n",
    "                        # this method is only implemented for a single datapoint\n",
    "                        if mean_acts is None or attn_cache is None:\n",
    "                            print(\"Invalid target decomposition score calculation\") # and then this is going to crash anyway\n",
    "                        target_mean_act = mean_acts[target_node.layer_idx, target_node.sequence_idx, target_node.attn_head_idx]\n",
    "                        target_rel = attn_cache['blocks.' + str(target_node.layer_idx) + '.attn.hook_z'][0][target_node.sequence_idx][target_node.attn_head_idx] - target_mean_act \n",
    "                        rel = target_decomp.rels[i][0]\n",
    "                        #print(target_rel.shape, rel.shape)\n",
    "                        score += torch.dot(rel, target_rel)\n",
    "                relevances[layer, sequence_position, attention_head_idx] = score\n",
    "\n",
    "\n",
    "    sums_per_layer = np.sum(relevances, axis=(1, 2))\n",
    "    sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "    normalized_relevances = relevances / np.expand_dims(sums_per_layer, (1, 2))\n",
    "\n",
    "    num_layers = 12\n",
    "    seq_len = 16\n",
    "    num_attention_heads = 12\n",
    "    for layer_idx in range(num_layers):\n",
    "        for seq_pos in range(seq_len):\n",
    "            for head_idx in range(num_attention_heads):\n",
    "                target_decomp = target_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "                results.append(Result(target_decomp.ablation_set, normalized_relevances[layer_idx, seq_pos, head_idx]))\n",
    "\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfc2e598-fe82-4e3f-b901-f61176417a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_per_iter.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ecd696fa-86b4-4ba3-862f-9be581d67a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Result(ablation_set=(Node(layer_idx=8, sequence_idx=14, attn_head_idx=6),), score=0.03813974573802492),\n",
       "  Result(ablation_set=(Node(layer_idx=8, sequence_idx=11, attn_head_idx=6),), score=0.034177570085989574)],\n",
       " [Result(ablation_set=(Node(layer_idx=8, sequence_idx=14, attn_head_idx=6),), score=0.03813974573802492),\n",
       "  Result(ablation_set=(Node(layer_idx=8, sequence_idx=11, attn_head_idx=6),), score=0.034177570085989574)],\n",
       " [Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=9),), score=0.87486565),\n",
       "  Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=6),), score=0.37573943)],\n",
       " [Result(ablation_set=(Node(layer_idx=8, sequence_idx=14, attn_head_idx=6),), score=0.03813974573802492),\n",
       "  Result(ablation_set=(Node(layer_idx=8, sequence_idx=11, attn_head_idx=6),), score=0.034177570085989574)],\n",
       " [Result(ablation_set=(Node(layer_idx=5, sequence_idx=10, attn_head_idx=5),), score=0.02986675545961833),\n",
       "  Result(ablation_set=(Node(layer_idx=7, sequence_idx=11, attn_head_idx=9),), score=0.02952390684446772)],\n",
       " [Result(ablation_set=(Node(layer_idx=6, sequence_idx=10, attn_head_idx=9),), score=0.04139306313448273),\n",
       "  Result(ablation_set=(Node(layer_idx=6, sequence_idx=11, attn_head_idx=0),), score=0.03349508347071345)],\n",
       " [Result(ablation_set=(Node(layer_idx=5, sequence_idx=10, attn_head_idx=5),), score=0.11361695632022674),\n",
       "  Result(ablation_set=(Node(layer_idx=5, sequence_idx=10, attn_head_idx=9),), score=0.05332546980497713)],\n",
       " [Result(ablation_set=(Node(layer_idx=3, sequence_idx=10, attn_head_idx=0),), score=0.038520373769848806),\n",
       "  Result(ablation_set=(Node(layer_idx=4, sequence_idx=5, attn_head_idx=11),), score=0.02788752213108418)],\n",
       " [Result(ablation_set=(Node(layer_idx=3, sequence_idx=5, attn_head_idx=7),), score=0.05608457333323692),\n",
       "  Result(ablation_set=(Node(layer_idx=3, sequence_idx=3, attn_head_idx=6),), score=0.05386950067347974)],\n",
       " [Result(ablation_set=(Node(layer_idx=2, sequence_idx=3, attn_head_idx=2),), score=0.10140302955641779),\n",
       "  Result(ablation_set=(Node(layer_idx=2, sequence_idx=3, attn_head_idx=9),), score=0.05820936329902795)],\n",
       " [Result(ablation_set=(Node(layer_idx=1, sequence_idx=3, attn_head_idx=7),), score=0.081322716382124),\n",
       "  Result(ablation_set=(Node(layer_idx=1, sequence_idx=3, attn_head_idx=10),), score=0.06703445480573866)],\n",
       " [Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=0.08746183454945368),\n",
       "  Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=0.07542276779756175)]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "587a4627-5729-4810-aaad-5445007a9869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=0.08746183454945368)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=0.07542276779756175)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=3, attn_head_idx=6),), score=0.07055409286121249)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=0.06713339385727347)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=0.05414199889043761)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=3, attn_head_idx=7),), score=0.049619719961781564)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=6),), score=0.04932286453511382)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=0.046369913283579374)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=3, attn_head_idx=0),), score=0.042463772022659954)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=3, attn_head_idx=4),), score=0.03883541583656693)\n"
     ]
    }
   ],
   "source": [
    "for result in results[:10]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15844abd-6da0-491c-b8f3-b58444a0f11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_nodes = []\n",
    "for it in outliers_per_iter:\n",
    "    for result in it:\n",
    "        if result.ablation_set[0] not in all_nodes:\n",
    "            all_nodes.append(result.ablation_set[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e6b3651f-71b7-4e4a-a8a2-ea39529292e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=8, sequence_idx=14, attn_head_idx=6)\n",
      "Node(layer_idx=8, sequence_idx=11, attn_head_idx=6)\n",
      "Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)\n",
      "Node(layer_idx=9, sequence_idx=14, attn_head_idx=6)\n",
      "Node(layer_idx=5, sequence_idx=10, attn_head_idx=5)\n",
      "Node(layer_idx=7, sequence_idx=11, attn_head_idx=9)\n",
      "Node(layer_idx=6, sequence_idx=10, attn_head_idx=9)\n",
      "Node(layer_idx=6, sequence_idx=11, attn_head_idx=0)\n",
      "Node(layer_idx=5, sequence_idx=10, attn_head_idx=9)\n",
      "Node(layer_idx=3, sequence_idx=10, attn_head_idx=0)\n",
      "Node(layer_idx=4, sequence_idx=5, attn_head_idx=11)\n",
      "Node(layer_idx=3, sequence_idx=5, attn_head_idx=7)\n",
      "Node(layer_idx=3, sequence_idx=3, attn_head_idx=6)\n",
      "Node(layer_idx=2, sequence_idx=3, attn_head_idx=2)\n",
      "Node(layer_idx=2, sequence_idx=3, attn_head_idx=9)\n",
      "Node(layer_idx=1, sequence_idx=3, attn_head_idx=7)\n",
      "Node(layer_idx=1, sequence_idx=3, attn_head_idx=10)\n",
      "Node(layer_idx=0, sequence_idx=2, attn_head_idx=1)\n",
      "Node(layer_idx=0, sequence_idx=2, attn_head_idx=4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bbc363b2-7433-4dae-be19-c2e8eed6cc75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=8, sequence_idx=14, attn_head_idx=6), Node(layer_idx=8, sequence_idx=11, attn_head_idx=6), Node(layer_idx=9, sequence_idx=14, attn_head_idx=9), Node(layer_idx=9, sequence_idx=14, attn_head_idx=6), Node(layer_idx=5, sequence_idx=10, attn_head_idx=5), Node(layer_idx=7, sequence_idx=11, attn_head_idx=9), Node(layer_idx=6, sequence_idx=10, attn_head_idx=9), Node(layer_idx=6, sequence_idx=11, attn_head_idx=0), Node(layer_idx=5, sequence_idx=10, attn_head_idx=9), Node(layer_idx=3, sequence_idx=10, attn_head_idx=0), Node(layer_idx=4, sequence_idx=5, attn_head_idx=11), Node(layer_idx=3, sequence_idx=5, attn_head_idx=7), Node(layer_idx=3, sequence_idx=3, attn_head_idx=6), Node(layer_idx=2, sequence_idx=3, attn_head_idx=2), Node(layer_idx=2, sequence_idx=3, attn_head_idx=9), Node(layer_idx=1, sequence_idx=3, attn_head_idx=7), Node(layer_idx=1, sequence_idx=3, attn_head_idx=10), Node(layer_idx=0, sequence_idx=2, attn_head_idx=1), Node(layer_idx=0, sequence_idx=2, attn_head_idx=4)]\n"
     ]
    }
   ],
   "source": [
    "print(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "393967e8-2f0d-4c38-ae0b-cf6a74d1cafb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, Megan and Ashley went to the restaurant. Megan gave a kiss to Ashley\n"
     ]
    }
   ],
   "source": [
    "print(ioi_dataset.sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d009fec2-10bf-41c0-93f6-3786a7121aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e32e8-925d-4285-b6db-d54e6854a531",
   "metadata": {},
   "source": [
    "## Automatic search\n",
    "\n",
    "This is just a bunch of the above cells put into a neat cell that does the whole experiment in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df1abe1f-c241-4fa8-a367-0c823f9fd5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ioi_dataset = IOIDataset(N=50, tokenizer=model.tokenizer, prepend_bos=False, prompt_type=[template])\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05babeb3-e7fb-414b-8ad4-0701b77cfd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length: 16 \n",
      "running input 0\n",
      "running input 1600\n",
      "[Node(layer_idx=9, sequence_idx=14, attn_head_idx=9), Node(layer_idx=10, sequence_idx=14, attn_head_idx=10)]\n",
      "running input 0\n",
      "running input 1600\n",
      "[Node(layer_idx=9, sequence_idx=14, attn_head_idx=6), Node(layer_idx=9, sequence_idx=2, attn_head_idx=6)]\n",
      "running input 0\n",
      "running input 1600\n",
      "[Node(layer_idx=0, sequence_idx=1, attn_head_idx=1), Node(layer_idx=0, sequence_idx=1, attn_head_idx=4)]\n"
     ]
    }
   ],
   "source": [
    "from pyfunctions.ioi_dataset import ABC_TEMPLATES, BAC_TEMPLATES, BABA_TEMPLATES, BABA_LONG_TEMPLATES, BABA_LATE_IOS, BABA_EARLY_IOS, ABBA_TEMPLATES, ABBA_LATE_IOS, ABBA_EARLY_IOS\n",
    "\n",
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "NUM_SAMPLES = 1\n",
    "NUM_OUTLIERS_TO_KEEP_PER_ITER = 2\n",
    "template = ABBA_EARLY_IOS[0]\n",
    "ioi_dataset = IOIDataset(N=50, tokenizer=model.tokenizer, prepend_bos=False, prompt_type=[template])\n",
    "\n",
    "# This is the P_ABC that is mentioned in the IOI paper, which we use for mean ablation.\n",
    "# Importantly, passing in prompt_type=\"ABC\" or similar is NOT the same thing as this.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "ioi_logits, ioi_cache = model.run_with_cache(ioi_dataset.toks) # run on entire dataset along batch dimension\n",
    "logits, cache = model.run_with_cache(abc_dataset.toks) # run on entire dataset along batch dimension\n",
    "\n",
    "attention_outputs = [cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(12)]\n",
    "attention_outputs = torch.stack(attention_outputs, dim=1) # now batch, layer, seq, n_heads, dim_attn\n",
    "mean_acts = torch.mean(attention_outputs, dim=0)\n",
    "old_shape = mean_acts.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "mean_acts = mean_acts.view(new_shape)\n",
    "\n",
    "text = ioi_dataset.sentences[0]\n",
    "encoding = model.tokenizer.encode_plus(text, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "input_shape = encoding.input_ids.size()\n",
    "extended_attention_mask = get_extended_attention_mask(encoding.attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "seq_len = ioi_dataset.toks.shape[1]\n",
    "print('sequence length: %d ' % seq_len)\n",
    "# Calculate relevance to logits\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(ioi_dataset.toks[0:NUM_SAMPLES, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "prop_fn = lambda ablation_list: prop_GPT(ioi_dataset.toks[0:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, _ = batch_run(prop_fn, ablation_sets, num_at_time=(64 // NUM_SAMPLES))\n",
    "results = compute_logits_decomposition_scores(out_decomps)\n",
    "# Now, find maximally relevant source nodes to target nodes\n",
    "\n",
    "outliers_per_iter = []\n",
    "while True:\n",
    "    outliers = results[:NUM_OUTLIERS_TO_KEEP_PER_ITER]\n",
    "    outliers_per_iter.append(outliers)\n",
    "    target_nodes = [r.ablation_set[0] for r in outliers]\n",
    "    print(target_nodes)\n",
    "    should_break = True\n",
    "    for node in target_nodes:\n",
    "        if node.layer_idx != 0:\n",
    "            should_break = False\n",
    "    if should_break:\n",
    "        break\n",
    "    \n",
    "    ranges = [\n",
    "            [layer for layer in range(12)],\n",
    "            [sequence_position for sequence_position in range(seq_len)],\n",
    "            # [ioi_dataset.word_idx['IO'][0]],\n",
    "            [attention_head_idx for attention_head_idx in range(12)]\n",
    "        ]\n",
    "    source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "    ablation_sets = [(n,) for n in source_nodes]\n",
    "    prop_fn = lambda ablation_list: prop_GPT(ioi_dataset.toks[0:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "    _, target_decomps = batch_run(prop_fn, ablation_sets, num_at_time=(64 // NUM_SAMPLES))\n",
    "    \n",
    "    results = calculate_target_decomposition_scores(target_decomps, method=\"dot\", mean_acts=mean_acts.view(old_shape), attn_cache=ioi_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15bb0c2f-bef4-4bc3-8f5a-f2177a17e538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)\n",
      "Node(layer_idx=10, sequence_idx=14, attn_head_idx=10)\n",
      "Node(layer_idx=9, sequence_idx=14, attn_head_idx=6)\n",
      "Node(layer_idx=9, sequence_idx=2, attn_head_idx=6)\n",
      "Node(layer_idx=0, sequence_idx=1, attn_head_idx=1)\n",
      "Node(layer_idx=0, sequence_idx=1, attn_head_idx=4)\n"
     ]
    }
   ],
   "source": [
    "all_nodes = []\n",
    "for it in outliers_per_iter:\n",
    "    for result in it:\n",
    "        if result.ablation_set[0] not in all_nodes:\n",
    "            all_nodes.append(result.ablation_set[0])\n",
    "for node in all_nodes:\n",
    "    print((node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a438ad2b-5fa8-4211-bed6-c0d70f152341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, Vanessa and Paul went to the house. Vanessa gave a basketball to Paul\n",
      "Then, Jessica and Lindsay went to the school. Jessica gave a snack to Lindsay\n"
     ]
    }
   ],
   "source": [
    "print(ioi_dataset.sentences[0])\n",
    "print(test_ioi_dataset.sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb281b2-5c53-4ed4-8fd8-fee3b78ab603",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ANTI-CIRCUIT for BABA_TEMPLATES[0]: achieves a -1.90 logits difference, i.e, -0.58 faithfulness\n",
    "Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)\n",
    "Node(layer_idx=10, sequence_idx=14, attn_head_idx=6)\n",
    "Node(layer_idx=9, sequence_idx=11, attn_head_idx=6)\n",
    "Node(layer_idx=9, sequence_idx=11, attn_head_idx=9)\n",
    "Node(layer_idx=8, sequence_idx=3, attn_head_idx=10)\n",
    "Node(layer_idx=8, sequence_idx=11, attn_head_idx=10)\n",
    "Node(layer_idx=7, sequence_idx=3, attn_head_idx=9)\n",
    "Node(layer_idx=7, sequence_idx=3, attn_head_idx=3)\n",
    "Node(layer_idx=6, sequence_idx=3, attn_head_idx=4)\n",
    "Node(layer_idx=6, sequence_idx=3, attn_head_idx=1)\n",
    "Node(layer_idx=5, sequence_idx=3, attn_head_idx=10)\n",
    "Node(layer_idx=4, sequence_idx=3, attn_head_idx=3)\n",
    "Node(layer_idx=4, sequence_idx=3, attn_head_idx=11)\n",
    "Node(layer_idx=4, sequence_idx=3, attn_head_idx=4)\n",
    "Node(layer_idx=3, sequence_idx=3, attn_head_idx=6)\n",
    "Node(layer_idx=3, sequence_idx=3, attn_head_idx=7)\n",
    "Node(layer_idx=2, sequence_idx=3, attn_head_idx=2)\n",
    "Node(layer_idx=2, sequence_idx=3, attn_head_idx=9)\n",
    "Node(layer_idx=1, sequence_idx=2, attn_head_idx=6)\n",
    "Node(layer_idx=1, sequence_idx=2, attn_head_idx=7)\n",
    "Node(layer_idx=0, sequence_idx=2, attn_head_idx=4)\n",
    "Node(layer_idx=0, sequence_idx=2, attn_head_idx=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b526010-d4e4-41b3-9ff2-fe33d832e148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "circuit = [Node(layer_idx=8, sequence_idx=14, attn_head_idx=6),\n",
    "           Node(layer_idx=8, sequence_idx=11, attn_head_idx=6),\n",
    "           Node(layer_idx=9, sequence_idx=14, attn_head_idx=9),\n",
    "           Node(layer_idx=9, sequence_idx=14, attn_head_idx=6),\n",
    "           Node(layer_idx=5, sequence_idx=10, attn_head_idx=5),\n",
    "           Node(layer_idx=7, sequence_idx=11, attn_head_idx=9),\n",
    "           Node(layer_idx=6, sequence_idx=10, attn_head_idx=9),\n",
    "           Node(layer_idx=6, sequence_idx=11, attn_head_idx=0),\n",
    "           Node(layer_idx=5, sequence_idx=10, attn_head_idx=9),\n",
    "           Node(layer_idx=3, sequence_idx=10, attn_head_idx=0),\n",
    "           Node(layer_idx=4, sequence_idx=5, attn_head_idx=11),\n",
    "           Node(layer_idx=3, sequence_idx=5, attn_head_idx=7),\n",
    "           Node(layer_idx=3, sequence_idx=3, attn_head_idx=6),\n",
    "           Node(layer_idx=2, sequence_idx=3, attn_head_idx=2),\n",
    "           Node(layer_idx=2, sequence_idx=3, attn_head_idx=9),\n",
    "           Node(layer_idx=1, sequence_idx=3, attn_head_idx=7),\n",
    "           Node(layer_idx=1, sequence_idx=3, attn_head_idx=10),\n",
    "           Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),\n",
    "           Node(layer_idx=0, sequence_idx=2, attn_head_idx=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33374a25-c2a8-493e-8480-ecc2274e6ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_circuit = random.sample(source_nodes, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8400c39-b1b5-42bd-8360-911dbdd9f4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=2, sequence_idx=0, attn_head_idx=4), Node(layer_idx=9, sequence_idx=13, attn_head_idx=6), Node(layer_idx=0, sequence_idx=14, attn_head_idx=2), Node(layer_idx=9, sequence_idx=5, attn_head_idx=8), Node(layer_idx=10, sequence_idx=8, attn_head_idx=4), Node(layer_idx=4, sequence_idx=2, attn_head_idx=2), Node(layer_idx=3, sequence_idx=11, attn_head_idx=9), Node(layer_idx=5, sequence_idx=6, attn_head_idx=11), Node(layer_idx=9, sequence_idx=15, attn_head_idx=8), Node(layer_idx=6, sequence_idx=1, attn_head_idx=6), Node(layer_idx=6, sequence_idx=4, attn_head_idx=10), Node(layer_idx=10, sequence_idx=0, attn_head_idx=11), Node(layer_idx=3, sequence_idx=11, attn_head_idx=1), Node(layer_idx=6, sequence_idx=13, attn_head_idx=0), Node(layer_idx=3, sequence_idx=8, attn_head_idx=2), Node(layer_idx=7, sequence_idx=12, attn_head_idx=7), Node(layer_idx=2, sequence_idx=6, attn_head_idx=7), Node(layer_idx=6, sequence_idx=15, attn_head_idx=7), Node(layer_idx=2, sequence_idx=0, attn_head_idx=2), Node(layer_idx=2, sequence_idx=6, attn_head_idx=9)]\n"
     ]
    }
   ],
   "source": [
    "print(random_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9db57878-aaf0-4ef6-83ad-021902bf9e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4686, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from pyfunctions.faithfulness_ablations import logits_to_ave_logit_diff_2, add_mean_ablation_hook\n",
    "'''\n",
    "test_ioi_dataset = IOIDataset(prompt_type=[template], N=10, tokenizer=model.tokenizer, prepend_bos=False)\n",
    "test_abc_dataset = (\n",
    "    test_ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "-2.1718\n",
    "'''\n",
    "circuit = all_nodes\n",
    "\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, means_dataset=test_abc_dataset, circuit=circuit) #, circuit=random_circuit)\n",
    "# model = add_mean_ablation_hook(model, means_dataset=test_abc_dataset)\n",
    "logits, cache = model.run_with_cache(test_ioi_dataset.toks) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff_2(logits, test_ioi_dataset)\n",
    "print(ave_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea429b1a-516d-4210-a0c7-7278aae0f8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tentatively improved score to -1.255778   by removing node  Node(layer_idx=10, sequence_idx=14, attn_head_idx=10)\n",
      "removing  Node(layer_idx=10, sequence_idx=14, attn_head_idx=10)  to achieve score of -1.255778\n",
      "tentatively improved score to -1.220982   by removing node  Node(layer_idx=0, sequence_idx=1, attn_head_idx=4)\n",
      "removing  Node(layer_idx=0, sequence_idx=1, attn_head_idx=4)  to achieve score of -1.220982\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# speculative: try to generate a better circuit by greedy search\n",
    "\n",
    "NAME_MOVER_HEADS = [Node(9, 14, 9), Node(10, 14, 0), Node(9, 14, 6)]\n",
    "old_circuit = circuit.copy()\n",
    "best_score = -1.4686 # \n",
    "while True:\n",
    "    node_to_remove = None\n",
    "    for idx, node in enumerate(circuit):\n",
    "        if node in NAME_MOVER_HEADS:\n",
    "            continue\n",
    "        new_circuit = circuit.copy()\n",
    "        new_circuit.remove(node)\n",
    "        # print(new_circuit)\n",
    "        model.reset_hooks(including_permanent=True)\n",
    "        model = add_mean_ablation_hook(model, means_dataset=test_abc_dataset, circuit=new_circuit)\n",
    "        logits, cache = model.run_with_cache(test_ioi_dataset.toks) # run on entire dataset along batch dimension\n",
    "        ave_logit_diff = logits_to_ave_logit_diff_2(logits, test_ioi_dataset).cpu().numpy().item()\n",
    "        if ave_logit_diff > best_score:\n",
    "            best_score = ave_logit_diff\n",
    "            node_to_remove = node\n",
    "            print('tentatively improved score to %f ' % best_score, ' by removing node ', node_to_remove)\n",
    "    if node_to_remove is None: \n",
    "        # then we can't improve any further so the algorithm terminates\n",
    "        break\n",
    "    print(\"removing \", node_to_remove, \" to achieve score of %f\" % best_score)\n",
    "    circuit.remove(node_to_remove)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de9d9f5-2955-46b7-92bc-9f26308ce450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note: for the following circuit:\n",
    "'''\n",
    "Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)\n",
    "Node(layer_idx=9, sequence_idx=14, attn_head_idx=6)\n",
    "Node(layer_idx=10, sequence_idx=14, attn_head_idx=0)\n",
    "Node(layer_idx=8, sequence_idx=1, attn_head_idx=11)\n",
    "Node(layer_idx=8, sequence_idx=1, attn_head_idx=10)\n",
    "Node(layer_idx=8, sequence_idx=1, attn_head_idx=2)\n",
    "Node(layer_idx=7, sequence_idx=1, attn_head_idx=1)\n",
    "Node(layer_idx=7, sequence_idx=1, attn_head_idx=4)\n",
    "Node(layer_idx=6, sequence_idx=1, attn_head_idx=4)\n",
    "Node(layer_idx=6, sequence_idx=1, attn_head_idx=0)\n",
    "Node(layer_idx=5, sequence_idx=1, attn_head_idx=10)\n",
    "Node(layer_idx=5, sequence_idx=1, attn_head_idx=2)\n",
    "Node(layer_idx=5, sequence_idx=1, attn_head_idx=3)\n",
    "Node(layer_idx=5, sequence_idx=1, attn_head_idx=6)\n",
    "Node(layer_idx=5, sequence_idx=1, attn_head_idx=9)\n",
    "Node(layer_idx=4, sequence_idx=1, attn_head_idx=3)\n",
    "Node(layer_idx=4, sequence_idx=1, attn_head_idx=10)\n",
    "Node(layer_idx=4, sequence_idx=1, attn_head_idx=9)\n",
    "Node(layer_idx=1, sequence_idx=1, attn_head_idx=3)\n",
    "Node(layer_idx=1, sequence_idx=1, attn_head_idx=10)\n",
    "Node(layer_idx=1, sequence_idx=1, attn_head_idx=4)\n",
    "Node(layer_idx=0, sequence_idx=1, attn_head_idx=3)\n",
    "Node(layer_idx=0, sequence_idx=1, attn_head_idx=4)\n",
    "Node(layer_idx=0, sequence_idx=1, attn_head_idx=5)\n",
    "'''\n",
    "# removing just one node, (8, 1, 11), raises the score from -2.1718 to -0.4423.\n",
    "# this node is not identified by the IOI paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "029f2c59-bcb1-4fc8-a97e-438cfa76e86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=9, sequence_idx=14, attn_head_idx=9), Node(layer_idx=10, sequence_idx=14, attn_head_idx=0), Node(layer_idx=9, sequence_idx=14, attn_head_idx=6), Node(layer_idx=10, sequence_idx=14, attn_head_idx=10), Node(layer_idx=10, sequence_idx=14, attn_head_idx=6), Node(layer_idx=10, sequence_idx=14, attn_head_idx=2), Node(layer_idx=10, sequence_idx=14, attn_head_idx=1), Node(layer_idx=11, sequence_idx=14, attn_head_idx=2), Node(layer_idx=9, sequence_idx=14, attn_head_idx=7), Node(layer_idx=9, sequence_idx=14, attn_head_idx=0), Node(layer_idx=11, sequence_idx=14, attn_head_idx=9), Node(layer_idx=10, sequence_idx=14, attn_head_idx=7), Node(layer_idx=11, sequence_idx=14, attn_head_idx=10), Node(layer_idx=7, sequence_idx=14, attn_head_idx=3), Node(layer_idx=7, sequence_idx=14, attn_head_idx=9), Node(layer_idx=8, sequence_idx=14, attn_head_idx=6), Node(layer_idx=8, sequence_idx=14, attn_head_idx=10), Node(layer_idx=5, sequence_idx=10, attn_head_idx=5), Node(layer_idx=5, sequence_idx=10, attn_head_idx=8), Node(layer_idx=5, sequence_idx=10, attn_head_idx=9), Node(layer_idx=6, sequence_idx=10, attn_head_idx=9), Node(layer_idx=0, sequence_idx=10, attn_head_idx=1), Node(layer_idx=0, sequence_idx=10, attn_head_idx=10), Node(layer_idx=3, sequence_idx=10, attn_head_idx=0), Node(layer_idx=2, sequence_idx=3, attn_head_idx=2), Node(layer_idx=4, sequence_idx=3, attn_head_idx=11)]\n"
     ]
    }
   ],
   "source": [
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e9717bb-1f4e-4823-bcfc-ea685daf8af6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5994, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks(including_permanent=True)\n",
    "# model = add_mean_ablation_hook(model, means_dataset=test_abc_dataset, circuit=circuit)\n",
    "model = add_mean_ablation_hook(model, means_dataset=test_abc_dataset, circuit=nodes)\n",
    "logits, cache = model.run_with_cache(test_ioi_dataset.toks) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff_2(logits, test_ioi_dataset)\n",
    "print(ave_logit_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00db07-0827-4674-bd58-64ef964a3d4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Other experiments / graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60444643-0eac-4975-a66b-77b3c8e58987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_logits, ioi_cache = model.run_with_cache(ioi_dataset.toks[0])\n",
    "ioi_cache['blocks.' + '0' + '.attn.hook_z'][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b63b93ac-7867-4cca-9b0b-8cc098458a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 16, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "print(mean_acts.view(old_shape).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4317571e-1417-4095-8d00-4ca43f46cddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=9, sequence_idx=14, attn_head_idx=9)\n",
      "tensor([ 4.5882,  1.8150, -4.5381,  9.2072, -5.7037,  0.4358,  6.8751, -2.5157,\n",
      "        -0.0201, -5.4035,  5.1540, -8.1743, -2.3777, -8.3265,  0.6575,  1.7242,\n",
      "         6.6951, -7.5154, -1.2071,  5.1037,  2.0116,  0.7948,  2.0949,  7.4878,\n",
      "        -1.0701, -4.5399,  1.5003,  1.6590,  3.1868,  1.0958, -0.1454,  2.2109,\n",
      "         1.5758,  0.0705, -1.5077, -0.7950,  5.7988, -1.2882, -2.4122, -0.6233,\n",
      "         2.6682, -4.5806,  2.9596, -3.6489, -4.7048, -1.0226, -1.5860, -2.3727,\n",
      "         5.0705, -0.5869,  1.2846, -4.9232, -0.0825,  1.9475, -0.8008, -1.3300,\n",
      "        -2.4370, -3.4239,  1.8176, -1.7732,  3.7865, -5.6771, -3.1785,  2.9272],\n",
      "       device='cuda:0')\n",
      "tensor([ 3.1207, -2.6716,  0.4378, -4.4690, -3.7148, -0.0856,  3.3663,  0.4827,\n",
      "        -0.0276, -2.1319, -2.4535, -1.3968,  1.8229, -1.8517, -1.9059,  0.6349,\n",
      "        -1.0417,  0.1398, -2.7960, -3.1978, -3.0324,  5.9148,  1.0522, -1.3331,\n",
      "        -2.1495,  0.7540,  2.5116,  0.8945,  0.0817,  2.1442,  0.4860, -0.1693,\n",
      "         0.5668,  1.7944, -0.3488, -1.0145,  0.2673, -2.8463,  3.0966, -1.9893,\n",
      "         1.1232,  0.5699, -1.9760, -1.8797, -1.3339, -0.1108,  1.8845,  2.2627,\n",
      "        -0.8134, -3.1224,  4.5247, -1.1517,  0.8192, -2.4354,  0.3437, -1.6626,\n",
      "         0.9372, -0.3881,  1.6717,  0.3546,  2.9326, -2.1492, -1.6601, -0.9716],\n",
      "       device='cuda:0')\n",
      "33.545406\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "for target_node in [Node(9, 14, 9), Node(9, 14, 6), Node(10, 14, 0)]:\n",
    "# target_node = Node(9, 14, 9)\n",
    "    print(target_node)\n",
    "    target_mean_act = mean_acts.view(old_shape)[target_node.layer_idx, target_node.sequence_idx, target_node.attn_head_idx]\n",
    "    activation = ioi_cache['blocks.' + str(target_node.layer_idx) + '.attn.hook_z'][0][target_node.sequence_idx][target_node.attn_head_idx]\n",
    "    print(activation)\n",
    "    print(target_mean_act)\n",
    "    #print(activation - target_mean_act)\n",
    "    print(np.linalg.norm((activation - target_mean_act).cpu().numpy()))\n",
    "    print('##################')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d715a8a5-a9ed-438d-b149-03901122def4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation: \n",
      "tensor([[ 4.5882,  1.8149, -4.5381,  9.2073, -5.7037,  0.4358,  6.8753, -2.5156,\n",
      "         -0.0201, -5.4033,  5.1538, -8.1742, -2.3779, -8.3267,  0.6575,  1.7242,\n",
      "          6.6949, -7.5156, -1.2072,  5.1037,  2.0114,  0.7949,  2.0948,  7.4878,\n",
      "         -1.0699, -4.5395,  1.5005,  1.6590,  3.1867,  1.0958, -0.1456,  2.2110,\n",
      "          1.5757,  0.0705, -1.5080, -0.7949,  5.7990, -1.2884, -2.4122, -0.6233,\n",
      "          2.6683, -4.5807,  2.9595, -3.6489, -4.7047, -1.0227, -1.5860, -2.3727,\n",
      "          5.0705, -0.5869,  1.2847, -4.9232, -0.0825,  1.9476, -0.8009, -1.3300,\n",
      "         -2.4370, -3.4239,  1.8177, -1.7732,  3.7866, -5.6771, -3.1786,  2.9275]],\n",
      "       device='cuda:0')\n",
      "mean: \n",
      "tensor([[ 3.1207, -2.6716,  0.4378, -4.4690, -3.7148, -0.0856,  3.3663,  0.4827,\n",
      "         -0.0276, -2.1319, -2.4535, -1.3968,  1.8229, -1.8517, -1.9059,  0.6349,\n",
      "         -1.0417,  0.1398, -2.7960, -3.1978, -3.0324,  5.9148,  1.0522, -1.3331,\n",
      "         -2.1495,  0.7540,  2.5116,  0.8945,  0.0817,  2.1442,  0.4860, -0.1693,\n",
      "          0.5668,  1.7944, -0.3488, -1.0145,  0.2673, -2.8463,  3.0966, -1.9893,\n",
      "          1.1232,  0.5699, -1.9760, -1.8797, -1.3339, -0.1108,  1.8845,  2.2627,\n",
      "         -0.8134, -3.1224,  4.5247, -1.1517,  0.8192, -2.4354,  0.3437, -1.6626,\n",
      "          0.9372, -0.3881,  1.6717,  0.3546,  2.9326, -2.1492, -1.6601, -0.9716]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ablation_sets = [(Node(9, 14, 9),)]\n",
    "target_nodes = []\n",
    "\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12f080c6-73e5-4833-9290-2919faa090be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=9),), score=tensor(889.4381, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=9, sequence_idx=14, attn_head_idx=6),), score=tensor(455.7758, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=14, attn_head_idx=0),), score=tensor(317.3372, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=tensor(43.9872, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=tensor(42.7847, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=tensor(40.7673, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=tensor(40.1853, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=6),), score=tensor(38.3538, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=tensor(34.8150, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=0),), score=tensor(32.6773, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=8),), score=tensor(31.8191, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=5),), score=tensor(31.0179, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=3),), score=tensor(30.9142, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=8),), score=tensor(30.7330, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=11),), score=tensor(30.6759, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=4, attn_head_idx=1),), score=tensor(29.5537, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=1),), score=tensor(29.5026, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=9),), score=tensor(28.8424, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=2),), score=tensor(28.6224, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=1, attn_head_idx=11),), score=tensor(28.2847, device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor result in results:\\n    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or         result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or         result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or         result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\\n        print(result.ablation_set[0], result.score)\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for result in results[:20]:\n",
    "    print(result)\n",
    "'''\n",
    "for result in results:\n",
    "    if result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 9 or \\\n",
    "        result.ablation_set[0].layer_idx == 7 and result.ablation_set[0].attn_head_idx == 3 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 6 or \\\n",
    "        result.ablation_set[0].layer_idx == 8 and result.ablation_set[0].attn_head_idx == 10:\n",
    "        print(result.ablation_set[0], result.score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f290e656-97a5-4467-b495-d29e31b2a968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means_by_layer = np.mean(decomp_scores, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac36c27b-61aa-46f4-a23b-ee381c0bff78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.24818977, 5.84034312, 4.1312829 , 3.2301396 , 2.41149031,\n",
       "       1.97253734, 1.36958096, 0.72439622, 0.38497442, 7.13600245,\n",
       "       1.65279786, 0.        ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4009073-89cd-4ba1-916d-da935d5fefa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized_decomp_scores = decomp_scores / np.expand_dims(means_by_layer, (1, 2))\n",
    "\n",
    "normalized_results = []\n",
    "for layer in range(9): # last two layers are 0s, causing inf problems\n",
    "    for sequence_position in range(16):\n",
    "        for attention_head_idx in range(12):\n",
    "            idx = layer * 16 * 12 + sequence_position * 12 + attention_head_idx\n",
    "            target_decomp = target_decomps[idx]\n",
    "            normalized_results.append(Result(target_decomp.ablation_set, normalized_decomp_scores[layer, sequence_position, attention_head_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e316d29-ae96-45e2-b930-0e9e5dadce4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=9, sequence_idx=14, attn_head_idx=9), Node(layer_idx=10, sequence_idx=14, attn_head_idx=0), Node(layer_idx=9, sequence_idx=14, attn_head_idx=6)]\n"
     ]
    }
   ],
   "source": [
    "print(target_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3fc374a-b272-4f5b-bc97-761a7e1ec320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=2),), score=8.06340133858641)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=2, attn_head_idx=4),), score=7.112563763523278)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=10),), score=7.085672807182714)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=6),), score=7.0457718902343185)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=4),), score=6.296416119927532)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=9),), score=6.2906252991982345)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=11),), score=6.237698431014729)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=2, attn_head_idx=6),), score=5.500263562825447)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=3, attn_head_idx=8),), score=5.363445484846832)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=5),), score=5.221690336741158)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=8),), score=5.030575692505166)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=1),), score=4.937050617031997)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=4, attn_head_idx=4),), score=4.885894072933203)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=6),), score=4.78094257842273)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=4.756301903887449)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=4, attn_head_idx=6),), score=4.70334778472697)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=6),), score=4.702807347182252)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=7),), score=4.702579580649376)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=10),), score=4.694905620178803)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=0),), score=4.684889656317291)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=3),), score=4.671107785047694)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=0),), score=4.640496211300507)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=4.626274873932114)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=6),), score=4.625097511953211)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=3, attn_head_idx=4),), score=4.625038308830087)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=2),), score=4.614505991221067)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=2, attn_head_idx=6),), score=4.601595432707063)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=9),), score=4.564373889075744)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=4, attn_head_idx=0),), score=4.5471149454912005)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=4, attn_head_idx=8),), score=4.511643462046953)\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=2, attn_head_idx=7),), score=4.499551189686188)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=11),), score=4.469392561407194)\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=2, attn_head_idx=3),), score=4.457146028204005)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=4.40814119981464)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=4.34521236091489)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=10, attn_head_idx=2),), score=4.335097635029136)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=10),), score=4.248578488466679)\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=2, attn_head_idx=4),), score=4.228495413809886)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=5),), score=4.206989921774501)\n",
      "Result(ablation_set=(Node(layer_idx=7, sequence_idx=4, attn_head_idx=5),), score=4.182469573757376)\n",
      "Result(ablation_set=(Node(layer_idx=4, sequence_idx=2, attn_head_idx=10),), score=4.16961018770512)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=6),), score=4.147169370953956)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=8),), score=4.125051402872492)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=7),), score=4.091629943848698)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=11),), score=4.073348188680282)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=6),), score=4.067309368208814)\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=10, attn_head_idx=10),), score=4.063723341309265)\n",
      "Result(ablation_set=(Node(layer_idx=6, sequence_idx=4, attn_head_idx=7),), score=4.003492138903598)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=2, attn_head_idx=5),), score=3.940137332766914)\n",
      "Result(ablation_set=(Node(layer_idx=5, sequence_idx=3, attn_head_idx=10),), score=3.9277925002344123)\n"
     ]
    }
   ],
   "source": [
    "# (7.3, 7.9, 8.6, 8.10)\n",
    "normalized_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "for result in normalized_results[:50]:\n",
    "    if result.ablation_set[0].layer_idx != 9:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4935a7c9-d519-4dab-8878-f5838fe20b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IO': tensor([4, 2, 4]),\n",
       " 'IO-1': tensor([3, 1, 3]),\n",
       " 'IO+1': tensor([5, 3, 5]),\n",
       " 'S': tensor([2, 4, 2]),\n",
       " 'S-1': tensor([1, 3, 1]),\n",
       " 'S+1': tensor([3, 5, 3]),\n",
       " 'S2': tensor([10, 10, 10]),\n",
       " 'end': tensor([14, 14, 14]),\n",
       " 'starts': tensor([0, 0, 0]),\n",
       " 'punct': tensor([9, 9, 9])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_dataset.word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b297d57f-47d7-4f87-9ec3-5cfba9b45646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = sns.heatmap(decomp_scores[:, ioi_dataset.word_idx['end'][0], :], xticklabels = range(12), yticklabels = range(12), cmap='Blues', cbar_kws={'label': ''})\n",
    "s.set(xlabel='Head', ylabel='Layer')\n",
    "#token = ioi_dataset.tokenized_prompts[0].split('|')[seq_idx]\n",
    "plt.title(\"Relevance of (layer, head) to Name Mover Heads at last sequence position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5baef4b-3ea1-4131-85a2-396d544d5ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(layer_idx=0, sequence_idx=0, attn_head_idx=10), Node(layer_idx=0, sequence_idx=0, attn_head_idx=1), Node(layer_idx=0, sequence_idx=0, attn_head_idx=0), Node(layer_idx=0, sequence_idx=0, attn_head_idx=7), Node(layer_idx=0, sequence_idx=0, attn_head_idx=3), Node(layer_idx=0, sequence_idx=0, attn_head_idx=9)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"TargetNodeDecompositionList\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m _, _, _, pre_layer_activations \u001b[38;5;241m=\u001b[39m prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, [ablation_sets[\u001b[38;5;241m0\u001b[39m]], target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_GPT(encoding_idxs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mmean_acts, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[0;32m---> 18\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_sets\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/CD_Circuit/pyfunctions/cdt_source_to_target.py:427\u001b[0m, in \u001b[0;36mbatch_run\u001b[0;34m(prop_model_fn, ablation_list, num_at_time, n_layers)\u001b[0m\n\u001b[1;32m    424\u001b[0m     batch_out_decomps, batch_target_decomps, _, _ \u001b[38;5;241m=\u001b[39m prop_model_fn(ablation_list[b_st: b_end])\n\u001b[1;32m    426\u001b[0m     out_decomps \u001b[38;5;241m=\u001b[39m out_decomps \u001b[38;5;241m+\u001b[39m batch_out_decomps\n\u001b[0;32m--> 427\u001b[0m     target_decomps \u001b[38;5;241m=\u001b[39m [\u001b[43mtarget_decomps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_target_decomps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)]\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_decomps, target_decomps\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"TargetNodeDecompositionList\") to list"
     ]
    }
   ],
   "source": [
    "results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = results[:6] # hardcoded first few N\n",
    "outliers_per_iter.append(outliers)\n",
    "target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "print(target_nodes)\n",
    "ranges = [\n",
    "        [layer for layer in range(12)],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "_, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2bf915a-9f08-46b7-b5ef-1cb1e3a7857b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(target_decomps))\n",
    "print((abs(target_decomps[0].rels[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18167b58-cf91-4d50-bbb8-42983d510a43",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## New algorithm (fixed number of nodes per layer, weight relevance to the nodes according to the nodes' relevance in the previous iter, take nodes with highest absolute scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131aae5-b946-4acc-aebf-1e769116f9e9",
   "metadata": {},
   "source": [
    "There are two problems with this algorithm generally:\n",
    "\n",
    "1. The \"relevance to logits\" score isn't on the same scale as \"relevance to target nodes\" score, so there's no principled way to decide whether nodes in the last layer are more or less relevant than others.\n",
    "\n",
    "2. More fatally, the most important nodes converge to position 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2ff3c0a-5464-4075-a40f-a110bef9da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "ranges = [\n",
    "        [11],\n",
    "        [sequence_position for sequence_position in range(input_shape[1])],\n",
    "        [attention_head_idx for attention_head_idx in range(12)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "# ablation_sets = [tuple(n for n in source_nodes)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "# print(source_nodes[:64])\n",
    "target_nodes = []\n",
    "# out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=False)\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)\n",
    "# for each source node determine the contribution of rel to the actual score\n",
    "\n",
    "logits = (out_decomps[0].rel + out_decomps[0].irrel) # 1, seq_len, 50257=d_vocab\n",
    "io_logit = logits[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "s_logit = logits[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "full_score = io_logit - s_logit\n",
    "assert(full_score > 0)\n",
    "\n",
    "last_layer_results = []\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "\n",
    "for decomp in out_decomps:\n",
    "    rel_io_logit = decomp.rel[0, -2, ioi_dataset.io_tokenIDs[0]]\n",
    "    rel_s_logit = decomp.rel[0, -2, ioi_dataset.s_tokenIDs[0]]\n",
    "    score = rel_io_logit - rel_s_logit\n",
    "    #print(score, rel_io_logit, rel_s_logit)\n",
    "    norm_score = score / full_score\n",
    "    last_layer_results.append(Result(decomp.ablation_set, norm_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc619414-6852-435a-b884-2c0a5692e3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=6),), score=0.0623091),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=2),), score=0.049144655),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.04818679),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=7),), score=0.04440797),\n",
       " Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=11),), score=0.0425904)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "last_layer_results[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8c7d26c-c213-4968-9784-f2c4ead35791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 10: \n",
      "new target nodes:\n",
      "[Node(layer_idx=11, sequence_idx=14, attn_head_idx=0), Node(layer_idx=11, sequence_idx=14, attn_head_idx=6), Node(layer_idx=11, sequence_idx=14, attn_head_idx=2), Node(layer_idx=11, sequence_idx=14, attn_head_idx=3), Node(layer_idx=11, sequence_idx=14, attn_head_idx=7), Node(layer_idx=11, sequence_idx=14, attn_head_idx=11)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 9: \n",
      "new target nodes:\n",
      "[Node(layer_idx=10, sequence_idx=9, attn_head_idx=0), Node(layer_idx=10, sequence_idx=9, attn_head_idx=6), Node(layer_idx=10, sequence_idx=9, attn_head_idx=10), Node(layer_idx=10, sequence_idx=9, attn_head_idx=7), Node(layer_idx=10, sequence_idx=9, attn_head_idx=1), Node(layer_idx=10, sequence_idx=9, attn_head_idx=2)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 8: \n",
      "new target nodes:\n",
      "[Node(layer_idx=9, sequence_idx=2, attn_head_idx=0), Node(layer_idx=9, sequence_idx=2, attn_head_idx=8), Node(layer_idx=9, sequence_idx=2, attn_head_idx=2), Node(layer_idx=9, sequence_idx=2, attn_head_idx=5), Node(layer_idx=9, sequence_idx=4, attn_head_idx=8), Node(layer_idx=9, sequence_idx=4, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 7: \n",
      "new target nodes:\n",
      "[Node(layer_idx=8, sequence_idx=2, attn_head_idx=2), Node(layer_idx=8, sequence_idx=2, attn_head_idx=11), Node(layer_idx=8, sequence_idx=2, attn_head_idx=4), Node(layer_idx=8, sequence_idx=2, attn_head_idx=9), Node(layer_idx=8, sequence_idx=2, attn_head_idx=8), Node(layer_idx=8, sequence_idx=2, attn_head_idx=10)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 6: \n",
      "new target nodes:\n",
      "[Node(layer_idx=7, sequence_idx=2, attn_head_idx=5), Node(layer_idx=7, sequence_idx=2, attn_head_idx=6), Node(layer_idx=7, sequence_idx=2, attn_head_idx=1), Node(layer_idx=7, sequence_idx=2, attn_head_idx=4), Node(layer_idx=7, sequence_idx=2, attn_head_idx=3), Node(layer_idx=7, sequence_idx=2, attn_head_idx=9)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 5: \n",
      "new target nodes:\n",
      "[Node(layer_idx=6, sequence_idx=2, attn_head_idx=4), Node(layer_idx=6, sequence_idx=2, attn_head_idx=6), Node(layer_idx=6, sequence_idx=2, attn_head_idx=7), Node(layer_idx=6, sequence_idx=2, attn_head_idx=0), Node(layer_idx=6, sequence_idx=2, attn_head_idx=5), Node(layer_idx=6, sequence_idx=2, attn_head_idx=1)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 4: \n",
      "new target nodes:\n",
      "[Node(layer_idx=5, sequence_idx=2, attn_head_idx=10), Node(layer_idx=5, sequence_idx=2, attn_head_idx=2), Node(layer_idx=5, sequence_idx=2, attn_head_idx=11), Node(layer_idx=5, sequence_idx=2, attn_head_idx=9), Node(layer_idx=5, sequence_idx=2, attn_head_idx=7), Node(layer_idx=5, sequence_idx=2, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 3: \n",
      "new target nodes:\n",
      "[Node(layer_idx=4, sequence_idx=2, attn_head_idx=4), Node(layer_idx=4, sequence_idx=2, attn_head_idx=3), Node(layer_idx=4, sequence_idx=2, attn_head_idx=7), Node(layer_idx=4, sequence_idx=2, attn_head_idx=5), Node(layer_idx=4, sequence_idx=2, attn_head_idx=8), Node(layer_idx=4, sequence_idx=2, attn_head_idx=6)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 2: \n",
      "new target nodes:\n",
      "[Node(layer_idx=3, sequence_idx=2, attn_head_idx=6), Node(layer_idx=3, sequence_idx=2, attn_head_idx=10), Node(layer_idx=3, sequence_idx=2, attn_head_idx=5), Node(layer_idx=3, sequence_idx=2, attn_head_idx=7), Node(layer_idx=3, sequence_idx=2, attn_head_idx=2), Node(layer_idx=3, sequence_idx=2, attn_head_idx=3)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 1: \n",
      "new target nodes:\n",
      "[Node(layer_idx=2, sequence_idx=2, attn_head_idx=1), Node(layer_idx=2, sequence_idx=2, attn_head_idx=9), Node(layer_idx=2, sequence_idx=2, attn_head_idx=7), Node(layer_idx=2, sequence_idx=2, attn_head_idx=0), Node(layer_idx=2, sequence_idx=2, attn_head_idx=10), Node(layer_idx=2, sequence_idx=2, attn_head_idx=2)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n",
      "layer 0: \n",
      "new target nodes:\n",
      "[Node(layer_idx=1, sequence_idx=2, attn_head_idx=11), Node(layer_idx=1, sequence_idx=2, attn_head_idx=10), Node(layer_idx=1, sequence_idx=2, attn_head_idx=7), Node(layer_idx=1, sequence_idx=2, attn_head_idx=0), Node(layer_idx=1, sequence_idx=2, attn_head_idx=6), Node(layer_idx=1, sequence_idx=2, attn_head_idx=5)]\n",
      "Running inputs 0 to 64 (of 192)\n",
      "Running inputs 64 to 128 (of 192)\n",
      "Running inputs 128 to 192 (of 192)\n"
     ]
    }
   ],
   "source": [
    "last_layer_results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "outliers = last_layer_results[:6] # hardcoded first few N\n",
    "outliers_per_iter = [outliers]\n",
    "node_weights = [r.score for r in outliers]\n",
    "\n",
    "for layer in range(10, -1, -1):\n",
    "    target_nodes = [r.ablation_set[0] for r in outliers] # here we assume that we only ever tried to ablate one node at once; our method doesn't handle anything else\n",
    "    sum_scores = sum([r.score for r in outliers])\n",
    "    node_weights = [r.score / sum_scores for r in outliers]\n",
    "    print(\"layer %d: \" % layer)\n",
    "    print(\"new target nodes:\")\n",
    "    print(target_nodes)\n",
    "    ranges = [\n",
    "            [layer],\n",
    "            [sequence_position for sequence_position in range(input_shape[1])],\n",
    "            [attention_head_idx for attention_head_idx in range(12)]\n",
    "        ]\n",
    "\n",
    "    source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "    ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "    prop_fn = lambda ablation_list: prop_GPT(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=mean_acts, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "    _, target_decomps = batch_run(prop_fn, ablation_sets) # why does this run so slowly? is it because moving target decomps is slow or something?\n",
    "\n",
    "    results = []\n",
    "    for target_decomp in target_decomps:\n",
    "        # this is just the same as what we did on BERT, seems like we take the ratio of the l1 norm of rel to l1 norm of irrel, summed over target nodes\n",
    "        score = 0\n",
    "        for i in range(len(target_decomp.target_nodes)):\n",
    "            weight = node_weights[i]\n",
    "            rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "            irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "            target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "            score += (target_node_score * weight)\n",
    "        results.append(Result(target_decomp.ablation_set, score))\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    outliers = results[:6] # hardcoded first few N\n",
    "    outliers_per_iter.append(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2e64cd0-7877-420b-9eed-35f9e722eb98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064)\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# for outs in outliers_per_iter:\n",
    "#     print([r.score for r in outs])\n",
    "\n",
    "all_outliers = sum(outliers_per_iter, [])\n",
    "print(all_outliers[0])\n",
    "print(len(all_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80475254-fedc-445a-b251-7ee50dd82df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=1),), score=tensor(0.0721, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=3),), score=tensor(0.0670, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=0),), score=0.0627064)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=6),), score=0.0623091)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=4),), score=tensor(0.0588, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=5),), score=tensor(0.0584, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=2),), score=0.049144655)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=3),), score=0.04818679)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=7),), score=0.04440797)\n",
      "Result(ablation_set=(Node(layer_idx=11, sequence_idx=14, attn_head_idx=11),), score=0.0425904)\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=0),), score=tensor(0.0415, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0404, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0392, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=1),), score=tensor(0.0357, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=2, attn_head_idx=9),), score=tensor(0.0308, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=6),), score=tensor(0.0284, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=2),), score=tensor(0.0275, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=6),), score=tensor(0.0267, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0266, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=11),), score=tensor(0.0266, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=10, sequence_idx=9, attn_head_idx=10),), score=tensor(0.0258, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=8, sequence_idx=2, attn_head_idx=4),), score=tensor(0.0251, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0249, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=2, attn_head_idx=7),), score=tensor(0.0249, device='cuda:0'))\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=2, attn_head_idx=10),), score=tensor(0.0236, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "all_outliers.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "for x in range(25):\n",
    "    print(all_outliers[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71414734-15f2-45b6-8bbc-be56faccf12f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Relevance of nodes to query vectors of known name mover heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058dd08-37a3-4d16-b410-912568d059ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
