{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0f3e36-fa19-4472-8945-3e17f6f8a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39df4701-17e9-4f7d-bf8e-5b1e7e2ed251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import operator\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "from pyfunctions.general import compare_same\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.cdt_from_source_nodes import *\n",
    "from pyfunctions.toy_model import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cbf067-0094-4f4e-a638-d0af92064665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-4l into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Toggle whether to explicitly calculate and expose the result for each attention head.\\nUseful for interpretability but can easily burn through GPU memory.\\n        '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from mi_utils_public import *\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "model = HookedTransformer.from_pretrained('attn-only-4l',\n",
    "                                         fold_ln=False)\n",
    "model.cfg.use_attn_result = False # what does this do?\n",
    "\"\"\"Toggle whether to explicitly calculate and expose the result for each attention head.\n",
    "Useful for interpretability but can easily burn through GPU memory.\n",
    "        \"\"\"\n",
    "# because running subprocess breaks things\n",
    "# %env TOKENIZERS_PARALLELISM=true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "92befc56-e4df-4dac-b568-d2a8fb268261",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-3): 4 x TransformerBlock(\n",
      "      (ln1): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNorm(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ac0b0f-cbfb-43df-a24e-35dab545e754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from im_utils.prompts import Prompt, docstring_ind_prompt_gen\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "docstring_ind_prompt_kwargs = dict(\n",
    "    n_matching_args=3,\n",
    "    n_def_prefix_args=2,\n",
    "    n_def_suffix_args=1,\n",
    "    n_doc_prefix_args=0,\n",
    "    met_desc_len=3,\n",
    "    arg_desc_len=2\n",
    ")\n",
    "prompts = [docstring_ind_prompt_gen(\"rest\", **docstring_ind_prompt_kwargs) for _ in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8d9004-4a12-4246-bc9d-d7339a90e790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = model.to_str_tokens(prompts[0].clean_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf3d334-05b4-43b8-898c-04c160e01fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_labels = model.to_str_tokens(prompts[0].clean_prompt)\n",
    "pos_labels[ 0] = \"BOS\"\n",
    "pos_labels[ 1] = \"⏎\"\n",
    "pos_labels[ 2] = \"def\"\n",
    "pos_labels[ 3] = \"rand0\"\n",
    "pos_labels[ 4] = \"(\"\n",
    "pos_labels[ 5] = \"self\"\n",
    "pos_labels[ 6] = \",_0\"\n",
    "pos_labels[ 7] = \"rand1\"\n",
    "pos_labels[ 8] = \",_1\"\n",
    "pos_labels[ 9] = \"rand2\"\n",
    "pos_labels[10] = \",_2\"\n",
    "pos_labels[11] = \"A_def\"\n",
    "pos_labels[12] = \",_A\"\n",
    "pos_labels[13] = \"B_def\"\n",
    "pos_labels[14] = \",_B\"\n",
    "pos_labels[15] = \"C_def\"\n",
    "pos_labels[16] = \",_C\"\n",
    "pos_labels[17] = \"rand3\"\n",
    "pos_labels[18] = \"):\"\n",
    "pos_labels[19] = \"⏎···_0\"\n",
    "pos_labels[20] = '\"\"\"'\n",
    "pos_labels[21] = \"rand4\"\n",
    "pos_labels[22] = \"rand5\"\n",
    "pos_labels[23] = \"rand6\"\n",
    "pos_labels[24] = \"⏎⏎···_1\"\n",
    "pos_labels[25] = \"·:_0\"\n",
    "pos_labels[26] = \"param_1\"\n",
    "pos_labels[27] = \"A_doc\"\n",
    "pos_labels[28] = \":_1\"\n",
    "pos_labels[29] = \"rand7\"\n",
    "pos_labels[30] = \"rand8\"\n",
    "pos_labels[31] = \"⏎···_2\"\n",
    "pos_labels[32] = \"·:_1\"\n",
    "pos_labels[33] = \"param_2\"\n",
    "pos_labels[34] = \"B_doc\"\n",
    "pos_labels[35] = \":_2\"\n",
    "pos_labels[36] = \"rand9\"\n",
    "pos_labels[37] = \"rand10\"\n",
    "pos_labels[38] = \"⏎···_3\"\n",
    "pos_labels[39] = \"·:_2\"\n",
    "pos_labels[40] = \"param_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685235b0-7ad0-4c78-b845-27b147af5cc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param description: drug machine\n",
      "    :param status: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, state, server, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, option):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, filename, valid, host):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param name: drug machine\n",
      "    :param index: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param description: drug\n",
      "    :param status: ground machine register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug\n",
      "    :param server: ground machine register\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "# dir(prompts[0])\n",
    "'''\n",
    "'clean_prompt',\n",
    " 'correct_answers',\n",
    " 'corrupt_prompt',\n",
    " 'print_all_corrupt',\n",
    " 'print_all_corrupt_tokenized',\n",
    " 'print_clean',\n",
    " 'print_clean_tokenized',\n",
    " 'print_corrupt',\n",
    " 'print_corrupt_tokenized',\n",
    " 'print_tokenized',\n",
    " 'wrong_answers'\n",
    "'''\n",
    "\n",
    "print(prompts[0].clean_prompt)\n",
    "# 'random_doc', 'random_def', 'random_answer', 'random_def_doc', 'random_answer_doc', 'random_random', 'vary_length_doc_desc', 'vary_length_doc_desc_random_doc'\n",
    "# print(prompts[0].corrupt_prompt.keys())\n",
    "# type(prompts[0])\n",
    "# These are actually decently well explained in the original LessWrong post, I just didn't see it at first.\n",
    "print(prompts[0].corrupt_prompt['random_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_def_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_answer_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_random'])\n",
    "print(prompts[0].corrupt_prompt['vary_length_doc_desc'])\n",
    "print(prompts[0].corrupt_prompt['vary_length_doc_desc_random_doc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5a2ba9f0-3f65-4ced-b5e4-f90a68763d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed                     (1, 35, 512)\n",
      "hook_pos_embed                 (1, 35, 512)\n",
      "blocks.0.hook_resid_pre        (1, 35, 512)\n",
      "blocks.0.ln1.hook_scale        (1, 35, 1)\n",
      "blocks.0.ln1.hook_normalized   (1, 35, 512)\n",
      "blocks.0.attn.hook_q           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_k           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_v           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_attn_scores (1, 8, 35, 35)\n",
      "blocks.0.attn.hook_pattern     (1, 8, 35, 35)\n",
      "blocks.0.attn.hook_z           (1, 35, 8, 64)\n",
      "blocks.0.hook_attn_out         (1, 35, 512)\n",
      "blocks.0.hook_resid_post       (1, 35, 512)\n",
      "ln_final.hook_scale            (1, 35, 1)\n",
      "ln_final.hook_normalized       (1, 35, 512)\n"
     ]
    }
   ],
   "source": [
    "logits, cache = model.run_with_cache(prompts[0].clean_prompt)\n",
    "tokens = model.to_tokens(prompts[0].clean_prompt).to(device)\n",
    "# logits, cache = model.run_with_cache(tokens)\n",
    "for activation_name, activation in cache.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(f\"{activation_name:30} {tuple(activation.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a1573d0f-19b5-4c04-a77e-e42e07438d22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(cache['blocks.1.hook_resid_pre'], cache['blocks.0.hook_resid_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0d1af7d-28dc-4d7f-99b7-ceadc46a5546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoding = model.tokenizer.encode_plus(prompts[0].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 # prepend_bos=True, # currently dealing with this: make sure BOS prepend matches because currently the sequence lengths are off-by-one\n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "620ac2b4-e534-43c1-aba2-f5c99dc3d028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n",
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_0 = cache['blocks.0.hook_resid_pre']\n",
    "compare_same(cache['hook_embed'] + cache['hook_pos_embed'], cache['blocks.0.hook_resid_pre'])\n",
    "\n",
    "# Ensure that the encodings are the same (they won't be if you set prepend_bos=True for one and not the other!)\n",
    "# print(tokens)\n",
    "# print(encoding.input_ids)\n",
    "\n",
    "# Note that model.embed alone isn't the same thing as what we might normally call \"the embedding\"!\n",
    "embedding_output = model.embed(encoding_idxs) + model.pos_embed(encoding_idxs)\n",
    "compare_same(in_0, embedding_output, atol=1e-8, rtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8f837e48-7390-40a6-b270-5e56d387365a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "att_probs = prop_toy_model_4l_layer(torch.zeros_like(in_0), embedding_output, extended_attention_mask, None, \n",
    "                  {}, [], 0, None,\n",
    "                  model.blocks[0], device, att_probs = None, set_irrel_to_mean=False, target_decomp_method=\"residual\")\n",
    "compare_same(att_probs, cache['blocks.0.attn.hook_pattern'])\n",
    "# print(type(att_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3b999eb8-4522-470b-934a-d71cf57d460f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now check correctness of prop implementation\n",
    "rel, irrel, _, _ = prop_toy_model_4l_layer(torch.zeros_like(in_0), embedding_output, extended_attention_mask, None, \n",
    "                  {}, [], 0, None,\n",
    "                  model.blocks[0], device, att_probs = None, set_irrel_to_mean=False, target_decomp_method=\"residual\")\n",
    "output_layer_0 = rel + irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dd3431e8-5688-457e-a027-6135d06524e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999441964285715"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(output_layer_0, cache['blocks.1.hook_resid_pre'], atol=1e-4)\n",
    "# print(type(desired_output_layer_0))\n",
    "# compare_same(output_layer_0, cache['blocks.1.hook_resid_pre'], atol=1e-6, rtol=1e-5) # numerical error accumulation is significant for this model compared to gpt-2, wonder why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ba3d06cf-ffea-457c-932f-a640dabc1d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_a_ln = prop_toy_model_4l(encoding_idxs,\n",
    "            extended_attention_mask,\n",
    "            model,\n",
    "            [(Node(0, 0, 0),)],\n",
    "            [],\n",
    "            device,\n",
    "            mean_acts = None,\n",
    "            att_list = None,\n",
    "            set_irrel_to_mean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "383a638b-3652-4c21-a6c5-dbc39618e3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.66% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965959821428572"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(cache['ln_final.hook_normalized'], out_a_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ffbbaefd-5be9-4391-a84d-9bc91f449a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_decomps, _, _, _ = prop_toy_model_4l(encoding_idxs,\n",
    "            extended_attention_mask,\n",
    "            model,\n",
    "            [(Node(0, 0, 0),)],\n",
    "            [],\n",
    "            device,\n",
    "            mean_acts = None,\n",
    "            att_list = None,\n",
    "            set_irrel_to_mean=False\n",
    ")\n",
    "output_total = out_decomps[0].rel + out_decomps[0].irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e8756d6-2232-46bb-886f-ed85673b9abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 35, 48262])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e75d591-12f5-4844-bc64-cf22c7bc620e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999997039966374"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(output_total, logits, atol=1) # error accumulated approaches 1e-4 in absolute value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e870560f-8c57-4bb1-babb-1b9cbe897924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def user(self, node, ret, order, version, read, settings):\n",
      "    \"\"\"export chemical plate\n",
      "\n",
      "    :param order: trip miss\n",
      "    :param version: strength scale\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0].clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2304ba2-2910-45af-a3b2-b4f711d13690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = prompts[0].clean_prompt\n",
    "tokens = model.to_tokens(text).to(device)\n",
    "logits, cache = model.run_with_cache(text)\n",
    "probs = logits.softmax(dim=-1)\n",
    "most_likely_next_tokens = model.tokenizer.batch_decode(logits.argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42026a08-7a8e-4ff0-8ea4-980cc5ac48b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4272, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(probs[0, -1, model.to_single_token(tokens[pos_labels.index(\"C_def\")])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16723852-f576-4638-83d2-56dfeec94194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'The', ' get', '_', 'request', ',', ' resource', '):', ' name', '=', ' name', '=', ' **', \"='\", ' name', ',', ' status', '):', '\\n   ', ' \"\"\"', '\\n   ', 's', '.', '.', ' @', 'param', ' fields', ':', ' The', ' value', ' for', ' :', 'param', ' action', ':', ' the', ' stand', '\\n   ', ' :', 'param', ' status']\n"
     ]
    }
   ],
   "source": [
    "print(most_likely_next_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1a37811-1234-4c4f-afb4-01d191a6cc91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def resource(self, fields, shape, last, action, status, info):\n",
      "    \"\"\"trust worker register\n",
      "\n",
      "    :param last: dollar stand\n",
      "    :param action: currency program\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0].clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a34abdc-0fdd-4a43-a0f5-1bbf119a3c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57b72e36-261c-40ab-9a6e-04478ff45064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def resource(self, fields, shape, last, action, status, info):\n",
      "    \"\"\"trust worker register\n",
      "\n",
      "    :param last: dollar stand\n",
      "    :param action: currency program\n",
      "    :param\n",
      " status\n",
      "Tokenized prompt: ['<|BOS|>', '\\n', 'def', ' resource', '(', 'self', ',', ' fields', ',', ' shape', ',', ' last', ',', ' action', ',', ' status', ',', ' info', '):', '\\n   ', ' \"\"\"', 'trust', ' worker', ' register', '\\n\\n   ', ' :', 'param', ' last', ':', ' dollar', ' stand', '\\n   ', ' :', 'param', ' action', ':', ' currency', ' program', '\\n   ', ' :', 'param']\n",
      "Tokenized answer: [' status']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.43</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42.72</span><span style=\"font-weight: bold\">% Token: | status|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.43\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m42.72\u001b[0m\u001b[1m% Token: | status|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.43 Prob: 42.72% Token: | status|\n",
      "Top 1th token. Logit: 16.01 Prob:  3.81% Token: | action|\n",
      "Top 2th token. Logit: 16.01 Prob:  3.80% Token: | value|\n",
      "Top 3th token. Logit: 15.99 Prob:  3.71% Token: | name|\n",
      "Top 4th token. Logit: 15.59 Prob:  2.50% Token: | type|\n",
      "Top 5th token. Logit: 15.41 Prob:  2.08% Token: | description|\n",
      "Top 6th token. Logit: 15.21 Prob:  1.70% Token: |:|\n",
      "Top 7th token. Logit: 15.05 Prob:  1.46% Token: | date|\n",
      "Top 8th token. Logit: 15.04 Prob:  1.44% Token: | body|\n",
      "Top 9th token. Logit: 14.89 Prob:  1.24% Token: | data|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' status'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' status'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_prompt = prompts[prompt_idx].clean_prompt\n",
    "tokens = model.to_str_tokens(example_prompt)\n",
    "\n",
    "example_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "print(example_prompt)\n",
    "print(example_answer)\n",
    "transformer_lens.utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d722ba-c7ac-4313-abeb-25fcb6147a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_layers = len(model.blocks)\n",
    "seq_len = len(pos_labels)\n",
    "num_attention_heads = model.cfg.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3aa1d53-4505-4be5-a13e-05c9c41c346d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupt_prompt = prompts[prompt_idx].corrupt_prompt['random_answer_doc']\n",
    "\n",
    "# corrupt_tokens = model.to_str_tokens(corrupt_prompt)\n",
    "corrupt_logits, corrupt_cache = model.run_with_cache(corrupt_prompt)\n",
    "corrupt_attention_outputs = [corrupt_cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(num_layers)]\n",
    "corrupt_attention_outputs = torch.stack(corrupt_attention_outputs, dim=1).squeeze(0) # now layer, seq, n_heads, dim_attn (squeezed away the batch dim)\n",
    "old_shape = corrupt_attention_outputs.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "corrupt_attention_outputs = corrupt_attention_outputs.view(new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd41cbcb-5c86-4b57-9e20-05b8b492100b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 41, 512])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_attention_outputs.shape\n",
    "# corrupt_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ba2d43-cde8-4d71-8663-87a98b13258b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 1312)\n",
      "Running inputs 64 to 128 (of 1312)\n",
      "Running inputs 128 to 192 (of 1312)\n",
      "Running inputs 192 to 256 (of 1312)\n",
      "Running inputs 256 to 320 (of 1312)\n",
      "Running inputs 320 to 384 (of 1312)\n",
      "Running inputs 384 to 448 (of 1312)\n",
      "Running inputs 448 to 512 (of 1312)\n",
      "Running inputs 512 to 576 (of 1312)\n",
      "Running inputs 576 to 640 (of 1312)\n",
      "Running inputs 640 to 704 (of 1312)\n",
      "Running inputs 704 to 768 (of 1312)\n",
      "Running inputs 768 to 832 (of 1312)\n",
      "Running inputs 832 to 896 (of 1312)\n",
      "Running inputs 896 to 960 (of 1312)\n",
      "Running inputs 960 to 1024 (of 1312)\n",
      "Running inputs 1216 to 1280 (of 1312)\n",
      "Running inputs 1280 to 1312 (of 1312)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import functools\n",
    "encoding = model.tokenizer.encode_plus(prompts[prompt_idx].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 # prepend_bos=True, # currently dealing with this: make sure BOS prepend matches because currently the sequence lengths are off-by-one\n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "\n",
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "]\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "# out_decomp, _, _, pre_layer_activations = prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c91f43-23ce-4d12-81cf-799441da42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d24e75a7-0d09-4573-a40d-90bd285aaff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0328, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(logits[0, -1, pos_labels.index(\"C_def\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf3eec51-ab45-4fc9-81dc-f2a691847f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.428976\n",
      "[ 4.0796576  2.415863   7.0873547  5.1420507  5.5726786  4.3406076\n",
      " 20.308504   9.830674   9.087577  15.697247  10.331891   9.550322\n",
      "  9.558107 ]\n",
      "2.415863\n"
     ]
    }
   ],
   "source": [
    "# just a check\n",
    "output = out_decomps[0].rel + out_decomps[0].irrel\n",
    "tokens = model.to_str_tokens(text)\n",
    "\n",
    "# print(tokens.shape)\n",
    "correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "correct_logit = output[0, -1, correct_logit_idx]\n",
    "incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                 pos_labels.index(\"rand0\"),\n",
    "                 pos_labels.index(\"rand1\"),\n",
    "                 pos_labels.index(\"rand2\"),\n",
    "                 pos_labels.index(\"rand3\"),\n",
    "                 pos_labels.index(\"rand4\"),\n",
    "                 pos_labels.index(\"rand5\"),\n",
    "                 pos_labels.index(\"rand6\"),\n",
    "                 pos_labels.index(\"rand7\"),\n",
    "                 pos_labels.index(\"rand8\"),\n",
    "                 pos_labels.index(\"rand9\"),\n",
    "                 pos_labels.index(\"rand10\"),\n",
    "                 ]\n",
    "incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "incorrect_logits = output[0, -1, incorrect_logit_idxs]\n",
    "\n",
    "diffs = (correct_logit - incorrect_logits)\n",
    "print(correct_logit)\n",
    "print(diffs)\n",
    "print(np.min(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00822bb1-8fec-4a7f-b6f9-fbe3caefcdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevances = np.zeros((num_layers, seq_len, num_attention_heads))\n",
    "tokens = model.to_str_tokens(text) # NOT to_tokens(text)\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "results = []\n",
    "\n",
    "for layer_idx in range(num_layers):\n",
    "    for seq_pos in range(seq_len):\n",
    "        for head_idx in range(num_attention_heads):\n",
    "            score = 0\n",
    "            decomp = out_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "            correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "            rel_correct_logit = decomp.rel[0, -1, correct_logit_idx]\n",
    "            incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                             pos_labels.index(\"rand0\"),\n",
    "                             pos_labels.index(\"rand1\"),\n",
    "                             pos_labels.index(\"rand2\"),\n",
    "                             pos_labels.index(\"rand3\"),\n",
    "                             pos_labels.index(\"rand4\"),\n",
    "                             pos_labels.index(\"rand5\"),\n",
    "                             pos_labels.index(\"rand6\"),\n",
    "                             pos_labels.index(\"rand7\"),\n",
    "                             pos_labels.index(\"rand8\"),\n",
    "                             pos_labels.index(\"rand9\"),\n",
    "                             pos_labels.index(\"rand10\"),\n",
    "                             ]\n",
    "            incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "            rel_incorrect_logits = decomp.rel[0, -1, incorrect_logit_idxs]\n",
    "            score = np.min(rel_correct_logit - rel_incorrect_logits)\n",
    "            relevances[layer_idx, seq_pos, head_idx] = score\n",
    "            results.append(Result(decomp.ablation_set, score))\n",
    "sums_per_layer = np.sum(relevances, axis=(1, 2))\n",
    "sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "normalized_relevances = relevances / np.expand_dims(sums_per_layer, (1, 2))\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5eb36be-ad59-4181-b893-93f4ba215c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c587efc-2e0f-4c08-a1f9-553c956ab249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "s = sns.heatmap(normalized_relevances[:, -1, :], xticklabels = range(num_attention_heads), yticklabels = range(num_layers), cmap='Blues', cbar_kws={'label': ''})\n",
    "s.set(xlabel='Head', ylabel='Layer')\n",
    "plt.title(\"relevance of nodes at last sequence position to logits, normalized for mean relevance among heads in layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "251797fb-2882-4f1c-95c7-8fddd1dfebd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=Node(layer_idx=3, sequence_idx=40, attn_head_idx=0), score=2.4325962)\n",
      "Result(ablation_set=Node(layer_idx=3, sequence_idx=40, attn_head_idx=6), score=2.1737149)\n",
      "Result(ablation_set=Node(layer_idx=2, sequence_idx=40, attn_head_idx=3), score=0.2628063)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=40, attn_head_idx=4), score=0.13904905)\n",
      "Result(ablation_set=Node(layer_idx=0, sequence_idx=15, attn_head_idx=1), score=0.020195633)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=40, attn_head_idx=2), score=0.018609595)\n",
      "Result(ablation_set=Node(layer_idx=2, sequence_idx=28, attn_head_idx=5), score=0.014143206)\n",
      "Result(ablation_set=Node(layer_idx=0, sequence_idx=29, attn_head_idx=2), score=0.010294773)\n",
      "Result(ablation_set=Node(layer_idx=0, sequence_idx=31, attn_head_idx=5), score=0.009637695)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=1, attn_head_idx=7), score=0.00550092)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=0), score=0.0032005142)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=3), score=0.002498461)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=2), score=0.0017409949)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=6), score=0.0013063457)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=7), score=0.0012365524)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=7, attn_head_idx=6), score=0.0012165606)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=8, attn_head_idx=5), score=0.00094232336)\n",
      "Result(ablation_set=Node(layer_idx=1, sequence_idx=2, attn_head_idx=6), score=0.00026798807)\n",
      "Result(ablation_set=Node(layer_idx=2, sequence_idx=23, attn_head_idx=0), score=0.00018911622)\n",
      "Result(ablation_set=Node(layer_idx=2, sequence_idx=13, attn_head_idx=0), score=0.000102497695)\n"
     ]
    }
   ],
   "source": [
    "for result in results[:20]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4607a538-cd2c-4f94-8b93-40ae49a3c1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nArg movers: 3.0, 3.6 at last position\\nInduction: 1.4 at last position\\nPrev token: 0.2 at B_doc, or the one after?\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Arg movers: 3.0, 3.6 at last position\n",
    "Induction: 1.4 at last position\n",
    "Prev token: 0.2 at B_doc, or the one after?\n",
    "Prev token: 2.0 at C_def\n",
    "Prev token: 1.4 at the fourth comma??\n",
    "\n",
    "Also 0.5 at B_def, C_def and B_doc, 0.4 relevant to 1.4, 1.2.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878cba2-3e09-4b74-83e8-a1257cac958d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_per_iter = []\n",
    "results_per_iter.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da921e36-58d5-449b-b6ef-081a678e4822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers = results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e509c4ea-347b-422f-9e90-0aa9a899869e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node(layer_idx=3, sequence_idx=40, attn_head_idx=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].ablation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd76c254-03eb-4c15-9c36-610b625ff69e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(target_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f82034-e351-4b67-87f8-d8054bd27e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 64 (of 1312)\n",
      "Running inputs 64 to 128 (of 1312)\n",
      "Running inputs 128 to 192 (of 1312)\n",
      "Running inputs 192 to 256 (of 1312)\n",
      "Running inputs 256 to 320 (of 1312)\n",
      "Running inputs 320 to 384 (of 1312)\n",
      "Running inputs 384 to 448 (of 1312)\n",
      "Running inputs 448 to 512 (of 1312)\n",
      "Running inputs 512 to 576 (of 1312)\n",
      "Running inputs 576 to 640 (of 1312)\n",
      "Running inputs 640 to 704 (of 1312)\n",
      "Running inputs 704 to 768 (of 1312)\n",
      "Running inputs 768 to 832 (of 1312)\n",
      "Running inputs 832 to 896 (of 1312)\n",
      "Running inputs 896 to 960 (of 1312)\n",
      "Running inputs 960 to 1024 (of 1312)\n",
      "Running inputs 1024 to 1088 (of 1312)\n",
      "Running inputs 1088 to 1152 (of 1312)\n",
      "Running inputs 1152 to 1216 (of 1312)\n",
      "Running inputs 1216 to 1280 (of 1312)\n",
      "Running inputs 1280 to 1312 (of 1312)\n"
     ]
    }
   ],
   "source": [
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "]\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "target_nodes = [outlier.ablation_set[0] for outlier in outliers]\n",
    "\n",
    "# cache activations for faster batch run\n",
    "# out_decomp, _, _, pre_layer_activations = prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8943bc-7273-4e5c-acb5-54a908d892dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevances = np.zeros((num_layers, seq_len, num_attention_heads))\n",
    "results = []\n",
    "for layer_idx in range(num_layers):\n",
    "    for seq_pos in range(seq_len):\n",
    "        for head_idx in range(num_attention_heads):\n",
    "            score = 0\n",
    "            target_decomp = target_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "\n",
    "            for i in range(len(target_decomp.target_nodes)):\n",
    "                rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "                irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "                target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "                score += (target_node_score)\n",
    "            if target_decomp.ablation_set[0] in target_nodes:\n",
    "                score = 0\n",
    "            relevances[layer_idx, seq_pos, head_idx] = score\n",
    "            results.append(Result(decomp.ablation_set, score))\n",
    "\n",
    "sums_per_layer = np.sum(relevances, axis=(1, 2))\n",
    "sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "normalized_relevances = relevances / np.expand_dims(sums_per_layer, (1, 2))\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4437c-4ee3-4315-ac90-7f8f030b9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sns.heatmap(normalized_relevances[:, -1, :], xticklabels = range(num_attention_heads), yticklabels = range(num_layers), cmap='Blues', cbar_kws={'label': ''})\n",
    "s.set(xlabel='Head', ylabel='Layer')\n",
    "plt.title(\"relevance of nodes at last sequence position to 'arg mover' heads, normalized\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
