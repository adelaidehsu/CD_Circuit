{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d8ad14-fc04-4c67-8f34-9f74f240b41f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0f3e36-fa19-4472-8945-3e17f6f8a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39df4701-17e9-4f7d-bf8e-5b1e7e2ed251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import operator\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "from pyfunctions.general import compare_same\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.cdt_source_to_target import *\n",
    "from pyfunctions.cdt_from_source_nodes import *\n",
    "from pyfunctions.toy_model import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cbf067-0094-4f4e-a638-d0af92064665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-4l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# from mi_utils_public import *\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "model = HookedTransformer.from_pretrained('attn-only-4l',\n",
    "                                         fold_ln=False)\n",
    "\n",
    "\"\"\"Toggle whether to explicitly calculate and expose the result for each attention head.\n",
    "Useful for interpretability but can easily burn through GPU memory.\n",
    "        \"\"\"\n",
    "model.cfg.use_attn_result = False # Not actually needed because we have methods for accessing the activation cache anyway.\n",
    "# note from the mi_utils guys: \"because running subprocess breaks things\"\n",
    "# %env TOKENIZERS_PARALLELISM=true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ac0b0f-cbfb-43df-a24e-35dab545e754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from im_utils.prompts import Prompt, docstring_ind_prompt_gen\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "docstring_ind_prompt_kwargs = dict(\n",
    "    n_matching_args=3,\n",
    "    n_def_prefix_args=2,\n",
    "    n_def_suffix_args=1,\n",
    "    n_doc_prefix_args=0,\n",
    "    met_desc_len=3,\n",
    "    arg_desc_len=2\n",
    ")\n",
    "prompts = [docstring_ind_prompt_gen(\"rest\", **docstring_ind_prompt_kwargs) for _ in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a425b81-95ce-4824-a493-556d980d13f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m prompts[prompt_idx]\u001b[38;5;241m.\u001b[39mclean_prompt\n\u001b[1;32m      3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto_str_tokens(example_prompt)\n\u001b[0;32m----> 5\u001b[0m example_answer \u001b[38;5;241m=\u001b[39m tokens[\u001b[43mpos_labels\u001b[49m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(example_prompt)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(example_answer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos_labels' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for prompt_idx in range(10):\n",
    "    example_prompt = prompts[prompt_idx].clean_prompt\n",
    "    tokens = model.to_str_tokens(example_prompt)\n",
    "\n",
    "    example_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "    # print(example_prompt)\n",
    "    print(example_answer)\n",
    "    # transformer_lens.utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)\n",
    "    # print('#####################')\n",
    "    print(model.to_string(model.generate(example_prompt, max_new_tokens=1, do_sample=False, return_type='tensor')[0][-1]))\n",
    "    print(example_answer == model.to_string(model.generate(example_prompt, max_new_tokens=1, do_sample=False, return_type='tensor')[0][-1]))\n",
    "    print('#####################')\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045af79e-42bb-46ef-85ee-0577a7fd0396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8d9004-4a12-4246-bc9d-d7339a90e790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = model.to_str_tokens(prompts[0].clean_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf3d334-05b4-43b8-898c-04c160e01fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_labels = model.to_str_tokens(prompts[0].clean_prompt)\n",
    "pos_labels[ 0] = \"BOS\"\n",
    "pos_labels[ 1] = \"⏎\"\n",
    "pos_labels[ 2] = \"def\"\n",
    "pos_labels[ 3] = \"rand0\"\n",
    "pos_labels[ 4] = \"(\"\n",
    "pos_labels[ 5] = \"self\"\n",
    "pos_labels[ 6] = \",_0\"\n",
    "pos_labels[ 7] = \"rand1\"\n",
    "pos_labels[ 8] = \",_1\"\n",
    "pos_labels[ 9] = \"rand2\"\n",
    "pos_labels[10] = \",_2\"\n",
    "pos_labels[11] = \"A_def\"\n",
    "pos_labels[12] = \",_A\"\n",
    "pos_labels[13] = \"B_def\"\n",
    "pos_labels[14] = \",_B\"\n",
    "pos_labels[15] = \"C_def\"\n",
    "pos_labels[16] = \",_C\"\n",
    "pos_labels[17] = \"rand3\"\n",
    "pos_labels[18] = \"):\"\n",
    "pos_labels[19] = \"⏎···_0\"\n",
    "pos_labels[20] = '\"\"\"'\n",
    "pos_labels[21] = \"rand4\"\n",
    "pos_labels[22] = \"rand5\"\n",
    "pos_labels[23] = \"rand6\"\n",
    "pos_labels[24] = \"⏎⏎···_1\"\n",
    "pos_labels[25] = \"·:_0\"\n",
    "pos_labels[26] = \"param_1\"\n",
    "pos_labels[27] = \"A_doc\"\n",
    "pos_labels[28] = \":_1\"\n",
    "pos_labels[29] = \"rand7\"\n",
    "pos_labels[30] = \"rand8\"\n",
    "pos_labels[31] = \"⏎···_2\"\n",
    "pos_labels[32] = \"·:_1\"\n",
    "pos_labels[33] = \"param_2\"\n",
    "pos_labels[34] = \"B_doc\"\n",
    "pos_labels[35] = \":_2\"\n",
    "pos_labels[36] = \"rand9\"\n",
    "pos_labels[37] = \"rand10\"\n",
    "pos_labels[38] = \"⏎···_3\"\n",
    "pos_labels[39] = \"·:_2\"\n",
    "pos_labels[40] = \"param_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b4bc54-6dcd-47e3-a361-fc89732e324e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f13334d4e4d4dfc91f481633bb4926a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d67baefa0e94aaca92a96adf0f42614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e6c3ea35d04c419853683e900721b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852ec27c6a48414b8731d2941ea76819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cabac575de48f0a741b564efcf49f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de1a09e15fd4fccb5a7a73d245e0c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e66231868b41c5bf6368007d1aa775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4d997a2993425686482d682e1c4783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95a8196b7b142e49eb18f1d40fcfad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10938f41d7d94e29994e76843a58e4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1452a36b12245709b104214c569d6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c736e9b13dc4f9dbfc928ac80c772d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151bc69d8ff043579da1daca507307e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011b33f346524c158c82c6b49922f740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab29f12943474086009c98169f03b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3b58983a1c4b358032bc063a904830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9893153bc94be7b3da8a38ea986a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965f2a1a56fa47f3816f8a48721c2f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805e30b032d2411e83c1586a94249b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e878fd532244c378477f6fb74c9064e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af339db5b7d840a1afadd3c41eb45ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856515a9e799421192a709c4ee1f596c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6a69c550344db2bc6babad85a08c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2fc62dec2046f6a4136e2b67239e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a702cd9c17946c3afe4a882047cd790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ee2c6f26a5454c984e3a95a49ebf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196c297379f14013bb239bda7fed0129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185a73abb6e54c92a17799a2758ae8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a012b66fef474ec4890e295f6348a87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03acd9a02da046158140dfd395d6cdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243e80fc91394d8da00f6caa056edd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cd3505c91b4d1ba1f3561c1e586175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16286dfd7f3a4414ad7a84fe218e3356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8f688497114cf2be66caf7d096706c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14948916304a4cf2a702f0e5237a40ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d101b4517843ad9d2500600614cf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7dcdb8722d45a69121a9313a1c64d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02022006922748958286c8b06ca4b393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc781c2ce58403ca307e3354a30b9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419a673410be425caad6784b4043c3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9718986b2c88426c87be6e43bce77be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac472e7b3b640c681d9ee45c87c005e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e4cca45b2145e18ec51f0a3c4311b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e70a186ef249ef9a602650d7e765f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0b227f5cfd44888b83a3d167b66e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1808ea5b8c64d3f92068f2302a62db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9af3a5f121045c59e52fd05c2502137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44629f390a95421a9c006f549f315b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c228ad7d0af4cc182b0c0a7da5a0ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6572ee047064faca52c035f8c3c6b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9b6d4d28ca4fc3b3aea55bd3b9e73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e53d2b61324fe8bd0f18ad0c13c6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ddf166cfce40309cade0712a97d6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69d61a0f3c646b8a5fbdfe84f903067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1034ab2d7f824277a173c25f7a24c8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb31b828f4a4185b9136ddef1fed07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce4ce3cfcb54caeba9e7947df470768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc246c35424b410fa48bc0d26acaebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd5ab5e22d24ea6a8ac162dcce18872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa50d9c57b546e9917d5e3ed8003102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f02e250162245eca12615ce64341a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dbb470bac542fd85b8729dd729774e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c62de13ff24eec9010765042d2a4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b755bb1268404401aaf54a2e0a453184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e08e74659b24d31bafeafd333ba4f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488e5c4e1ae346628645fca93e365590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bd779f96e84f04b8b922e862ea5ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de765c15060c4e778904a31f7e2d86ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a423b28843e4361a9212c283286c1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a888e4a1dc3452da34238b10901dffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d908b78d43a446ea205733090ba55fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ce4bc807294a4aa94723cbcf52ebe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a928240d568e453cad7311e1d4023880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b8a03dcd3747fb89c6b73a15b067bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943e28b8a0e8471da2deb2d787c0a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413e8d1cdc7e4914a797f3f88a39fa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7827586f03c4a6d9363b82a7bf38348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69bfa0cc27541f88023034779d2ff59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae061964a92d4f0fb00617d38d1e1eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9c1835b3ae4620bc6978645ed8335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6d78e0127849d1958d54f111cb5a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0243d93d23884519a0139fbf52774104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b20e059bd94c9fb147a03a85ef4942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a2e9a234ea498fb7c05f3ecf45a83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2aa78345b8469986166a6f63f3e1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6e9059d04e435886952396b0a17033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fa8812e8044b94a9e373ad452399b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c326eaf09bdd400e853b368f212f6704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fec2a88d1149a993965e58bd83d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d107bfce4644f790b8cf7861e3bfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca186997b09d4aac9a980b32b3af170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4ec5b2436e4f0b9575e523b9afeb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de7b3031a348c88bd9970e81b70c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2176f362710248b5b2417d34d96a5b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ade8756a4945aca5351b9cdb7c7f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c541f0ec696148b798863e971c41a9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb2a75a25734ed583af6d3fb043a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47051ffef9694cdd9169d568f4ffab93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b55a542cb9474ba33b63b943b165d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb1d19e0c544347ac58844e3faad7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a \"better\" dataset, i.e, ones where the model answers the correct answer, preferably by a wide margin.\n",
    "# the toy model actually isn't very good at the docstring task, only getting it right like 50-75% of the time.\n",
    "# We obviously can't investigate the question of how the model does the docstring task if it's not actually \"doing\" it.\n",
    "good_prompts = []\n",
    "for prompt in prompts:\n",
    "    clean_prompt = prompt.clean_prompt\n",
    "    tokens = model.to_str_tokens(clean_prompt)\n",
    "    # it's perhaps better to check if the model's prediction logit is highest by a certain threshold.\n",
    "    correct_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "    model_prediction = model.to_string(model.generate(clean_prompt, max_new_tokens=1, do_sample=False, return_type='tensor')[0][-1])\n",
    "    if model_prediction == correct_answer:\n",
    "        good_prompts.append(prompt)\n",
    "prompts = good_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e101be-0bf1-412b-88dd-36eddd8a58fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1947c6bf-8503-4300-9732-4562ff34b2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_layers = len(model.blocks)\n",
    "seq_len = len(pos_labels)\n",
    "num_attention_heads = model.cfg.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8588c472-012c-47d3-8fb1-f213186d289a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this thing assumes the input is a list of sequences, the sequences are a list of tokens\n",
    "# if you pass in only a single list, you should wrap it in a [] \n",
    "def compute_logits_decomposition_scores(texts, out_decomps):\n",
    "    if not isinstance(texts, list):\n",
    "        texts = [texts] # so that the batching works out\n",
    "    relevances = np.zeros((num_layers, seq_len, num_attention_heads))\n",
    "     # NOT to_tokens(text)\n",
    "    batch_size = len(texts)\n",
    "    results = []\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        for seq_pos in range(seq_len):\n",
    "            for head_idx in range(num_attention_heads):\n",
    "                score = 0\n",
    "                decomp = out_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "                for i in range(batch_size):\n",
    "                    tokens = model.to_str_tokens(texts[i])\n",
    "                    correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "                    rel_correct_logit = decomp.rel[i, -1, correct_logit_idx]\n",
    "                    incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                                     pos_labels.index(\"rand0\"),\n",
    "                                     pos_labels.index(\"rand1\"),\n",
    "                                     pos_labels.index(\"rand2\"),\n",
    "                                     pos_labels.index(\"rand3\"),\n",
    "                                     pos_labels.index(\"rand4\"),\n",
    "                                     pos_labels.index(\"rand5\"),\n",
    "                                     pos_labels.index(\"rand6\"),\n",
    "                                     pos_labels.index(\"rand7\"),\n",
    "                                     pos_labels.index(\"rand8\"),\n",
    "                                     pos_labels.index(\"rand9\"),\n",
    "                                     pos_labels.index(\"rand10\"),\n",
    "                                     ]\n",
    "                    incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "                    rel_incorrect_logits = decomp.rel[i, -1, incorrect_logit_idxs]\n",
    "                    score += np.min(rel_correct_logit - rel_incorrect_logits)\n",
    "                    relevances[layer_idx, seq_pos, head_idx] = score\n",
    "                score /= batch_size\n",
    "                results.append(Result(decomp.ablation_set, score))\n",
    "    # sums_per_layer = np.sum(relevances, axis=(1, 2))\n",
    "    # sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "    # normalized_relevances = relevances / np.expand_dims(sums_per_layer, (1, 2))\n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    return results, relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8064a3-f2f7-48c2-a875-835b10fef418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_target_decomposition_scores(target_decomps, normalized=False):\n",
    "    relevances = np.zeros((num_layers, seq_len, num_attention_heads))\n",
    "    results = []\n",
    "    for layer_idx in range(num_layers):\n",
    "        for seq_pos in range(seq_len):\n",
    "            for head_idx in range(num_attention_heads):\n",
    "                score = 0\n",
    "                target_decomp = target_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "\n",
    "                for i in range(len(target_decomp.target_nodes)):\n",
    "                    rels_magnitude = torch.mean(abs(target_decomp.rels[i])) # np.mean if you are on cpu\n",
    "                    irrels_magnitude = torch.mean(abs(target_decomp.irrels[i])) # np.mean if you are on cpu\n",
    "                    target_node_score = rels_magnitude / (rels_magnitude + irrels_magnitude)\n",
    "                    score += (target_node_score)\n",
    "                if target_decomp.ablation_set[0] in target_nodes:\n",
    "                    score = 0\n",
    "                relevances[layer_idx, seq_pos, head_idx] = score\n",
    "                if not normalized:\n",
    "                    results.append(Result(target_decomp.ablation_set, relevances[layer_idx, seq_pos, head_idx]))\n",
    "    if normalized:\n",
    "        sums_per_layer = np.sum(relevances, axis=(1, 2))\n",
    "        sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "        relevances = relevances / np.expand_dims(sums_per_layer, (1, 2))\n",
    "\n",
    "        for layer_idx in range(num_layers):\n",
    "            for seq_pos in range(seq_len):\n",
    "                for head_idx in range(num_attention_heads):\n",
    "                    target_decomp = target_decomps[layer_idx * seq_len * num_attention_heads + seq_pos * num_attention_heads + head_idx]\n",
    "                    results.append(Result(target_decomp.ablation_set, relevances[layer_idx, seq_pos, head_idx]))\n",
    "    \n",
    "    results.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    return results, relevances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2cf67b-21e1-4cc3-9023-a6170c655e44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Datatype investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b83127-6624-43c8-bf2d-ddb6d58dd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685235b0-7ad0-4c78-b845-27b147af5cc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param description: drug machine\n",
      "    :param status: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, state, server, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, option):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug machine\n",
      "    :param server: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, filename, valid, host):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param name: drug machine\n",
      "    :param index: ground register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param description: drug\n",
      "    :param status: ground machine register\n",
      "    :param\n",
      "\n",
      "def msg(self, description, status, call):\n",
      "    \"\"\"choice minute sort\n",
      "\n",
      "    :param state: drug\n",
      "    :param server: ground machine register\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "# dir(prompts[0])\n",
    "'''\n",
    "'clean_prompt',\n",
    " 'correct_answers',\n",
    " 'corrupt_prompt',\n",
    " 'print_all_corrupt',\n",
    " 'print_all_corrupt_tokenized',\n",
    " 'print_clean',\n",
    " 'print_clean_tokenized',\n",
    " 'print_corrupt',\n",
    " 'print_corrupt_tokenized',\n",
    " 'print_tokenized',\n",
    " 'wrong_answers'\n",
    "'''\n",
    "\n",
    "print(prompts[0].clean_prompt)\n",
    "# 'random_doc', 'random_def', 'random_answer', 'random_def_doc', 'random_answer_doc', 'random_random', 'vary_length_doc_desc', 'vary_length_doc_desc_random_doc'\n",
    "# print(prompts[0].corrupt_prompt.keys())\n",
    "# type(prompts[0])\n",
    "# These are actually decently well explained in the original LessWrong post, I just didn't see it at first.\n",
    "print(prompts[0].corrupt_prompt['random_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_def_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_answer_doc'])\n",
    "print(prompts[0].corrupt_prompt['random_random'])\n",
    "print(prompts[0].corrupt_prompt['vary_length_doc_desc'])\n",
    "print(prompts[0].corrupt_prompt['vary_length_doc_desc_random_doc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1dcd6-12b8-4a09-9237-0adc86c7b42b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Correctness tests for implementation of CD-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5a2ba9f0-3f65-4ced-b5e4-f90a68763d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed                     (1, 35, 512)\n",
      "hook_pos_embed                 (1, 35, 512)\n",
      "blocks.0.hook_resid_pre        (1, 35, 512)\n",
      "blocks.0.ln1.hook_scale        (1, 35, 1)\n",
      "blocks.0.ln1.hook_normalized   (1, 35, 512)\n",
      "blocks.0.attn.hook_q           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_k           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_v           (1, 35, 8, 64)\n",
      "blocks.0.attn.hook_attn_scores (1, 8, 35, 35)\n",
      "blocks.0.attn.hook_pattern     (1, 8, 35, 35)\n",
      "blocks.0.attn.hook_z           (1, 35, 8, 64)\n",
      "blocks.0.hook_attn_out         (1, 35, 512)\n",
      "blocks.0.hook_resid_post       (1, 35, 512)\n",
      "ln_final.hook_scale            (1, 35, 1)\n",
      "ln_final.hook_normalized       (1, 35, 512)\n"
     ]
    }
   ],
   "source": [
    "logits, cache = model.run_with_cache(prompts[0].clean_prompt)\n",
    "tokens = model.to_tokens(prompts[0].clean_prompt).to(device)\n",
    "# logits, cache = model.run_with_cache(tokens)\n",
    "for activation_name, activation in cache.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(f\"{activation_name:30} {tuple(activation.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a1573d0f-19b5-4c04-a77e-e42e07438d22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(cache['blocks.1.hook_resid_pre'], cache['blocks.0.hook_resid_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0d1af7d-28dc-4d7f-99b7-ceadc46a5546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoding = model.tokenizer.encode_plus(prompts[0].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 # prepend_bos=True, # currently dealing with this: make sure BOS prepend matches because currently the sequence lengths are off-by-one\n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "620ac2b4-e534-43c1-aba2-f5c99dc3d028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n",
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_0 = cache['blocks.0.hook_resid_pre']\n",
    "compare_same(cache['hook_embed'] + cache['hook_pos_embed'], cache['blocks.0.hook_resid_pre'])\n",
    "\n",
    "# Ensure that the encodings are the same (they won't be if you set prepend_bos=True for one and not the other!)\n",
    "# print(tokens)\n",
    "# print(encoding.input_ids)\n",
    "\n",
    "# Note that model.embed alone isn't the same thing as what we might normally call \"the embedding\"!\n",
    "embedding_output = model.embed(encoding_idxs) + model.pos_embed(encoding_idxs)\n",
    "compare_same(in_0, embedding_output, atol=1e-8, rtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8f837e48-7390-40a6-b270-5e56d387365a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "att_probs = prop_toy_model_4l_layer(torch.zeros_like(in_0), embedding_output, extended_attention_mask, None, \n",
    "                  {}, [], 0, None,\n",
    "                  model.blocks[0], device, att_probs = None, set_irrel_to_mean=False, target_decomp_method=\"residual\")\n",
    "compare_same(att_probs, cache['blocks.0.attn.hook_pattern'])\n",
    "# print(type(att_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3b999eb8-4522-470b-934a-d71cf57d460f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now check correctness of prop implementation\n",
    "rel, irrel, _, _ = prop_toy_model_4l_layer(torch.zeros_like(in_0), embedding_output, extended_attention_mask, None, \n",
    "                  {}, [], 0, None,\n",
    "                  model.blocks[0], device, att_probs = None, set_irrel_to_mean=False, target_decomp_method=\"residual\")\n",
    "output_layer_0 = rel + irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dd3431e8-5688-457e-a027-6135d06524e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999441964285715"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(output_layer_0, cache['blocks.1.hook_resid_pre'], atol=1e-4)\n",
    "# print(type(desired_output_layer_0))\n",
    "# compare_same(output_layer_0, cache['blocks.1.hook_resid_pre'], atol=1e-6, rtol=1e-5) # numerical error accumulation is significant for this model compared to gpt-2, wonder why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ba3d06cf-ffea-457c-932f-a640dabc1d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_a_ln = prop_toy_model_4l(encoding_idxs,\n",
    "            extended_attention_mask,\n",
    "            model,\n",
    "            [(Node(0, 0, 0),)],\n",
    "            [],\n",
    "            device,\n",
    "            mean_acts = None,\n",
    "            att_list = None,\n",
    "            set_irrel_to_mean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "383a638b-3652-4c21-a6c5-dbc39618e3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.66% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965959821428572"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(cache['ln_final.hook_normalized'], out_a_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ffbbaefd-5be9-4391-a84d-9bc91f449a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_decomps, _, _, _ = prop_toy_model_4l(encoding_idxs,\n",
    "            extended_attention_mask,\n",
    "            model,\n",
    "            [(Node(0, 0, 0),)],\n",
    "            [],\n",
    "            device,\n",
    "            mean_acts = None,\n",
    "            att_list = None,\n",
    "            set_irrel_to_mean=False\n",
    ")\n",
    "output_total = out_decomps[0].rel + out_decomps[0].irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e8756d6-2232-46bb-886f-ed85673b9abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 35, 48262])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e75d591-12f5-4844-bc64-cf22c7bc620e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% of the values are equal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999997039966374"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_same(output_total, logits, atol=1) # error accumulated approaches 1e-4 in absolute value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e870560f-8c57-4bb1-babb-1b9cbe897924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def user(self, node, ret, order, version, read, settings):\n",
      "    \"\"\"export chemical plate\n",
      "\n",
      "    :param order: trip miss\n",
      "    :param version: strength scale\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0].clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2304ba2-2910-45af-a3b2-b4f711d13690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = prompts[0].clean_prompt\n",
    "logits, cache = model.run_with_cache(text)\n",
    "probs = logits.softmax(dim=-1)\n",
    "most_likely_next_tokens = model.tokenizer.batch_decode(logits.argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42026a08-7a8e-4ff0-8ea4-980cc5ac48b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4272, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(probs[0, -1, model.to_single_token(tokens[pos_labels.index(\"C_def\")])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16723852-f576-4638-83d2-56dfeec94194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'The', ' get', '_', 'request', ',', ' resource', '):', ' name', '=', ' name', '=', ' **', \"='\", ' name', ',', ' status', '):', '\\n   ', ' \"\"\"', '\\n   ', 's', '.', '.', ' @', 'param', ' fields', ':', ' The', ' value', ' for', ' :', 'param', ' action', ':', ' the', ' stand', '\\n   ', ' :', 'param', ' status']\n"
     ]
    }
   ],
   "source": [
    "print(most_likely_next_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1a37811-1234-4c4f-afb4-01d191a6cc91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def resource(self, fields, shape, last, action, status, info):\n",
      "    \"\"\"trust worker register\n",
      "\n",
      "    :param last: dollar stand\n",
      "    :param action: currency program\n",
      "    :param\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0].clean_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a04cb-b3ec-4c7b-a1a3-c911729b26d8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ec72c-4103-4b1d-a41b-9b77d9e87d0f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Loose investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3aa1d53-4505-4be5-a13e-05c9c41c346d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupt_prompt = prompts[prompt_idx].corrupt_prompt['random_answer_doc']\n",
    "\n",
    "# corrupt_tokens = model.to_str_tokens(corrupt_prompt)\n",
    "corrupt_logits, corrupt_cache = model.run_with_cache(corrupt_prompt)\n",
    "corrupt_attention_outputs = [corrupt_cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(num_layers)]\n",
    "corrupt_attention_outputs = torch.stack(corrupt_attention_outputs, dim=1).squeeze(0) # now layer, seq, n_heads, dim_attn (squeezed away the batch dim)\n",
    "old_shape = corrupt_attention_outputs.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "corrupt_attention_outputs = corrupt_attention_outputs.view(new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd41cbcb-5c86-4b57-9e20-05b8b492100b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 41, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_attention_outputs.shape\n",
    "# corrupt_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ba2d43-cde8-4d71-8663-87a98b13258b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running input 0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import functools\n",
    "encoding = model.tokenizer.encode_plus(prompts[prompt_idx].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 # prepend_bos=True, # currently dealing with this: make sure BOS prepend matches because currently the sequence lengths are off-by-one\n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "\n",
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "]\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "# out_decomp, _, _, pre_layer_activations = prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) #, num_at_time=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24e75a7-0d09-4573-a40d-90bd285aaff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.6641, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "logits, cache = model.run_with_cache(prompts[prompt_idx].clean_prompt)\n",
    "\n",
    "correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "print(logits[0, -1, correct_logit_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf3eec51-ab45-4fc9-81dc-f2a691847f05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.428976\n",
      "[ 4.0796576  2.415863   7.0873547  5.1420507  5.5726786  4.3406076\n",
      " 20.308504   9.830674   9.087577  15.697247  10.331891   9.550322\n",
      "  9.558107 ]\n",
      "2.415863\n"
     ]
    }
   ],
   "source": [
    "# just a check\n",
    "\n",
    "output = out_decomps[0].rel + out_decomps[0].irrel\n",
    "tokens = model.to_str_tokens(text)\n",
    "\n",
    "# print(tokens.shape)\n",
    "correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "correct_logit = output[0, -1, correct_logit_idx]\n",
    "incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                 pos_labels.index(\"rand0\"),\n",
    "                 pos_labels.index(\"rand1\"),\n",
    "                 pos_labels.index(\"rand2\"),\n",
    "                 pos_labels.index(\"rand3\"),\n",
    "                 pos_labels.index(\"rand4\"),\n",
    "                 pos_labels.index(\"rand5\"),\n",
    "                 pos_labels.index(\"rand6\"),\n",
    "                 pos_labels.index(\"rand7\"),\n",
    "                 pos_labels.index(\"rand8\"),\n",
    "                 pos_labels.index(\"rand9\"),\n",
    "                 pos_labels.index(\"rand10\"),\n",
    "                 ]\n",
    "incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "incorrect_logits = output[0, -1, incorrect_logit_idxs]\n",
    "\n",
    "diffs = (correct_logit - incorrect_logits)\n",
    "print(correct_logit)\n",
    "print(diffs)\n",
    "print(np.min(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c587efc-2e0f-4c08-a1f9-553c956ab249",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "s = sns.heatmap(relevances[:, -1, :], xticklabels = range(num_attention_heads), yticklabels = range(num_layers), cmap='Blues', cbar_kws={'label': ''})\n",
    "s.set(xlabel='Head', ylabel='Layer')\n",
    "plt.title(\"relevance of nodes at last sequence position to logits, normalized for mean relevance among heads in layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251797fb-2882-4f1c-95c7-8fddd1dfebd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=40, attn_head_idx=0),), score=3.5854855)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=40, attn_head_idx=6),), score=1.620693)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=40, attn_head_idx=3),), score=0.26229173)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=40, attn_head_idx=7),), score=0.1636591)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=15, attn_head_idx=5),), score=0.11920023)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=40, attn_head_idx=7),), score=0.09153849)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=15, attn_head_idx=0),), score=0.033045173)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=34, attn_head_idx=1),), score=0.02659972)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=29, attn_head_idx=7),), score=0.025986627)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=27, attn_head_idx=1),), score=0.024690509)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=18, attn_head_idx=1),), score=0.022711635)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=15, attn_head_idx=3),), score=0.020621777)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=38, attn_head_idx=7),), score=0.018891394)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=19, attn_head_idx=3),), score=0.017226428)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=34, attn_head_idx=6),), score=0.017215706)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=27, attn_head_idx=0),), score=0.015927196)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=15, attn_head_idx=7),), score=0.015478581)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=30, attn_head_idx=5),), score=0.01494772)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=30, attn_head_idx=1),), score=0.0147103)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=35, attn_head_idx=5),), score=0.014111102)\n"
     ]
    }
   ],
   "source": [
    "for result in results[:20]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f795c37-4e33-40c0-8564-4173ed9e2bd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inputs 0 to 32 (of 32)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import functools\n",
    "encoding = model.tokenizer.encode_plus(prompts[prompt_idx].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "encoding_idxs, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = encoding_idxs.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "'''\n",
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "]\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "\n",
    "'''\n",
    "ablation_sets = []\n",
    "for layer in range(num_layers):\n",
    "    for attn_head in range(num_attention_heads):\n",
    "        ablation_sets.append(tuple(Node(layer, seq_pos, attn_head) for seq_pos in range(seq_len)))\n",
    "\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "# out_decomp, _, _, pre_layer_activations = prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:1, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "out_decomps, target_decomps = batch_run(prop_fn, ablation_sets) #, num_at_time=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7924c3f-1be5-43ea-9e96-0c6d1d40519d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = prompts[prompt_idx].clean_prompt\n",
    "\n",
    "relevances = np.zeros((num_layers, num_attention_heads))\n",
    "tokens = model.to_str_tokens(text) # NOT to_tokens(text)\n",
    "Result = collections.namedtuple('Result', ('ablation_set', 'score'))\n",
    "results = []\n",
    "\n",
    "for layer_idx in range(num_layers):\n",
    "    for head_idx in range(num_attention_heads):\n",
    "        score = 0\n",
    "        decomp = out_decomps[layer_idx * num_attention_heads + head_idx]\n",
    "        correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "        rel_correct_logit = decomp.rel[0, -1, correct_logit_idx]\n",
    "        incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                         pos_labels.index(\"rand0\"),\n",
    "                         pos_labels.index(\"rand1\"),\n",
    "                         pos_labels.index(\"rand2\"),\n",
    "                         pos_labels.index(\"rand3\"),\n",
    "                         pos_labels.index(\"rand4\"),\n",
    "                         pos_labels.index(\"rand5\"),\n",
    "                         pos_labels.index(\"rand6\"),\n",
    "                         pos_labels.index(\"rand7\"),\n",
    "                         pos_labels.index(\"rand8\"),\n",
    "                         pos_labels.index(\"rand9\"),\n",
    "                         pos_labels.index(\"rand10\"),\n",
    "                         ]\n",
    "        incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "        rel_incorrect_logits = decomp.rel[0, -1, incorrect_logit_idxs]\n",
    "        score = np.min(rel_correct_logit - rel_incorrect_logits)\n",
    "        relevances[layer_idx, head_idx] = score\n",
    "        results.append(Result(decomp.ablation_set, score))\n",
    "sums_per_layer = np.sum(relevances, axis=1)\n",
    "sums_per_layer[sums_per_layer == 0] = -1e-8\n",
    "normalized_relevances = relevances / np.expand_dims(sums_per_layer, 1)\n",
    "results.sort(key=operator.attrgetter('score'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9798e-525f-4d21-8638-508f4e1964dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0:  3.5854855\n",
      "3.6:  1.620693\n",
      "2.3:  0.2665378\n",
      "3.7:  0.1636591\n",
      "2.7:  0.11762053\n",
      "0.0:  0.022501111\n",
      "0.3:  0.015666306\n",
      "2.0:  0.00905484\n",
      "1.7:  0.0027136207\n",
      "1.3:  0.0024920702\n",
      "2.1:  -0.0019327998\n",
      "1.2:  -0.0033437312\n",
      "2.6:  -0.0044555664\n",
      "0.5:  -0.0048312545\n",
      "0.1:  -0.006903589\n",
      "0.6:  -0.008307397\n",
      "0.2:  -0.011153758\n",
      "1.0:  -0.012790024\n",
      "0.7:  -0.022209883\n",
      "0.4:  -0.023172408\n"
     ]
    }
   ],
   "source": [
    "for result in results[:20]:\n",
    "    print(\"%d.%d: \" % (result.ablation_set[0].layer_idx, result.ablation_set[0].attn_head_idx), result.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4607a538-cd2c-4f94-8b93-40ae49a3c1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nArg movers: 3.0, 3.6 at last position\\nInduction: 1.4 at last position\\nPrev token: 0.2 at B_doc, or the one after?\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Arg movers: 3.0, 3.6 at last position (40)\n",
    "Induction: 1.4 at last position (40)\n",
    "Prev token: 0.2 at B_doc, or the one after? (34) or (35) # can't be found by patching, maybe can be found here\n",
    "Prev token: 2.0 at C_def (15)\n",
    "Prev token: 1.4 at the fourth comma?? (14)\n",
    "\n",
    "Also 0.5 at B_def (13), C_def (15) and B_doc (34), (0.4 relevant to 1.4), 1.2.\n",
    "Also 2.3, 0.5, 1.2, 0.0, 0.1, 2.2, in roughly that order.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318366f-fc87-44fc-81b5-5817ed6496e6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## All in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39187319-06f3-4e71-9791-a26ef6d3e802",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def parser(self, image, format, code, query, line, client):\n",
      "    \"\"\"leg shell nature\n",
      "\n",
      "    :param code: mile protein\n",
      "    :param query: process hat\n",
      "    :param\n",
      " line\n",
      "Tokenized prompt: ['<|BOS|>', '\\n', 'def', ' parser', '(', 'self', ',', ' image', ',', ' format', ',', ' code', ',', ' query', ',', ' line', ',', ' client', '):', '\\n   ', ' \"\"\"', 'leg', ' shell', ' nature', '\\n\\n   ', ' :', 'param', ' code', ':', ' mile', ' protein', '\\n   ', ' :', 'param', ' query', ':', ' process', ' hat', '\\n   ', ' :', 'param']\n",
      "Tokenized answer: [' line']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.15</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.31</span><span style=\"font-weight: bold\">% Token: | line|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m21.15\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m76.31\u001b[0m\u001b[1m% Token: | line|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 21.15 Prob: 76.31% Token: | line|\n",
      "Top 1th token. Logit: 17.00 Prob:  1.20% Token: | format|\n",
      "Top 2th token. Logit: 16.60 Prob:  0.81% Token: | client|\n",
      "Top 3th token. Logit: 16.38 Prob:  0.65% Token: | query|\n",
      "Top 4th token. Logit: 16.27 Prob:  0.58% Token: | code|\n",
      "Top 5th token. Logit: 16.24 Prob:  0.56% Token: | lines|\n",
      "Top 6th token. Logit: 16.20 Prob:  0.54% Token: | int|\n",
      "Top 7th token. Logit: 16.02 Prob:  0.45% Token: |:|\n",
      "Top 8th token. Logit: 15.99 Prob:  0.44% Token: | source|\n",
      "Top 9th token. Logit: 15.91 Prob:  0.40% Token: | data|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' line'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' line'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of task\n",
    "example_prompt = prompts[prompt_idx].clean_prompt\n",
    "tokens = model.to_str_tokens(example_prompt)\n",
    "\n",
    "example_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "print(example_prompt)\n",
    "print(example_answer)\n",
    "transformer_lens.utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6673dd-a350-409b-8745-6035e400da7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running input 0\n",
      "running input 200\n",
      "running input 400\n",
      "running input 600\n",
      "running input 800\n",
      "running input 1000\n",
      "running input 1200\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "\n",
    "\n",
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "NUM_SAMPLES = 8 # don't increase this past 1 if you don't know that patching the corrupted prompt values in works\n",
    "NUM_OUTLIERS_TO_KEEP_PER_ITER = 2\n",
    "\n",
    "corrupt_prompts = [prompt.corrupt_prompt['random_answer_doc'] for prompt in prompts[:NUM_SAMPLES]]\n",
    "\n",
    "corrupt_logits, corrupt_cache = model.run_with_cache(corrupt_prompts)\n",
    "corrupt_attention_outputs = [corrupt_cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(num_layers)]\n",
    "corrupt_attention_outputs = torch.stack(corrupt_attention_outputs, dim=1).squeeze(0) # now batch, layer, seq, n_heads, dim_attn (squeezed away the batch dim)\n",
    "old_shape = corrupt_attention_outputs.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "corrupt_attention_outputs = corrupt_attention_outputs.view(new_shape) \n",
    "\n",
    "encoding_idxs = model.tokenizer.batch_encode_plus([prompt.clean_prompt for prompt in prompts], \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device).input_ids\n",
    "# put in only one example for the attention mask, so that it has batch dimension 1, which broadcasts\n",
    "attention_mask = model.tokenizer.encode_plus(prompts[0].clean_prompt, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=512,\n",
    "                                 truncation=True, \n",
    "                                 padding = \"longest\", \n",
    "                                 return_attention_mask=True, \n",
    "                                 return_tensors=\"pt\").to(device).attention_mask\n",
    "# god help us if we want to make HF prepend the BOS token, which this model expects\n",
    "# so do it ourselves manually\n",
    "attention_mask = torch.tensor([[1] + attention_mask.cpu().numpy().tolist()[0]], device=device)\n",
    "# attention_mask = torch.tensor(np.hstack([np.ones((attention_mask.shape[0], 1), dtype=np.int64), encoding_idxs.cpu().numpy()]), device=device)\n",
    "encoding_idxs = torch.tensor(np.hstack([np.ones((encoding_idxs.shape[0], 1), dtype=np.int64), encoding_idxs.cpu().numpy()]), device=device)\n",
    "\n",
    "# encoding_idxs = torch.tensor([[1] + encoding_idxs.cpu().numpy().tolist()[0]], device=device)\n",
    "input_shape = attention_mask.size()\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, \n",
    "                                                        input_shape, \n",
    "                                                        model,\n",
    "                                                        device)\n",
    "\n",
    "# Calculate relevance to logits\n",
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "    ]\n",
    "\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "target_nodes = []\n",
    "\n",
    "# cache activations for faster batch run\n",
    "out_decomp, _, _, pre_layer_activations = prop_toy_model_4l(encoding_idxs[0:NUM_SAMPLES, :], extended_attention_mask, model, [ablation_sets[0]], target_nodes=target_nodes, device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True)\n",
    "# print(len(pre_layer_activations))\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, \\\n",
    "                                                  device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "out_decomps, _ = batch_run(prop_fn, ablation_sets, num_at_time=(64 // NUM_SAMPLES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c469c447-6b79-403d-b7b1-850cb9af6ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=40, attn_head_idx=0),), score=2.1524660885334015)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=40, attn_head_idx=6),), score=1.5224626958370209)\n",
      "Result(ablation_set=(Node(layer_idx=2, sequence_idx=40, attn_head_idx=3),), score=0.10353106632828712)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=12, attn_head_idx=0),), score=0.0046040830202400684)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=12, attn_head_idx=7),), score=0.0038718872820027173)\n",
      "Result(ablation_set=(Node(layer_idx=0, sequence_idx=15, attn_head_idx=5),), score=0.003306705504655838)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=12, attn_head_idx=4),), score=0.0030077453702688217)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=12, attn_head_idx=3),), score=0.0016807264764793217)\n",
      "Result(ablation_set=(Node(layer_idx=1, sequence_idx=21, attn_head_idx=4),), score=0.0008666748180985451)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=0),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=1),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=2),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=3),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=4),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=5),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=6),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=0, attn_head_idx=7),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=1, attn_head_idx=0),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=1, attn_head_idx=1),), score=0.0)\n",
      "Result(ablation_set=(Node(layer_idx=3, sequence_idx=1, attn_head_idx=2),), score=0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results, relevances = compute_logits_decomposition_scores([prompt.clean_prompt for prompt in prompts[0:NUM_SAMPLES]], out_decomps)# text, out_decomps)\n",
    "for result in results[:20]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8926fbc9-c8cf-4fdc-bb73-10e5e2b1fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running input 0\n",
      "running input 200\n",
      "running input 400\n",
      "running input 600\n",
      "running input 800\n",
      "running input 1000\n",
      "running input 1200\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "corrupt_prompts = [prompt.corrupt_prompt['random_answer_doc'] for prompt in prompts[:NUM_SAMPLES]]\n",
    "\n",
    "corrupt_logits, corrupt_cache = model.run_with_cache(corrupt_prompts)\n",
    "corrupt_attention_outputs = [corrupt_cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(num_layers)]\n",
    "corrupt_attention_outputs = torch.stack(corrupt_attention_outputs, dim=1).squeeze(0) # now layer, seq, n_heads, dim_attn (squeezed away the batch dim)\n",
    "old_shape = corrupt_attention_outputs.shape\n",
    "last_dim = old_shape[-2] * old_shape[-1]\n",
    "new_shape = old_shape[:-2] + (last_dim,)\n",
    "corrupt_attention_outputs = corrupt_attention_outputs.view(new_shape)\n",
    "'''\n",
    "target_nodes = [Node(3, 40, 0), Node(3, 40, 6)]\n",
    "    \n",
    "ranges = [\n",
    "        [layer for layer in range(num_layers)],\n",
    "        [sequence_position for sequence_position in range(seq_len)],\n",
    "        [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "    ]\n",
    "source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "ablation_sets = [(n,) for n in source_nodes]\n",
    "prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, \\\n",
    "                                         device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "_, target_decomps = batch_run(prop_fn, ablation_sets, num_at_time=(64 // NUM_SAMPLES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ca7fc49-507f-4f42-9cdb-4773f89d5123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=1, sequence_idx=40, attn_head_idx=4)\n",
      "Node(layer_idx=0, sequence_idx=15, attn_head_idx=5)\n",
      "Node(layer_idx=1, sequence_idx=33, attn_head_idx=4)\n",
      "Node(layer_idx=0, sequence_idx=27, attn_head_idx=5)\n",
      "Node(layer_idx=0, sequence_idx=15, attn_head_idx=0)\n",
      "Node(layer_idx=1, sequence_idx=16, attn_head_idx=0)\n",
      "Node(layer_idx=0, sequence_idx=34, attn_head_idx=5)\n",
      "Node(layer_idx=1, sequence_idx=16, attn_head_idx=4)\n",
      "Node(layer_idx=0, sequence_idx=15, attn_head_idx=1)\n",
      "Node(layer_idx=2, sequence_idx=35, attn_head_idx=3)\n",
      "Node(layer_idx=1, sequence_idx=27, attn_head_idx=2)\n",
      "Node(layer_idx=1, sequence_idx=15, attn_head_idx=0)\n",
      "Node(layer_idx=0, sequence_idx=1, attn_head_idx=0)\n",
      "Node(layer_idx=2, sequence_idx=34, attn_head_idx=2)\n",
      "Node(layer_idx=0, sequence_idx=1, attn_head_idx=1)\n",
      "Node(layer_idx=0, sequence_idx=27, attn_head_idx=0)\n",
      "Node(layer_idx=1, sequence_idx=28, attn_head_idx=4)\n",
      "Node(layer_idx=1, sequence_idx=35, attn_head_idx=4)\n",
      "Node(layer_idx=2, sequence_idx=27, attn_head_idx=2)\n",
      "Node(layer_idx=2, sequence_idx=28, attn_head_idx=3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results, relevances = calculate_target_decomposition_scores(target_decomps, normalized=True)\n",
    "\n",
    "for result in results[:20]:\n",
    "    print(result.ablation_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece14a76-600c-4815-9727-c65f29aaf4db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/georgiasimpression/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running input 0\n",
      "running input 200\n",
      "running input 400\n",
      "running input 600\n",
      "running input 800\n",
      "running input 1000\n",
      "running input 1200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prompt_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m prop_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ablation_list: prop_toy_model_4l(encoding_idxs[\u001b[38;5;241m0\u001b[39m:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes\u001b[38;5;241m=\u001b[39mtarget_nodes, \\\n\u001b[1;32m     64\u001b[0m                                                   device\u001b[38;5;241m=\u001b[39mdevice, mean_acts\u001b[38;5;241m=\u001b[39mcorrupt_attention_outputs, set_irrel_to_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cached_pre_layer_acts\u001b[38;5;241m=\u001b[39mpre_layer_activations)\n\u001b[1;32m     65\u001b[0m out_decomps, _ \u001b[38;5;241m=\u001b[39m batch_run(prop_fn, ablation_sets, num_at_time\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m NUM_SAMPLES))\n\u001b[0;32m---> 66\u001b[0m results \u001b[38;5;241m=\u001b[39m compute_logits_decomposition_scores(prompts[\u001b[43mprompt_idx\u001b[49m]\u001b[38;5;241m.\u001b[39mclean_prompt, out_decomps)\u001b[38;5;66;03m# text, out_decomps)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Now, find maximally relevant source nodes to target nodes\u001b[39;00m\n\u001b[1;32m     69\u001b[0m outliers_per_iter \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt_idx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, find maximally relevant source nodes to target nodes\n",
    "\n",
    "outliers_per_iter = []\n",
    "while True:\n",
    "    outliers = results[:NUM_OUTLIERS_TO_KEEP_PER_ITER]\n",
    "    outliers_per_iter.append(outliers)\n",
    "    target_nodes = [r.ablation_set[0] for r in outliers]\n",
    "    print(target_nodes)\n",
    "    should_break = True\n",
    "    for node in target_nodes:\n",
    "        if node.layer_idx != 0:\n",
    "            should_break = False\n",
    "    if should_break:\n",
    "        break\n",
    "    \n",
    "    ranges = [\n",
    "            [layer for layer in range(num_layers)],\n",
    "            [sequence_position for sequence_position in range(seq_len)],\n",
    "            # [ioi_dataset.word_idx['IO'][0]],\n",
    "            [attention_head_idx for attention_head_idx in range(num_attention_heads)]\n",
    "        ]\n",
    "    source_nodes = [Node(*x) for x in itertools.product(*ranges)]\n",
    "    ablation_sets = [(n,) for n in source_nodes]\n",
    "    prop_fn = lambda ablation_list: prop_toy_model_4l(encoding_idxs[0:NUM_SAMPLES, :], extended_attention_mask, model, ablation_list, target_nodes=target_nodes, \\\n",
    "                                             device=device, mean_acts=corrupt_attention_outputs, set_irrel_to_mean=True, cached_pre_layer_acts=pre_layer_activations)\n",
    "    _, target_decomps = batch_run(prop_fn, ablation_sets, num_at_time=(64 // NUM_SAMPLES))\n",
    "    \n",
    "    results, relevances = calculate_target_decomposition_scores(target_decomps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dcbc887-b4b6-40f1-a553-11e1d48e0452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(layer_idx=3, sequence_idx=40, attn_head_idx=0)\n",
      "Node(layer_idx=3, sequence_idx=40, attn_head_idx=6)\n",
      "Node(layer_idx=0, sequence_idx=15, attn_head_idx=5)\n",
      "Node(layer_idx=0, sequence_idx=34, attn_head_idx=5)\n"
     ]
    }
   ],
   "source": [
    "all_nodes = []\n",
    "for it in outliers_per_iter:\n",
    "    for result in it:\n",
    "        if result.ablation_set[0] not in all_nodes:\n",
    "            all_nodes.append(result.ablation_set[0])\n",
    "for node in all_nodes:\n",
    "    print((node))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c884b-e249-4960-b456-e15b8d18e422",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Circuit evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d050e1d-2f9b-44d6-ab35-492c71f67923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 41, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "print(corrupt_attention_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "021575d4-caaf-4c6c-8596-c33a79511320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def correctness_rate(model, prompts, patch_values=None):\n",
    "    correct = 0\n",
    "    for idx, prompt in enumerate(prompts):\n",
    "        if patch_values is not None:\n",
    "            model.reset_hooks(including_permanent=True)\n",
    "            model = add_mean_ablation_hook(model, patch_values=patch_values[:, idx, :, :, :], circuit=circuit)\n",
    "        tokens = model.to_str_tokens(prompt)\n",
    "        print(tokens)\n",
    "        # it's perhaps better to check if the model's prediction logit is highest by a certain threshold.\n",
    "        correct_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "        model_prediction = model.to_string(model.generate(prompt, max_new_tokens=1, do_sample=False, return_type='tensor')[0][-1])\n",
    "        if model_prediction == correct_answer:\n",
    "            correct += 1\n",
    "    return correct / len(prompts)\n",
    "'''\n",
    "def correctness_rate(logits, test_dataset):\n",
    "    total = 0\n",
    "    # text = test_dataset[i]\n",
    "    tokens = model.to_str_tokens(test_dataset) # NOT to_tokens(text)\n",
    "    correct_logits = np.array([model.to_single_token(tokens[i][pos_labels.index(\"C_def\")]) for i in range(len(test_dataset))])\n",
    "    # correct_logits = logits[list(range(len(test_dataset))), -1, correct_logit_idxs]\n",
    "    predicted_logits = np.argmax(logits.cpu().numpy()[:, -1, :], axis=-1)\n",
    "    return np.sum(correct_logits == predicted_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef8e896-a1f6-44b8-9d58-98c6bdba7cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logits_to_ave_logit_diff(logits, test_dataset):\n",
    "    total = 0\n",
    "    for i in range(len(test_dataset)):\n",
    "        text = test_dataset[i]\n",
    "        tokens = model.to_str_tokens(text) # NOT to_tokens(text)\n",
    "        correct_logit_idx = model.to_single_token(tokens[pos_labels.index(\"C_def\")])\n",
    "        rel_correct_logit = logits[i, -1, correct_logit_idx]\n",
    "        incorrect_seq_idxs = [pos_labels.index(\"A_def\"), pos_labels.index(\"B_def\"),\n",
    "                         pos_labels.index(\"rand0\"),\n",
    "                         pos_labels.index(\"rand1\"),\n",
    "                         pos_labels.index(\"rand2\"),\n",
    "                         pos_labels.index(\"rand3\"),\n",
    "                         pos_labels.index(\"rand4\"),\n",
    "                         pos_labels.index(\"rand5\"),\n",
    "                         pos_labels.index(\"rand6\"),\n",
    "                         pos_labels.index(\"rand7\"),\n",
    "                         pos_labels.index(\"rand8\"),\n",
    "                         pos_labels.index(\"rand9\"),\n",
    "                         pos_labels.index(\"rand10\"),\n",
    "                         ]\n",
    "        incorrect_logit_idxs = [model.to_single_token(tokens[idx]) for idx in incorrect_seq_idxs]\n",
    "        rel_incorrect_logits = logits[0, -1, incorrect_logit_idxs]\n",
    "        total += np.min(rel_correct_logit - rel_incorrect_logits)\n",
    "    avg = total / len(test_dataset)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c5d1e68b-5ebc-4059-82d8-6f7ad2d07371",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a15ec1d4d8642b897d0b436297ef8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33303bbdb2954014aa2596b054a34ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe1d006fc7f4616ab2e95382273c81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a54fbcce4934322b24aed88cec977cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4458d79f63574e2d9c7030c89576dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadfdb8acd9741bd8af88651bc35e7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd7aae208d4408183e7b0bea4c7e791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfcbc4b202847888267d04370f4558e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a777f84b9394b618745b816e04b7560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9aaf3f6b7b43dea5ffe1c8eeefe2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95406d81ac884c1e92af6452900e8ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0a65533fcd4fe0af18dcf656789991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615a8250c73e425da4b1a5b0b3b246b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d02ba36c6e248f88a72d9ddc78f3540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d62d7105bf4d54b551de954a9fa6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0b6881c5204754b19a75d42b998809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9cf613adad4db3a9b0fbc7ed0a8df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8f0581afe64b0f8c9b3105a8d58d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992ddc88f9dd4b7aa1c9426b2c7bae26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e326f9744494cffa6c2f3866e5dc96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816845ad3aac4c3a85c0b98343d96ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24f645a27b849ddb4f63a9ec93c706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcfd8ba9ea94e4b88a632aa842c104c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f622a21ee85469cabc180ecec14bc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7aea61f0bc4d4e823897ca6d808d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8e82912a1f4202b8acd7c332a823a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f551d9a7e3c5405dae55a04ee3da2956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1097bde62814dd5963e2e5049eea91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d3c8126df436582f16a0f2c26f7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6aef7bf0ca549289c8876e5e376ce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0da7ffc6c64194b3b6a34f6241f19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968eb6960a248809f91dd6b8c6ac848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f5bc37a48146b3bbe7ce64f5b15e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d2d58c5d014da293b041b967ed64f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce9bdfc889c4277affa77b8d64d5675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667370c8d384409e8b77b1a902bfcdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d12d747fc724bbc89bf92b54c2b1744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984e2c0e923e4b109bf91797ebb41e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d48adecb1b4982a91228e92c3df1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f51be5ca9d64c148e0f037b2a56e0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30aa196984cb44e695c24a27cab942ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cf14927b594e8ba01cee22e3d7a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519b87f4070e4f55a6b0b3cb3addbdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd41ad62561040eeb2201157ed53a15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6900bb71df884a279f37e20b3751befe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0801d02a3e54747a2e4b9065073b6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53581c38caea4c79822944fa8bc65cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82c1f31bf644cb4ade521e7b09a6ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1ef23899374a609f212a6f579616cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0795c77c439049919a2d166c16284b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e841214bba848e5b7d357a3f87713b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6b7d96d85440168481bb86f374983f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c441c09096a549e292ca6fc43c7223d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84e1c8227ee4341be867558cce335f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ced6a95d5f440081a03292fa4f24ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326c5f7f8c4244208216fd0883d583f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eb6f7b296d430bafa33bb82147f49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924da770324646b38a86b6496c46eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e469ae46bd7494d9bf11f175d8049b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bdca1ddbe94176a1627851d9d9ff29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae98b9f61304cb492583202b9425e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3373aa360b5641e7a812ffeaa638c10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434975adae424f1db6b7139a53de0863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc611e967d476eb8ba093a21a61ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376489e4a42a41c2bb9ada57587b7290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0e834bea6548f18907a348675dcd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6779866feb054510abcc278f6fd61c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fad866459b4a78886eada24175dcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc446b834bf4025b0215d3e2483970f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9ed82e8ed84558915a52b88ac52c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57be9b3530d4e0a90c1912e4bc5b5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf99d3606584a3f826a09543099dd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cf36ef185f4bca8766c219ba14d76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20ebe2797ae405487e5d2c0a207478e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688f9373cc434c889b25aa15aba7ad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c2005e41374d1799f2ef7d515303f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177637f55194456d8c58628cc2e9bf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8565882d9ecf4fe9b00de40811e44de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0896501495384860a4eb3cfd895254cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2800100935f7474fb17043edef9dad97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f789ccc63a14e10a3290ba627cdfffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f255df7344341dea8f9310075001169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd18a48746b488eb5df4bae4e700632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7c59296bd34af5902321ab4b6b7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a04375ad32a4ac6b1dd4c4cd4ec03b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bbcba3ce9f4d39b17bb93586ba2f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd6cd3a6cdf425b9666ebdc76f40706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8912a27fc544e9959611c8bb4460e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdfd28f82904a479d4b44af50660cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f130a8d25ed4fec8ff0cf54d24d9c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb063636af54abf844c431d146f7891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06def1b7c6f24cdab593cb275977d773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eb5ff67b854783a1f7563e660b4be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccd4a6f28a04481b0b0eff2ec745ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6db49650e74044a1f0b7b1b309e43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45331d78fbdb48c69927fd1bf60acfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa05edf0f4554ccab851d8edaa46a5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5533952f770f444dbb74fd7da8d8956d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f160f140dc3d4dbb931023c768fdcd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693bc0a0cad8439289809a37ef01015a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6435c5530ed24e2c8f9a7e674c2b5bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a24ad7390b4f6e81ecfca8bde5ed9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2d7501e6064f4284187a5241e8c129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4249ce45a408eac9e6f3d2959754c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa32f6cfe6e49f298acec5416052b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfee9dfb6cbc4b3890aa869faf79ff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e903060521e942908599d6032ec3e111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5471ef8f734648ee9aee57e346ca0906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad9e22a3d1491f8846673b16cc979d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce66e2e6e66a42e3ac32e5b10af5bd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e21bf023e544a998866e39b63c3103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eceafdc88fa4e2893509e2b01ea2626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74680678de8543b5a23fafdc66cec788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3379e44a85834ee1866697bdc535b274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a68c49aabb4d6e9f1cf61cc2fbb50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4500ca25751240fcacff4045c0d47f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0b4bb5dd49421baf271d097fc2c656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce63fe27b5e34531859d8df7f1e092fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84f412df3814e9aa84715f9e18d6d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dab17d8c0946df94b56f0613676b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1d2e1a23b54a0a8ed9ae66af68f8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93291af5edb74874972ebe2b63149c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93545951b97e4956ba80bc58dfe6c8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f01537c11f4ea9bdb419a709d6f5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15310d1f7ef44a9b8f01775c0359a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1689f2e5dfe040b3afcdda4771c778d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bd5e8031114655bf289cd8c5a4d910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134573a872c949908d04cd45a96a924e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3961e5a639d472b9e69a8d0410aaa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ea1c53f10941c88dcd3903be3ab5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1eaeefb27b94543816ce99a219a2233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9a28d88bfd49a6bf4885792b9f8e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bb7034c4dd4f8ab86f57ed09dd6954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c695c8a63845bc985ce49f58478353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b0ca58fbfd44f7908a3b1aa10ce8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6a1fff4fc3449aaa10749f7993961b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb63423c4e204b0285ee571737053fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72467891a809489088ae6f920009780f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e1da3e050e4ead84d4ca7b6d49c1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb4b109f06648e6b3a8fe66cfd82c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bde1b9e0094c78ac5432ca160f76d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de91550e121f41a18ce5dfe237f4d0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5a5de0eb2845859dea739c8c58d061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6487a60383459c8316a06a5052f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d06cf884974ae29f469a450c1c004a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8ff478465e4b8e87045305eaea6acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8b526d9d834bcd85e8b9d06aea0922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c938471fd764262ba119088f877f11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c728690a0424335a69312231aa82b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24c182144f341bfa711825fbebad0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28d3b9e3483404faf2ec68469480bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a767f86cefe4a9fb24fa7e70bd0c223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f18c6d3904d4d5ab79ce3c20ae08db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c426fcd01f57464c8b9eb2db7ab705bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d99a189df641e6af43e377eea36caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455be55f471b4fdcba0e294f59ca74ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0a6d0190c4045b713b40d98dec778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8308612edca5474a9d130cbf8b3133b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87acbd40939d45709c413f4502c31f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10089d7fab5431eb0f7e4b30917bcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd16f75520241b8b2a484c498b08a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e5f145123b4d42874f22873a125906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff340a10a714cecb4899f75f38ab308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777a6331df184b9bb5b0722240c1d6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b43983acec4b8299e36f0b116ef4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a58af661cc47e68f0205a8777c0092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b857b5a7df4ee4abf333bfbdf9c189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42a854871fe430892f173df13aa32d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39702c6911d4c5c89e2c21117c543df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e5d6d2e5764337a0125ca59eab198f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3382cd892bd54192a93c16e8081748cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4d27dde5544b7987247d7e62623207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5140640f7194f56b8524951ad220bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5caf7ecf231646118b2c6b70937e9950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb392ee0e614260ad4b08d40e522739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc577407b2764aab9bb2be6aa4d479b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab272a3b85041c89a77f586770f9fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43174ba2a66543cbabf412cb5f82951d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f26a9bf3b614b28b48de43f382e419b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c19673b9f2419d8cb1f64e6005f609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc472fe142e4d03abd690b4abc63a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b817e5227a4245953bcb4c5f78409f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bc63f14b6c487fbd6dc9f294444308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006fc4a6ab124070b48d644fc5bf6c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9d69bbd618483ea86f9993ffa3badb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30d0786fa54457d9d8dd88769c9622d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb0be86e764a4b9d79488daa909634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f55cacbc404a4db269182554f00d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536783bccaf1457ca96e68c475e6c1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4096f1bb12394736a0fca2d1fa497fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660feed0ea124e75970f11ccdb321b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e92c2ec07f42d193dc85f9926a3bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356dfb592d6b496abe00ca6fd7452387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaabe181e534aed8ed54b272ed28d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fb5ff8a49e4b48932684d2e7a0c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d1b0d585fa42709fbb96b484b64c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92787f6711684e0fb67244aafc8b8058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bb3036191b459f8f4a0a45b774452b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73cb2af1314429ca3bed6f3247a6749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce862aa215dd4bdfb71d7ce20b36bb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "docstring_ind_prompt_kwargs = dict(\n",
    "    n_matching_args=3,\n",
    "    n_def_prefix_args=2,\n",
    "    n_def_suffix_args=1,\n",
    "    n_doc_prefix_args=0,\n",
    "    met_desc_len=3,\n",
    "    arg_desc_len=2\n",
    ")\n",
    "prompts = [docstring_ind_prompt_gen(\"rest\", **docstring_ind_prompt_kwargs) for _ in range(batch_size)]\n",
    "# Get a \"better\" dataset, i.e, ones where the model answers the correct answer, preferably by a wide margin.\n",
    "# the toy model actually isn't very good at the docstring task, only getting it right like 50-75% of the time.\n",
    "# We obviously can't investigate the question of how the model does the docstring task if it's not actually \"doing\" it.\n",
    "good_prompts = []\n",
    "for prompt in prompts:\n",
    "    clean_prompt = prompt.clean_prompt\n",
    "    tokens = model.to_str_tokens(clean_prompt)\n",
    "    # it's perhaps better to check if the model's prediction logit is highest by a certain threshold.\n",
    "    correct_answer = tokens[pos_labels.index(\"C_def\")]\n",
    "    model_prediction = model.to_string(model.generate(clean_prompt, max_new_tokens=1, do_sample=False, return_type='tensor')[0][-1])\n",
    "    if model_prediction == correct_answer:\n",
    "        good_prompts.append(prompt)\n",
    "prompts = good_prompts\n",
    "print(len(prompts))\n",
    "\n",
    "\n",
    "TEST_DATASET_SIZE = 100\n",
    "test_dataset = [prompt.clean_prompt for prompt in prompts[:TEST_DATASET_SIZE:]]\n",
    "\n",
    "corrupt_prompts = [prompt.corrupt_prompt['random_answer_doc'] for prompt in prompts[:TEST_DATASET_SIZE]]\n",
    "\n",
    "corrupt_logits, corrupt_cache = model.run_with_cache(corrupt_prompts)\n",
    "corrupt_attention_outputs = [corrupt_cache['blocks.' + str(i) + '.attn.hook_z'] for i in range(num_layers)]\n",
    "corrupt_attention_outputs = torch.stack(corrupt_attention_outputs, dim=0) # now batch, layer, seq_ nheads, dim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "02616386-75e3-4761-a351-a1fa3f03819a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.661138000488281\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks(including_permanent=True)\n",
    "logits, cache = model.run_with_cache(test_dataset) # full model performance\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71d4931c-164f-4e4c-a6d9-ec4301dc0e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8475144004821777\n",
      "[ 2160  5575  7538 10207  1802  2063  3476  4090   931  7538  3637  3637\n",
      "  1360  4466   931  6161  1802  2347  3407   845  3195  4759  2063  1361\n",
      "  8464  4298  8464  4059  4059  3159  3585  1615   801  1615 14046  2374\n",
      "  3407 19151   922  9433  6692  3469   898  3476  2160   745  5575 21435\n",
      "  3808  1364  6627  3340  4522  9433  2796  2525  3469  3808   980  4360\n",
      "  1242  5076  3485  1631  1631  6161  2181 19151  2176  2426   931  3514\n",
      "  1294  2181  2520  4622  1242 21435  3064  2787 10644  5811  3797  2426\n",
      "   745  2520  3656   980  2288  2127   845  1142 10207  1819  6161 21435\n",
      " 10391  4522  6161  3808]\n",
      "[ 1802  1615  7538  2306  1802  3407  4059  4090   931  7538  3637  3637\n",
      "  1142  5224   931  6161  1390  4059    28   845  2374 13729  1802  2741\n",
      "  1390  4298   539  4059  4059  3476  1242  5076  1364  1615  9433  2374\n",
      "   898 19151   922  9433  6692  1294 10391  3476  1530   745  5575  1819\n",
      "  3808  1195  6627  1390  7108  1390  3485  3808  3469  5127   980  2426\n",
      "  1242   980  3485  2525  1195  1802  2517  3808  2176  2382  5224  7538\n",
      "  1294  4059  2520  4622  1242 21435  3064  2787  2787  5127  3797  2426\n",
      "   745  2520  1359   980  2288  1802   845  5575  7336  1819  2176  7108\n",
      " 10391  5575  3159  3808]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "circuit = [Node(layer_idx=3, sequence_idx=40, attn_head_idx=0),\n",
    "          Node(layer_idx=3, sequence_idx=40, attn_head_idx=6),\n",
    "           Node(layer_idx=1, sequence_idx=40, attn_head_idx=4),\n",
    "        # Node(layer_idx=0, sequence_idx=15, attn_head_idx=5),\n",
    "        # Node(layer_idx=1, sequence_idx=33, attn_head_idx=4),\n",
    "        # Node(layer_idx=0, sequence_idx=27, attn_head_idx=5),\n",
    "        # Node(layer_idx=0, sequence_idx=15, attn_head_idx=0),\n",
    "        # Node(layer_idx=1, sequence_idx=16, attn_head_idx=0),\n",
    "        Node(layer_idx=0, sequence_idx=34, attn_head_idx=5),\n",
    "        # Node(layer_idx=1, sequence_idx=16, attn_head_idx=4),\n",
    "        # Node(layer_idx=0, sequence_idx=15, attn_head_idx=1),\n",
    "        # Node(layer_idx=2, sequence_idx=35, attn_head_idx=3),\n",
    "        # Node(layer_idx=1, sequence_idx=27, attn_head_idx=2),\n",
    "        # Node(layer_idx=1, sequence_idx=15, attn_head_idx=0),\n",
    "        # Node(layer_idx=0, sequence_idx=1, attn_head_idx=0),\n",
    "        # Node(layer_idx=2, sequence_idx=34, attn_head_idx=2),\n",
    "        # Node(layer_idx=0, sequence_idx=1, attn_head_idx=1),\n",
    "        # Node(layer_idx=0, sequence_idx=27, attn_head_idx=0),\n",
    "        # Node(layer_idx=1, sequence_idx=28, attn_head_idx=4),\n",
    "          ]\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=circuit)\n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))\n",
    "# (3, 0), (3, 6), (1, 4), (0, 5), (0, 0), (1, 0), (1, 4), (0, 1), (2, 3), (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "789e0898-5353-4ee3-81b9-916b98fa5f11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0950055742263793\n",
      "[ 4145  2796  3476  1802  1218  3485  4522  1142  1218  1615  3485  2181\n",
      "  7336  7123  2629  4522  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176 13729 14046 21435  1802  1052  3929  2662  2232  1382 10391\n",
      "  2530  5811   922  5566  1668  2160  7538 10391  9433  2347  3929  2382\n",
      "  1921  1056  1361  1360  4090   980  1359  3485  1631  3476  2525  3195\n",
      "   980  3797 10644 10391  8464  5575  3064   980  4522  2426  3135  1802\n",
      "  1056  1056   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5224  7538  1359  1360  2336  1921 21435  6627  1052  4686\n",
      "  3797  2530  2063  1350]\n",
      "[ 4686  5566  1056  6627  1390  1359  4622  1056   743  1819  3476  2629\n",
      "  4522  4059  1294  1056  1390  7336  7108  4059  3407  3476  2232  4090\n",
      "  1056  2426  2181  1359  4622  1242  4059  3135  1819  4622  4622  1819\n",
      "  2306  1819 10207  2426  2165  6692  5575  2520  4466  6161  2176  2525\n",
      "  2517  2525  2741  1819  2530  2165  2741  2374  4466   931  2787  1390\n",
      "  7108  3929  4090  2288  2232  6627 10391  1390  5050 14046   898  1294\n",
      " 10644  1242  1390  3195  1056  7123  1390  4059  1382  3407  3407  3797\n",
      "  2165  1142  4059  3469  7538  3195 13729  1382  3476  6692  2176  2306\n",
      "  3476  4466  1530 10207]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "random_circuit = random.sample(source_nodes, 20)\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=random_circuit) # baseline \n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dafc78-3554-45f9-bfb7-36938310a34f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Not including sequence positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8220bfd0-0a61-469e-8b83-cf2b87803fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.235892753601074\n",
      "[ 4145  2796  3476  1802  1218  3485  4522  1142  1218  1615  3485  2181\n",
      "  7336  7123  2629  4522  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176 13729 14046 21435  1802  1052  3929  2662  2232  1382 10391\n",
      "  2530  5811   922  5566  1668  2160  7538 10391  9433  2347  3929  2382\n",
      "  1921  1056  1361  1360  4090   980  1359  3485  1631  3476  2525  3195\n",
      "   980  3797 10644 10391  8464  5575  3064   980  4522  2426  3135  1802\n",
      "  1056  1056   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5224  7538  1359  1360  2336  1921 21435  6627  1052  4686\n",
      "  3797  2530  2063  1350]\n",
      "[ 4145  5566  3476  1802  1218  2520  4622  1218  1316  1615  4622 19151\n",
      "  4522  7123  2629  2160  2347   931  1921  4522  2306   922  2629  5076\n",
      "  4622  2063  3929  4522 10207  1802  1052  1819  2662  4622  1382 10391\n",
      "  3808  1819   922  2426  1668  2160  5575  2426  4466   931  1819  2382\n",
      "  1921  2741  6692  1360  4090  7123  1359  3485  1631  3476  5811  1390\n",
      "   980  3476 10644 10391  8464  5575  3064   980  4522  2160  3135  1802\n",
      " 10644  3808   931   922  9433  2426  1390  2288  1382  5811  1819  4686\n",
      " 10644  1631  5224  1359  1359  1360  2336  1921 21435  6627  1052  4686\n",
      " 14046  1360  2063  1350]\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "circuit = []\n",
    "for (layer_idx, head_idx) in [(3, 0), (3, 6), (1, 4), (0, 5), (0, 0), (1, 0), (1, 4), (0, 1), (2, 3), (1, 2)]: # this is our finding\n",
    "    for seq_pos in range(seq_len):\n",
    "        circuit.append(Node(layer_idx, seq_pos, head_idx))\n",
    "        model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=circuit)\n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1257c8ca-7bd5-4e7e-baa3-3f8abfaed2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.884234743118286\n",
      "[ 4145  2796  3476  1802  1218  3485  4522  1142  1218  1615  3485  2181\n",
      "  7336  7123  2629  4522  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176 13729 14046 21435  1802  1052  3929  2662  2232  1382 10391\n",
      "  2530  5811   922  5566  1668  2160  7538 10391  9433  2347  3929  2382\n",
      "  1921  1056  1361  1360  4090   980  1359  3485  1631  3476  2525  3195\n",
      "   980  3797 10644 10391  8464  5575  3064   980  4522  2426  3135  1802\n",
      "  1056  1056   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5224  7538  1359  1360  2336  1921 21435  6627  1052  4686\n",
      "  3797  2530  2063  1350]\n",
      "[ 4145  5566  3476  1802  1390  3485  4622  1218   743  1615  3485 19151\n",
      "  4522  3585  2629  2160  2530   931  1921  4522  2306   922  5575  5076\n",
      "  4622  2063  3929  1242  4622  1802  1052  1819  1819  2232  1382 10391\n",
      "  3808  2796   922   818  1668  1615  7538  2520  9433 14842  3929  2382\n",
      "  1921  2525  6692  1819  4090  7123  1359  3485  1294   931  2525  1390\n",
      "   980  3929 10644  5566  8464  5575  3064   980  3637  2160  3135  1802\n",
      " 10644  1056   931   922  3929  2426  1390  2741  3808  3407  1819 21435\n",
      "  1819  5811  5127  7538  7538  1360  2336  1921 21435  6627  2176  4686\n",
      "  9433  1360  2063  1350]\n",
      "54\n",
      "2.960804023742676\n",
      "[ 4145  2796  3476  1802  1218  3485  4522  1142  1218  1615  3485  2181\n",
      "  7336  7123  2629  4522  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176 13729 14046 21435  1802  1052  3929  2662  2232  1382 10391\n",
      "  2530  5811   922  5566  1668  2160  7538 10391  9433  2347  3929  2382\n",
      "  1921  1056  1361  1360  4090   980  1359  3485  1631  3476  2525  3195\n",
      "   980  3797 10644 10391  8464  5575  3064   980  4522  2426  3135  1802\n",
      "  1056  1056   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5224  7538  1359  1360  2336  1921 21435  6627  1052  4686\n",
      "  3797  2530  2063  1350]\n",
      "[ 4145  5566  3476  1802  1390  3485  4622  1056   743  1615  3485 19151\n",
      "  4522  3585  2629  2160  2530   931  1921  4522  2306   922  5575  5076\n",
      "  3808  2063  3929  1242  4622  1802  1052  1819  1819  4622  1382 10391\n",
      "  3808  2796   922   818  2382  1615  7538  2520  9433 14842  3929  2382\n",
      "  1921  2525  2741  1360  4090  7123  1359  3485  1294   931  2525  1390\n",
      "   980  3929 10644  2382  8464  5575  3064   980  3637  2160  3135  1802\n",
      " 10644  1056   931   922  3929  2426  2306  2741  3808  2787  1819 12702\n",
      "  1819  5811  5127  1359  1294  1360  2336  1921 21435  6627  2176  1530\n",
      "  9433  1360  2063  1350]\n",
      "52\n",
      "3.5241334438323975\n",
      "[ 4145  2796  3476  1802  1218  3485  4522  1142  1218  1615  3485  2181\n",
      "  7336  7123  2629  4522  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176 13729 14046 21435  1802  1052  3929  2662  2232  1382 10391\n",
      "  2530  5811   922  5566  1668  2160  7538 10391  9433  2347  3929  2382\n",
      "  1921  1056  1361  1360  4090   980  1359  3485  1631  3476  2525  3195\n",
      "   980  3797 10644 10391  8464  5575  3064   980  4522  2426  3135  1802\n",
      "  1056  1056   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5224  7538  1359  1360  2336  1921 21435  6627  1052  4686\n",
      "  3797  2530  2063  1350]\n",
      "[ 4145  5566  3476  1802  1218  3485  4622  1056  2374  1615  4622 19151\n",
      "  4522  7123  2629  2160  2347   931  1921  4522  3637   922  3797  5076\n",
      "  3808  2176  3929 14046  4622  1802  1052  1819  2662  2232  1382 10391\n",
      "  3808  1819   922   818  1668  1615  7538  2426  9433 14842  3929  2382\n",
      "  1921  2525  2741  1360  4090  7123  1359  3485  1631  3476  5811  1390\n",
      "   980  3929 10644  2382  8464  5575  3064   980  3637  2160   898  1802\n",
      " 10644  3808   931   922  3929  2426  2306  2288  3808  5811  1819 21435\n",
      " 10644  5811  5127  7538  1359  1360  2336  1921 21435  6627  2176  1530\n",
      "  3476  1360  2063  1350]\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0.0 and 2.2 are negative in impact\n",
    "# docstring project result\n",
    "circuit = []\n",
    "for (layer_idx, head_idx) in [(0, 2), (0, 4), (0, 5), (1, 2), (1, 4), (2, 0), (3, 0), (3, 6)]: \n",
    "    for seq_pos in range(seq_len):\n",
    "        circuit.append(Node(layer_idx, seq_pos, head_idx))\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=circuit)\n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))\n",
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "\n",
    "# docstring project + \n",
    "circuit = []\n",
    "\n",
    "for (layer_idx, head_idx) in [(0, 2), (0, 4), (0, 5), (1, 2), (1, 4), (2, 0), (3, 0), (3, 6), (1, 0)]:\n",
    "    for seq_pos in range(seq_len):\n",
    "        circuit.append(Node(layer_idx, seq_pos, head_idx))\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=circuit)\n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))\n",
    "model.reset_hooks(including_permanent=True)\n",
    "\n",
    "# docstring project ++ \n",
    "circuit = []\n",
    "\n",
    "for (layer_idx, head_idx) in [(0, 2), (0, 4), (0, 5), (1, 2), (1, 4), (2, 0), (3, 0), (3, 6), (1, 0), (0, 1), (2, 3)]:\n",
    "    for seq_pos in range(seq_len):\n",
    "        circuit.append(Node(layer_idx, seq_pos, head_idx))\n",
    "model.reset_hooks(including_permanent=True)\n",
    "model = add_mean_ablation_hook(model, patch_values=corrupt_attention_outputs, circuit=circuit)\n",
    "logits, cache = model.run_with_cache(test_dataset) # run on entire dataset along batch dimension\n",
    "ave_logit_diff = logits_to_ave_logit_diff(logits.cpu().numpy(), test_dataset)\n",
    "model.reset_hooks(including_permanent=True)\n",
    "print(ave_logit_diff)\n",
    "print(correctness_rate(logits, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70bad1d8-9349-4748-b4ee-a1d68b51e49c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nArg movers: 3.0, 3.6 at last position (40)\\nInduction: 1.4 at last position (40)\\nPrev token: 0.2 at B_doc, or the one after? (34) or (35) # can't be found by patching, maybe can be found here\\nPrev token: 2.0 at C_def (15)\\nPrev token: 1.4 at the fourth comma?? (14)\\n\\nAlso 0.5 at B_def (13), C_def (15) and B_doc (34), (0.4 relevant to 1.4), 1.2.\\nAlso 2.3, 0.5, 1.2, 0.0, 0.1, 2.2, in roughly that order.\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "'''\n",
    "Docstring post's analysis:\n",
    "Arg movers: 3.0, 3.6 at last position (40)\n",
    "Induction: 1.4 at last position (40)\n",
    "Prev token: 0.2 at B_doc, or the one after? (34) or (35) # can't be found by patching, maybe can be found here\n",
    "Prev token: 2.0 at C_def (15)\n",
    "Prev token: 1.4 at the fourth comma?? (14)\n",
    "\n",
    "Also 0.5 at B_def (13), C_def (15) and B_doc (34), (0.4 relevant to 1.4), 1.2.\n",
    "Also 2.3, 0.5, 1.2, 0.0, 0.1, 2.2, in roughly that order.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
