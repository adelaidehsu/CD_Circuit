{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d50c0c",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook just contains a bunch of cells that I used to explore the model and some alternatives. \n",
    "It is mostly not directly useful to producing the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61a0720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a120102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# CD-T Imports\n",
    "import math\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson, combine_token_attn, compute_word_intervals\n",
    "from pyfunctions.pathology import extract_synoptic, fixLabelProstateGleason, fixProstateLabels, fixLabel, exclude_labels\n",
    "from pyfunctions.cdt_basic import *\n",
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d6ada4-4781-4789-b3b1-1d044c11b3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x77db4975eab0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651660-7f59-4b59-a574-afecc52dc306",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load Model\n",
    "\n",
    "Note: Unlike with the BERT model + medical dataset objective, it is not necessary to pretrain GPT-2 to perform the IOI dataset.\n",
    "GPT-2-small is already capable of performing IOI; that's part of the point of the Mech Interp in the Wild paper.\n",
    "We only need to examine how it does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3183be1-3bf6-4f5a-8134-9bdd83db0a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4838142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820d21e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d912fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer',\n",
       "              GPT2Model(\n",
       "                (wte): Embedding(50257, 768)\n",
       "                (wpe): Embedding(1024, 768)\n",
       "                (drop): Dropout(p=0.1, inplace=False)\n",
       "                (h): ModuleList(\n",
       "                  (0-11): 12 x GPT2Block(\n",
       "                    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attn): GPT2SdpaAttention(\n",
       "                      (c_attn): Conv1D()\n",
       "                      (c_proj): Conv1D()\n",
       "                      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "                      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (mlp): GPT2MLP(\n",
       "                      (c_fc): Conv1D()\n",
       "                      (c_proj): Conv1D()\n",
       "                      (act): NewGELUActivation()\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )),\n",
       "             ('lm_head',\n",
       "              Linear(in_features=768, out_features=50257, bias=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5069ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3041, 5372,  502,  416,  597, 2420,  345, 1549,  588,   13,  198,  198,\n",
      "           40, 1101,  407, 1654,  611,  345,  821, 3910]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgiazhou/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Replace me by any text you'd like.\\n\\nI'm not sure if you're aware\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Replace me by any text you'd\"\n",
    "input = tokenizer(text, return_tensors='pt').input_ids\n",
    "# print(encoded_input) # has 'input_idx' and 'attention_mask'\n",
    "# output = model(input)\n",
    "# print(output.last_hidden_state.shape)\n",
    "gen_tokens = model.generate(input, pad_token_id=tokenizer.pad_token_id, output_scores=True)\n",
    "print(gen_tokens)\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712c94e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# other exploratory stuff\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model.to_tokens(text) #turns out this is a utility of trasnformer_lens\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(output.past_key_values[0][0].shape) # this has to do with key matrix stuff\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(output.values())\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m output\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "# other exploratory stuff\n",
    "# model.to_tokens(text) #turns out this is a utility of trasnformer_lens\n",
    "# print(output.past_key_values[0][0].shape) # this has to do with key matrix stuff\n",
    "#print(output.values())\n",
    "#output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b375528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m320.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (0.24.1)\n",
      "Requirement already satisfied: packaging in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl (392 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.4/392.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl (27.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, tqdm, requests, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.5.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-17.0.0 pyarrow-hotfix-0.6 requests-2.32.3 tqdm-4.66.4 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08241bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 3.46k/3.46k [00:00<00:00, 10.5MB/s]\n",
      "Downloading data: 100%|██████████| 5.84M/5.84M [00:01<00:00, 4.59MB/s]\n",
      "Downloading data: 100%|██████████| 756M/756M [01:27<00:00, 8.65MB/s] \n",
      "Generating train split: 100%|██████████| 26210000/26210000 [00:03<00:00, 7827513.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ioi_dataset = load_dataset(\"fahamu/ioi\")\n",
    "# i've decided against using this for the most part; it's better to use the raw IOIDataset \n",
    "# from the paper and from the related notebook using EasyTransformers, since these both provide many utilities for dealing with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0e1142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformer_lens in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.33.0)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (2.20.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.8.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.33)\n",
      "Requirement already satisfied: numpy>=1.26 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (2.2.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (13.7.1)\n",
      "Requirement already satisfied: sentencepiece in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.10 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (4.66.5)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (4.44.0)\n",
      "Requirement already satisfied: typing-extensions in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (4.12.2)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformer_lens) (0.17.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
      "Requirement already satisfied: psutil in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.4)\n",
      "Requirement already satisfied: filelock in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.10.3)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
      "Requirement already satisfied: sympy in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (72.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from torch>=1.10->transformer_lens) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens) (12.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (5.27.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.12.0)\n",
      "Requirement already satisfied: setproctitle in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
      "Requirement already satisfied: einops in /home/shawnghu/ml/CD_Circuit/.venv/lib/python3.12/site-packages (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformer_lens\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a520f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Model code adapted from Callum McDougall's notebook for ARENA on reproducing the IOI paper using TransformerLens.\n",
    "# This makes some sense, since EasyTransformer, the repo/lib released by the IOI guys, was forked from TransformerLens.\n",
    "# In fact, this makes the reproduction a little bit more faithful, since they most likely do certain things such as \n",
    "# \"folding\" LayerNorms to improve their interpretability results, and we are able to do the same by using TransformerLens.\n",
    "# HuggingFace, by contrast, has the most impenetrable docs and tons of outdated APIs and etc.; even their source \n",
    "# code is impossible to traverse, and I gave up on it, thankfully quickly.\n",
    "\n",
    "from transformer_lens import utils, HookedTransformer, ActivationCache\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\",\n",
    "                                          center_unembed=True,\n",
    "                                          center_writing_weights=True,\n",
    "                                          fold_ln=False,\n",
    "                                          refactor_factored_attn_matrices=True)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28216f8c",
   "metadata": {},
   "source": [
    "## Example forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3fb595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "tokens = model.to_tokens(text).to(device)\n",
    "logits, cache = model.run_with_cache(tokens)\n",
    "probs = logits.softmax(dim=-1)\n",
    "most_likely_next_tokens = model.tokenizer.batch_decode(logits.argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11dbf9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed                     (1, 17, 768)\n",
      "hook_pos_embed                 (1, 17, 768)\n",
      "blocks.0.hook_resid_pre        (1, 17, 768)\n",
      "blocks.0.ln1.hook_scale        (1, 17, 1)\n",
      "blocks.0.ln1.hook_normalized   (1, 17, 768)\n",
      "blocks.0.attn.hook_q           (1, 17, 12, 64)\n",
      "blocks.0.attn.hook_k           (1, 17, 12, 64)\n",
      "blocks.0.attn.hook_v           (1, 17, 12, 64)\n",
      "blocks.0.attn.hook_attn_scores (1, 12, 17, 17)\n",
      "blocks.0.attn.hook_pattern     (1, 12, 17, 17)\n",
      "blocks.0.attn.hook_z           (1, 17, 12, 64)\n",
      "blocks.0.hook_attn_out         (1, 17, 768)\n",
      "blocks.0.hook_resid_mid        (1, 17, 768)\n",
      "blocks.0.ln2.hook_scale        (1, 17, 1)\n",
      "blocks.0.ln2.hook_normalized   (1, 17, 768)\n",
      "blocks.0.mlp.hook_pre          (1, 17, 3072)\n",
      "blocks.0.mlp.hook_post         (1, 17, 3072)\n",
      "blocks.0.hook_mlp_out          (1, 17, 768)\n",
      "blocks.0.hook_resid_post       (1, 17, 768)\n",
      "ln_final.hook_scale            (1, 17, 1)\n",
      "ln_final.hook_normalized       (1, 17, 768)\n"
     ]
    }
   ],
   "source": [
    "for activation_name, activation in cache.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(f\"{activation_name:30} {tuple(activation.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9aaa465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hack to get model dtype out, for compatibility with other code\n",
    "next(model.parameters()).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "515c528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x TransformerBlock(\n",
      "      (ln1): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNorm(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# print(model.config) # doesn't work on hookedtransformer, is a huggingface thing\n",
    "# print(model.embed.dtype) same, but can use dtype trick\n",
    "# print(type(model))\n",
    "#model.state_dict().keys()#.blocks[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d130a854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformer_lens.HookedTransformer.HookedTransformer,\n",
       " transformer_lens.hook_points.HookedRootModule,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "# inspect.getclasstree(inspect.getmro(type(model)))\n",
    "inspect.getmro(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32fc711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OV',\n",
       " 'QK',\n",
       " 'T_destination',\n",
       " 'W_E',\n",
       " 'W_E_pos',\n",
       " 'W_K',\n",
       " 'W_O',\n",
       " 'W_Q',\n",
       " 'W_U',\n",
       " 'W_V',\n",
       " 'W_gate',\n",
       " 'W_in',\n",
       " 'W_out',\n",
       " 'W_pos',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_enable_hook',\n",
       " '_enable_hook_with_name',\n",
       " '_enable_hooks_for_points',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_init_weights_gpt2',\n",
       " '_init_weights_kaiming',\n",
       " '_init_weights_muP',\n",
       " '_init_weights_xavier',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'accumulated_bias',\n",
       " 'add_caching_hooks',\n",
       " 'add_hook',\n",
       " 'add_module',\n",
       " 'add_perma_hook',\n",
       " 'all_composition_scores',\n",
       " 'all_head_labels',\n",
       " 'apply',\n",
       " 'b_K',\n",
       " 'b_O',\n",
       " 'b_Q',\n",
       " 'b_U',\n",
       " 'b_V',\n",
       " 'b_in',\n",
       " 'b_out',\n",
       " 'bfloat16',\n",
       " 'blocks',\n",
       " 'buffers',\n",
       " 'cache_all',\n",
       " 'cache_some',\n",
       " 'call_super_init',\n",
       " 'center_unembed',\n",
       " 'center_writing_weights',\n",
       " 'cfg',\n",
       " 'check_and_add_hook',\n",
       " 'check_hooks_to_add',\n",
       " 'children',\n",
       " 'clear_contexts',\n",
       " 'compile',\n",
       " 'context_level',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dataset',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embed',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fill_missing_keys',\n",
       " 'float',\n",
       " 'fold_layer_norm',\n",
       " 'fold_value_biases',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'from_pretrained_no_processing',\n",
       " 'generate',\n",
       " 'get_buffer',\n",
       " 'get_caching_hooks',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'get_token_position',\n",
       " 'half',\n",
       " 'hook_dict',\n",
       " 'hook_embed',\n",
       " 'hook_points',\n",
       " 'hook_pos_embed',\n",
       " 'hooks',\n",
       " 'init_weights',\n",
       " 'input_to_embed',\n",
       " 'ipu',\n",
       " 'is_caching',\n",
       " 'ln_final',\n",
       " 'load_and_process_state_dict',\n",
       " 'load_sample_training_dataset',\n",
       " 'load_state_dict',\n",
       " 'loss_fn',\n",
       " 'mod_dict',\n",
       " 'modules',\n",
       " 'move_model_modules_to_device',\n",
       " 'mps',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'pos_embed',\n",
       " 'process_weights_',\n",
       " 'refactor_factored_attn_matrices',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'remove_all_hook_fns',\n",
       " 'requires_grad_',\n",
       " 'reset_hooks',\n",
       " 'run_with_cache',\n",
       " 'run_with_hooks',\n",
       " 'sample_datapoint',\n",
       " 'set_extra_state',\n",
       " 'set_tokenizer',\n",
       " 'set_use_attn_in',\n",
       " 'set_use_attn_result',\n",
       " 'set_use_hook_mlp_in',\n",
       " 'set_use_split_qkv_input',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_single_str_token',\n",
       " 'to_single_token',\n",
       " 'to_str_tokens',\n",
       " 'to_string',\n",
       " 'to_tokens',\n",
       " 'tokenizer',\n",
       " 'tokens_to_residual_directions',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'unembed',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "dir(model)\n",
    "# torchviz.make_dot(model)\n",
    "# model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c19f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Users/georgiazhou/miniconda3/lib/python3.12/site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437d3a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/var/folders/c9/mvmx0pt17m51nyh8wgjnqj900000gn/T/ipykernel_11966/1150960534.py\u001b[0m(9)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      6 \u001b[0;31m\u001b[0;31m# embedding_output = model.embed(encoding.input_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "Moving model to device:  cpu\n",
      "> \u001b[0;32m/Users/georgiazhou/miniconda3/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py\u001b[0m(332)\u001b[0;36minput_to_embed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    330 \u001b[0;31m            \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    331 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 332 \u001b[0;31m        \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    333 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"standard\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    334 \u001b[0;31m            pos_embed = self.hook_pos_embed(\n",
      "\u001b[0m\n",
      "tensor([[0.4899, 0.2857, 0.5669, 0.1953, 0.6854, 0.5814, 0.6580, 0.0523, 0.2990,\n",
      "         0.1988, 0.7593, 0.1852, 0.7425, 0.4648, 0.5173, 0.7029, 0.3675, 0.9153,\n",
      "         0.7823, 0.3810, 0.3304, 0.9647, 0.0897, 0.2235, 0.4690, 0.2287, 0.8431,\n",
      "         0.8483, 0.9326, 0.9771, 0.5403, 0.3954, 0.6604, 0.7142, 0.8972, 0.2977,\n",
      "         0.7195, 0.7162, 0.3847, 0.4517, 0.9752, 0.9666, 0.0712, 0.0250, 0.8160,\n",
      "         0.3575, 0.9512, 0.7769, 0.2854, 0.4061, 0.7344, 0.1340, 0.7894, 0.9840,\n",
      "         0.1162, 0.6278, 0.0486, 0.9728, 0.3930, 0.8698, 0.5723, 0.4823, 0.1816,\n",
      "         0.7587, 0.4184, 0.6558, 0.1571, 0.4515, 0.4165, 0.8522, 0.8111, 0.6924,\n",
      "         0.6437, 0.9026, 0.2192, 0.0989, 0.5159, 0.3355, 0.8494, 0.6002, 0.7349,\n",
      "         0.0083, 0.9187, 0.0925, 0.8987, 0.7683, 0.3159, 0.0378, 0.1252, 0.5801,\n",
      "         0.0203, 0.0947, 0.3744, 0.7115, 0.3326, 0.3328, 0.6923, 0.2880, 0.9191,\n",
      "         0.8675, 0.7663, 0.8713, 0.7144, 0.4411, 0.6582, 0.0898, 0.4590, 0.3271,\n",
      "         0.2631, 0.0537, 0.6148, 0.3446, 0.5498, 0.8089, 0.9017, 0.4061, 0.0830,\n",
      "         0.8876, 0.1901, 0.7061, 0.0136, 0.1473, 0.9664, 0.9490, 0.1113, 0.1925,\n",
      "         0.8839, 0.5137, 0.5024, 0.0486, 0.4943, 0.2920, 0.9127, 0.0786, 0.4882,\n",
      "         0.8552, 0.6846, 0.4457, 0.5783, 0.5699, 0.6590, 0.3101, 0.1902, 0.7043,\n",
      "         0.3915, 0.0648, 0.0240, 0.3804, 0.1248, 0.1597, 0.0679, 0.3468, 0.6730,\n",
      "         0.8988, 0.4014, 0.2396, 0.2250, 0.5709, 0.3526, 0.1530, 0.0991, 0.5143,\n",
      "         0.6921, 0.0903, 0.6905, 0.1902, 0.0551, 0.5591, 0.4701, 0.6137, 0.5072,\n",
      "         0.3103, 0.8234, 0.9188, 0.2785, 0.2089, 0.5823, 0.4982, 0.4530, 0.5238,\n",
      "         0.0391, 0.3277, 0.6176, 0.8468, 0.4664, 0.5836, 0.1416, 0.0454, 0.8716,\n",
      "         0.3649, 0.9487, 0.1167, 0.7138, 0.0287, 0.1598, 0.5213, 0.2092, 0.9240,\n",
      "         0.4404, 0.4938, 0.8985, 0.2073, 0.7810, 0.3395, 0.1523, 0.0434, 0.9561,\n",
      "         0.9232, 0.8999, 0.0324, 0.0425, 0.3745, 0.6305, 0.7821, 0.9206, 0.5554,\n",
      "         0.2627, 0.7650, 0.9858, 0.1061, 0.9053, 0.1728, 0.0382, 0.1807, 0.6976,\n",
      "         0.5316, 0.5923, 0.4144, 0.4891, 0.1001, 0.1540, 0.3216, 0.3637, 0.7163,\n",
      "         0.8862, 0.4387, 0.5797, 0.8650, 0.1084, 0.5112, 0.8885, 0.3980, 0.0343,\n",
      "         0.0434, 0.1546, 0.5567, 0.7556, 0.3330, 0.5119, 0.6388, 0.7013, 0.8565,\n",
      "         0.5847, 0.5807, 0.5563, 0.5279, 0.3003, 0.3859, 0.4216, 0.5219, 0.1395,\n",
      "         0.2036, 0.9654, 0.9772, 0.7715, 0.2956, 0.2767, 0.9410, 0.3786, 0.0932,\n",
      "         0.3292, 0.5029, 0.5760, 0.0208, 0.0637, 0.9186, 0.9885, 0.7412, 0.1572,\n",
      "         0.5471, 0.3899, 0.8888, 0.9664, 0.0497, 0.9365, 0.2104, 0.8621, 0.7478,\n",
      "         0.6707, 0.8473, 0.7479, 0.5224, 0.9571, 0.4775, 0.3613, 0.3901, 0.8054,\n",
      "         0.4893, 0.8736, 0.3289, 0.0871, 0.5696, 0.3937, 0.7633, 0.8726, 0.6764,\n",
      "         0.0977, 0.0907, 0.2916, 0.7737, 0.9670, 0.0652, 0.6116, 0.6232, 0.2342,\n",
      "         0.6466, 0.4742, 0.2253, 0.0282, 0.1587, 0.3295, 0.8226, 0.6524, 0.7975,\n",
      "         0.4274, 0.1326, 0.1188, 0.4811, 0.5123, 0.4046, 0.5831, 0.7454, 0.7263,\n",
      "         0.0485, 0.3007, 0.9539, 0.5549, 0.0363, 0.1347, 0.6428, 0.8186, 0.8706,\n",
      "         0.3836, 0.9726, 0.9615, 0.1727, 0.7548, 0.4441, 0.7454, 0.6260, 0.7024,\n",
      "         0.1654, 0.8457, 0.7552, 0.4047, 0.6426, 0.9379, 0.5923, 0.9384, 0.3322,\n",
      "         0.1395, 0.1710, 0.6311, 0.0645, 0.1388, 0.8102, 0.8372, 0.3399, 0.2006,\n",
      "         0.8864, 0.6795, 0.4333, 0.0924, 0.9547, 0.7047, 0.7579, 0.3229, 0.0173,\n",
      "         0.5777, 0.5384, 0.0618, 0.0246, 0.5326, 0.5614, 0.3867, 0.6161, 0.8893,\n",
      "         0.0152, 0.6122, 0.4878, 0.2037, 0.8578, 0.2855, 0.9086, 0.9782, 0.1208,\n",
      "         0.2376, 0.7118, 0.6967, 0.5760, 0.3038, 0.4250, 0.3302, 0.5346, 0.6359,\n",
      "         0.6297, 0.5526, 0.9838, 0.7923, 0.4786, 0.1191, 0.2552, 0.6948, 0.6776,\n",
      "         0.2140, 0.3437, 0.7803, 0.7786, 0.4308, 0.5289, 0.8695, 0.3809, 0.6609,\n",
      "         0.8122, 0.7698, 0.3418, 0.3925, 0.1280, 0.4924, 0.2541, 0.3799, 0.6441,\n",
      "         0.5129, 0.3139, 0.7623, 0.7880, 0.9771, 0.7432, 0.1450, 0.3149, 0.0335,\n",
      "         0.8724, 0.8111, 0.9561, 0.2345, 0.6864, 0.4894, 0.4488, 0.9238, 0.3203,\n",
      "         0.4466, 0.5934, 0.9474, 0.6028, 0.3135, 0.8827, 0.5949, 0.7135, 0.9596,\n",
      "         0.9333, 0.2618, 0.0168, 0.5854, 0.9003, 0.0157, 0.1732, 0.7766, 0.1983,\n",
      "         0.0749, 0.2900, 0.4583, 0.5228, 0.6954, 0.2390, 0.9702, 0.4439, 0.3731,\n",
      "         0.0070, 0.4164, 0.0287, 0.9959, 0.9893, 0.2160, 0.7416, 0.4318, 0.3783,\n",
      "         0.5098, 0.0504, 0.2660, 0.7073, 0.9229, 0.1133, 0.3662, 0.3290, 0.2825,\n",
      "         0.9583, 0.6319, 0.4753, 0.0157, 0.9813, 0.5651, 0.0764, 0.5601, 0.0528,\n",
      "         0.3889, 0.5240, 0.6499, 0.8602, 0.1737, 0.2780, 0.7497, 0.2339]])\n",
      "torch.Size([1, 512])\n",
      "*** IndexError: tensors used as indices must be long, int, byte or bool tensors\n",
      "*** IndexError: tensors used as indices must be long, int, byte or bool tensors\n",
      "*** IndexError: tensors used as indices must be long, int, byte or bool tensors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:524\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     (\n\u001b[1;32m    520\u001b[0m         residual,\n\u001b[1;32m    521\u001b[0m         tokens,\n\u001b[1;32m    522\u001b[0m         shortformer_pos_embed,\n\u001b[1;32m    523\u001b[0m         attention_mask,\n\u001b[0;32m--> 524\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_to_embed(\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    526\u001b[0m         prepend_bos\u001b[38;5;241m=\u001b[39mprepend_bos,\n\u001b[1;32m    527\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[1;32m    528\u001b[0m         past_kv_cache\u001b[38;5;241m=\u001b[39mpast_kv_cache,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:332\u001b[0m, in \u001b[0;36mHookedTransformer.input_to_embed\u001b[0;34m(self, input, prepend_bos, padding_side, past_kv_cache)\u001b[0m\n\u001b[1;32m    331\u001b[0m pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m--> 332\u001b[0m embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_embed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(tokens))  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpositional_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/bdb.py:90\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_line(frame)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/bdb.py:115\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_shape)\n\u001b[1;32m      9\u001b[0m pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m---> 10\u001b[0m summary(model, input_shape, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m forward_pass(\n\u001b[1;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "from torchinfo import summary\n",
    "\n",
    "text = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "encoding = get_encoding(text, model.tokenizer, \"cpu\")\n",
    "# embedding_output = model.embed(encoding.input_ids)\n",
    "input_shape = encoding.input_ids.shape\n",
    "print(input_shape)\n",
    "pdb.set_trace()\n",
    "summary(model, input_shape, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8823997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.07</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m70.07\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same as in the notebook, example\n",
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "example_answer = \"Mary\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d377977-fe3b-45dd-9d00-1c19e5366038",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Generate dataset/Explore types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b295089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 4, 9, 6, 1, 13, 2, 8, 8, 4]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = IOIDataset(N=500, prompt_type=\"ABBA\", tokenizer=model.tokenizer)\n",
    "#data.tokenized_prompts\n",
    "data.ioi_prompts[0]\n",
    "[x['TEMPLATE_IDX'] for x in data.ioi_prompts[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92798f42",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "# indices in 'batch query_pos d_model' != length of shape [1, 512, 768]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m encoding \u001b[38;5;241m=\u001b[39m get_encoding(text, model\u001b[38;5;241m.\u001b[39mtokenizer, device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# encoding.input_ids.shape # 512-long vector, not sure why the tokens change from EOS to 0 at some point\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# embedding = model.embed(encoding.input_ids)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m out_decomps, target_decomps \u001b[38;5;241m=\u001b[39m \u001b[43mprop_model_hh_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                                   \u001b[49m\u001b[43mpatched_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_ablated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_at_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m                                                                    \u001b[38;5;66;03m# patched_values=mean_act, mean_ablated=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/patch_hh.py:394\u001b[0m, in \u001b[0;36mprop_model_hh_batched\u001b[0;34m(encoding, model, source_node_list, target_nodes, device, patched_values, num_at_time, n_layers, att_list, output_att_prob, mean_ablated)\u001b[0m\n\u001b[1;32m    386\u001b[0m     layer_out_decomps, layer_target_decomps, att_probs_lst \u001b[38;5;241m=\u001b[39m prop_BERT_hh(encoding, model, \n\u001b[1;32m    387\u001b[0m                                                                     source_node_list[b_st: b_end],\n\u001b[1;32m    388\u001b[0m                                                                     target_nodes, device,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m                                                                     output_att_prob\u001b[38;5;241m=\u001b[39moutput_att_prob,\n\u001b[1;32m    392\u001b[0m                                                                     mean_ablated\u001b[38;5;241m=\u001b[39mmean_ablated)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, transformer_lens\u001b[38;5;241m.\u001b[39mHookedTransformer):\n\u001b[0;32m--> 394\u001b[0m     layer_out_decomps, layer_target_decomps, att_probs_lst \u001b[38;5;241m=\u001b[39m \u001b[43mprop_GPT_hh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43msource_node_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb_st\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mpatched_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43matt_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matt_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43moutput_att_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_att_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mmean_ablated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_ablated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m out_decomps \u001b[38;5;241m=\u001b[39m out_decomps \u001b[38;5;241m+\u001b[39m layer_out_decomps\n\u001b[1;32m    403\u001b[0m target_decomps \u001b[38;5;241m=\u001b[39m [target_decomps[i] \u001b[38;5;241m+\u001b[39m layer_target_decomps[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)]\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/patch_hh.py:342\u001b[0m, in \u001b[0;36mprop_GPT_hh\u001b[0;34m(encoding, model, source_node_list, target_nodes, device, patched_values, att_list, output_att_prob, mean_ablated)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     layer_patched_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m rel, irrel, layer_target_decomps, returned_att_probs \u001b[38;5;241m=\u001b[39m \u001b[43mprop_GPT_layer_hh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mirrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_node_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_patched_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mlayer_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43matt_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_att_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mmean_ablated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_ablated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m target_decomps\u001b[38;5;241m.\u001b[39mappend(layer_target_decomps)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# normalize_rel_irrel(rel_n, irrel_n)\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# rel, irrel = rel_n, irrel_n\u001b[39;00m\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/patch_hh.py:217\u001b[0m, in \u001b[0;36mprop_GPT_layer_hh\u001b[0;34m(rel, irrel, attention_mask, head_mask, source_node_list, target_nodes, level, layer_patched_values, layer_module, device, att_probs, output_att_prob, mean_ablated)\u001b[0m\n\u001b[1;32m    212\u001b[0m rel_ln, irrel_ln \u001b[38;5;241m=\u001b[39m prop_layer_norm(rel, irrel, GPTLayerNormWrapper(layer_module\u001b[38;5;241m.\u001b[39mln1))\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# what the BERT model calls attention is what this model calls attention, plus a linear layer,\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# since it's an encoder model. Since this is a decoder model, we only need the \"self attention\" function,\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# and also we have to do the second layer norm ourselves out here.\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m rel_attn_residual, irrel_attn_residual, returned_att_probs \u001b[38;5;241m=\u001b[39m \u001b[43mprop_self_attention_hh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_ln\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mirrel_ln\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_node_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mGPTAttentionWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43matt_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_att_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m normalize_rel_irrel(rel_attn_residual, irrel_attn_residual)\n\u001b[1;32m    224\u001b[0m rel_attn, irrel_attn \u001b[38;5;241m=\u001b[39m rel \u001b[38;5;241m+\u001b[39m rel_attn_residual, irrel \u001b[38;5;241m+\u001b[39m irrel_attn_residual\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/patch_hh.py:121\u001b[0m, in \u001b[0;36mprop_self_attention_hh\u001b[0;34m(rel, irrel, attention_mask, head_mask, source_node_list, target_nodes, level, sa_module, device, att_probs, output_att_prob)\u001b[0m\n\u001b[1;32m    119\u001b[0m     att_probs \u001b[38;5;241m=\u001b[39m att_probs\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     att_probs \u001b[38;5;241m=\u001b[39m \u001b[43mget_attention_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mirrel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msa_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m rel_value, irrel_value \u001b[38;5;241m=\u001b[39m prop_linear(rel, irrel, sa_module\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m    125\u001b[0m rel_context \u001b[38;5;241m=\u001b[39m mul_att(att_probs, rel_value, sa_module)\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/cd.py:255\u001b[0m, in \u001b[0;36mget_attention_probs\u001b[0;34m(tot_embed, attention_mask, head_mask, sa_module)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_attention_probs\u001b[39m(tot_embed, attention_mask, head_mask, sa_module):\n\u001b[0;32m--> 255\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[43msa_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtot_embed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# these parentheses are the call to forward(), i think it's easiest to implement another wrapper class\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m transpose_for_scores(sa_module\u001b[38;5;241m.\u001b[39mkey(tot_embed), sa_module)\n\u001b[1;32m    259\u001b[0m     query_layer \u001b[38;5;241m=\u001b[39m transpose_for_scores(mixed_query_layer, sa_module)\n",
      "File \u001b[0;32m~/ml/CD_Circuit/pyfunctions/patch_hh.py:32\u001b[0m, in \u001b[0;36mGPTAttentionWrapper.query\u001b[0;34m(self, embedding)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, embedding):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_Q\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_module\u001b[38;5;241m.\u001b[39mb_Q\n",
      "File \u001b[0;32m~/ml/CD_Circuit/.venv/lib/python3.12/site-packages/einsum/lib.py:227\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *tensors)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(equation: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    226\u001b[0m     ishapes \u001b[38;5;241m=\u001b[39m [ tensor\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors ]\n\u001b[0;32m--> 227\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43meinsum_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mishapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum_execute(spec, \u001b[38;5;28mlist\u001b[39m(tensors))\n",
      "File \u001b[0;32m~/ml/CD_Circuit/.venv/lib/python3.12/site-packages/einsum/lib.py:189\u001b[0m, in \u001b[0;36meinsum_spec\u001b[0;34m(equation, ishapes)\u001b[0m\n\u001b[1;32m    187\u001b[0m isubscripts \u001b[38;5;241m=\u001b[39m io[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(isubscripts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(ishapes), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# equation inputs != # input shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 189\u001b[0m ispecs \u001b[38;5;241m=\u001b[39m [ \u001b[43meinsum_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(isubscripts, ishapes) ]\n\u001b[1;32m    190\u001b[0m idxs_map \u001b[38;5;241m=\u001b[39m einsum_idxs_map(ispecs)\n\u001b[1;32m    191\u001b[0m ospec \u001b[38;5;241m=\u001b[39m einsum_output(idxs_map, ispecs, osubscripts)\n",
      "File \u001b[0;32m~/ml/CD_Circuit/.venv/lib/python3.12/site-packages/einsum/lib.py:148\u001b[0m, in \u001b[0;36meinsum_input\u001b[0;34m(subscripts, shape)\u001b[0m\n\u001b[1;32m    146\u001b[0m lst \u001b[38;5;241m=\u001b[39m [ s\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m subscripts\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m) ]\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lst) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lst[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape), \\\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubscripts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m != length of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     lst\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# treat this case the same as an empty ellipsis at end\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: # indices in 'batch query_pos d_model' != length of shape [1, 512, 768]"
     ]
    }
   ],
   "source": [
    "# test\n",
    "pos_specific_hs = [\n",
    "        [i for i in range(12)],\n",
    "        [0],\n",
    "        [i for i in range(12)]\n",
    "    ]\n",
    "all_heads = list(itertools.product(*pos_specific_hs))\n",
    "target_nodes = [(7, 82, 11), (7, 82, 0), (7, 82, 6), (9, 82, 0), (9, 91, 7), (8, 82, 0)] # not meaningful in a GPT context\n",
    "source_list = [[node] for node in all_heads if node not in target_nodes]\n",
    "\n",
    "text = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "encoding = get_encoding(text, model.tokenizer, device)\n",
    "# encoding.input_ids.shape # 512-long vector, not sure why the tokens change from EOS to 0 at some point\n",
    "# embedding = model.embed(encoding.input_ids)\n",
    "\n",
    "out_decomps, target_decomps = prop_model_hh_batched(encoding, model, source_list, target_nodes,\n",
    "                                                                   device=device,\n",
    "                                                                   patched_values=None, mean_ablated=False, num_at_time=1)\n",
    "                                                                   # patched_values=mean_act, mean_ablated=True)\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa5c2b",
   "metadata": {},
   "source": [
    "## Explore IOI Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e9522d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfunctions.ioi_dataset import IOIDataset\n",
    "\n",
    "ioi_dataset = IOIDataset(prompt_type=\"mixed\", N=50, tokenizer=model.tokenizer, prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de60c87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4, 16, 23, 42, 48]),\n",
       " array([33, 34]),\n",
       " array([36]),\n",
       " array([ 0,  9, 19, 25, 29, 38, 39]),\n",
       " array([ 1,  5, 35, 49]),\n",
       " array([ 3, 47]),\n",
       " array([ 2,  7, 26, 40, 44]),\n",
       " array([18]),\n",
       " array([32, 43, 45]),\n",
       " array([20, 24, 30]),\n",
       " array([ 6, 12, 37]),\n",
       " array([ 8, 22]),\n",
       " array([11, 13, 14, 15, 17, 21, 27, 31]),\n",
       " array([10, 28, 41, 46])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_dataset.toks.shape\n",
    "\n",
    "ioi_dataset.word_idx\n",
    "\n",
    "ioi_dataset.sentences[:4]\n",
    "\n",
    "ioi_dataset.groups\n",
    "\n",
    "# ioi_dataset.toks[ioi_dataset.groups[-1]]\n",
    "# [ioi_dataset.sentences[x] for x in ioi_dataset.groups[3]] # sentences of the same group are identical except for the choice of nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59e67051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is wrong! The generated sentences are not of the same format as what is described in the paper, and \n",
    "# this is also not what they do in their experiments.py.\n",
    "# abc_dataset = IOIDataset(prompt_type=\"ABC mixed\", N=50, tokenizer=model.tokenizer, prepend_bos=False)\n",
    "\n",
    "# Instead, do this, apparently.\n",
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ") # Note generating several of these in a row will generate different random names; this can be useful for a quick mean ablation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65604ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Then, Katie and Angela were working at the hospital. Nicole decided to give a computer to Angela',\n",
       " 'Then, Jessica and Sarah went to the hospital. Jose gave a kiss to Sarah',\n",
       " 'When Jeremy and Jonathan got a basketball at the garden, Jesse decided to give it to Jonathan',\n",
       " 'Then, Tyler and Kristen were thinking about going to the hospital. Christopher wanted to give a bone to Tyler']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_dataset.sentences[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
